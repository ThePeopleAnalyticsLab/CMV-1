---
title: "You've Gotta Keep em' Separated? Examining the Efficacy of Proximal Remedies for Causes of Method Variance"

author:
- address: 906 East 1st. St., Thibodaux, LA 70301
  affiliation: '1'
  corresponding: yes
  email: chris_castille@mac.com
  name: Christopher M. Castille
- affiliation: '2'
  name: Wayne S. Crawford
- affilitation: '3'
  name: Marcia J. Simmering
affiliation:
- id: '1'
  institution: Nicholls State University
- id: '2'
  institution: University of Texas at Arlington
- id: '3'
  institution: Louisiana Tech University
output: pdf_document
bibliography: r-references.bib
class: man
figsintext: no
figurelist: no
footnotelist: no
keywords: method variance, procedural remedies, statistical remedies
lang: english
lineno: yes
author_note: "A previous version of this manuscript received best paper awards in the Research Methods division and conference overall from the 2018 annual conference for the Southern Management Association. We'd like to thank several individuals for providing friendly reviewer feedback on the development of this manuscript, including Hettie Richardson, Larry Williams, Alyssa McGonagle, and Chris Rosen. Additionally, we'd like to thank members of the lavaan user group, specifically Terrence Jorgenson and Ed Rigon for providing helpful feedback as we were troubleshooting the analytics. Any mistakes are ours alone. All data and code have been made publically available for re-analysis at (insert osf link)."
shorttitle: PROXIMAL CMV REMEDIES
tablelist: no
abstract: "Scholars have argued that method factors, such as common rater effects, bias estimates of covariation from same-source and single time-point investigations. In response, researchers have proposed procedural remedies. For such studies, recommended remedies include (1) presenting participants with a cover story to disguise the purpose of the survey (which addresses respondents' ability to produce data consistent with researchers' hypotheses), (2) randomizing item and scale presentation around filler scales (which addresses item and scale context effects), and (3) introducing a brief temporal separation (which addresses respondents' momentary mood). Though researchers have relied upon these proximal method variance remedies, there are no studies examining whether they nullify method variance. Here, we present the findings from two experiments utilizing the same measurement model and demonstrate that such remedies do, indeed, reduce (and in some instances, eliminate) the presence of method variance attributable to (1) consistency motifs, (2) context effects, and (3) mood. However, these sources of method variance did not substantially bias our findings. Rather, other sources of method variance (i.e., positive affectivity and negative item wording) consistently biased estimates. We conclude with recommendations for researchers wishing to addresses method bias in their same-source investigations. Readers are directed to Internet resources to review our work as a pre-peer-review preprint of this article, which is available at https://xyz osf."    
wordcount: X
---
```{r Load Packages, include=FALSE}
library(papaja)
library(apaTables)
library(citr)
library(tidyverse)
library(haven)
library(readr)
library(MOTE)
library(frequencies)
library(mice)
library(psych)
library(car)
library(boot)
library(lavaan)
library(semTools)
set.seed(19)
```
#Introduction
  Few methodological problems have been discussed more frequently than the presence and impact of method variance [@SpectorNewPerspectiveMethod2017], or variation in observations attributable to methodolgoical sources than to substantive/theoretical constructs of interest [@CampbellConvergentDiscriminantValidation1959]. Though long debated over the past several decades [e.g., @CampbellConvergentDiscriminantValidation1959; @LanceUseindependentmeasures2015; @RichardsonTaleThreePerspectives2009; @SpectorMethodVarianceOrganizational2006], the problem of method variance is often viewed as a serious one in the organizational sciences, where researchers often rely upon observations made using sources believed to share common method variance [i.e., variation in observations that is attributable to a common cause, such mood held by respondents; see @PodsakoffCommonmethodbiases2003]. Those who believe strongly that CMV is persistent problem believe that method variance threatens the substantive knowledgebase upon which practitioners rely, and so many procedural solutions have been proposed to address this eminent problem [@PodsakoffCommonmethodbiases2003; @PodsakoffSourcesMethodBias2012]. The proposed solutions are often simple (e.g., use a cover story to disguise the purpose of a study, counterbalance item presentation, and separate measurement by an interval of time) and routinely encouraged by journal editors [e.g., @AshkanasySubmittingyourmanuscript2008].   
  Unfortunately, these procedural method variance remedies have not received close examination, particularly using experimental designs that compare observations obtained using these remedies to those obtained without. These experiments are needed because they can demonstrate the extent to which a remedy addresses a proposed cause of method variance (e.g., participant beliefs about item covariation, respondent mood), resulting in reduced method variance and less biased results. Therefore, we set out to conduct these experiments and to this end we make the following contributions to the literature. First, we test the causal role of hypothesized proximal causes of method variance, specifically resondent consistency motifs, item context effects, and mood. Second, drawing on recent literature distinguishing between common and uncommon method variance [see @SpectorNewPerspectiveMethod2017], we demonstrate the extent to which these different sources of method variance differentially affect observations, affecting reserachers' ability to produce accurate effect size estimates. Thirdly, we explore causes of method variance that are specific to the substantive theory under investigation in our study, allowing a comparison of general and specific causes of method variance. 
##Theoretical Overview of Method Variance
	Before we dive too deeply into the literature on method bias, we should clarify the terms 'method,' 'method variance,' and 'method bias,' as there are differing perspectives. Summarizing the available literature, @PodsakoffSourcesMethodBias2012 distinguished between a broad and narrow definition. Drawing on @FiskeConvergentdiscriminantvalidationmeasurements1982 and citing several researchers who support this position [e.g., @Edwardsprosperorganizationalpsychology2008; @JohnsonAssessingimpactcommon2011; @SiemsenCommonMethodBias2010; @Weijtersstabilityindividualresponse2010], Podsakoff et al. noted that method encompasses several abstract elements (e.g., taking a paper-and-pencil instrument, responding using Likert scales, characteristics of the examiner) and when these elements are shared across methods or measures in the same investigation, there will be a convergence resulting in bias. By contrast, Lance and colleagues [@LanceIfitain2009; @LanceMethodEffectsMeasurement2010; @LanceUseindependentmeasures2015] restricted method to aspects that refer to alternative means of enumerating observations to indicate standings on latent traits (e.g., self- vs. other-report), which has been critized as omitting common rater sources of method variance [e.g., @PodsakoffSourcesMethodBias2012]. Method variance refers to the impact of a methodological aspect of study on a particular observation(s) [e.g.,  mood affecting observations obtained with a single-source single time-point design), which differs from the extent to which method variance is shared across methods, causing biased/inflated parameter estimates (e.g., negative mood both contaminating observations of two variables, inflating their covariances; see @Williamsalternativeapproachmethod1994]. This distinction is important because method variance can be unique to a specific set of observations within a dataset (e.g., halo effects contaminate supervisor appraisals of employee performance, but not subordinate variables). When such uncommon method variance is present in one's observations, observed covariances with other observations are attentuated [@SpectorNewPerspectiveMethod2017].
	Conventionally, method variance is a concern when researchers's conclusions dervie from self-report surveys administered at a single time-point because it is believed that methods affect the same item response process. Therefore, it is important to understand how methods affect the underlying item response process resulting in contaminated observations. Research from cognitive psychology suggests that four cognitive processes are associated with responding to survey items [see @Tourangeaupsychologysurveyresponse2000]: (1) comprehension (i.e., understanding items), (2) retrieval (i.e., recalling item-relevant memories), (3) judgment (i.e., assessing the completeness of a relevant memory), and (4) response (i.e., mapping one's judgement onto the available item responses). @PodsakoffCommonmethodbiases2003 later divided the last process into response selection and (5) response reporting to highlight how individuals might modify their responses to adhere to certain criteria (e.g., adjusting previous item responses to appear more consistent). @PodsakoffCommonmethodbiases2003 summarized the method variance literature into four broad potential sources of common method bias (i.e., common rater effects, item characteristic effects, item context effeccts, and measurement context effects) to explain how response processes are corrupted, resulting in contaminated observations. 
	In our manuscript, we examine the role of a few sources identified by @PodsakoffCommonmethodbiases2003 that are believed to play a role in all same-source surveys. These sources of method variance are referred to as proximal causes of method variance. In two studies, we examine the role of a specific common rater effects (i.e., implicit theories, consistency motifs, mood states, trait affectivity factors), item context effects (i.e., item/scale priming and item/scale embeddedness effects), and measurement context effects (i.e., gathering observations on predictor and criterion variables at the same point in time vs a differnt point in time), which are believed to corrupt the item response process, contaminate observations, and ultimately bias estimates of covariation. We have decided to focus on proximal causes of method variance for single-source designs because these designs are likely to be the most prevalent in the organizational and social science (applied and academic settings) due to their relatively lower cost and reduced administrative burden. As such, ensuring that our remedies work is paramount to helping researchers make the most of their research designs. Furthermore, single-source designs should be ripe for method variance because the cognitive processes of retrieval (i.e., remembering responses to previously answered items rather than the whole of one's experience), judgment (i.e., falsely judging that one has effectively retrieved relevant memories), and in some instances reporting (i.e., modifying one's responses to be consistent) may not be addressed unless a remedy is applied [see @PodsakoffCommonmethodbiases2003; @PodsakoffSourcesMethodBias2012; @Tourangeaupsychologysurveyresponse2000]. 
	
[Question: Why not examine response style indicators as well (e.g., acquiescence, disacquiescence, intra-individual response consistency)? More recently, researchers have examined the stability of response styles, or the preference for particular response categories, which reflects a clear consistency motif. In an 8-year ongoing panel study, @WetzelStabilityExtremeResponse2016 found that between 49 and 59% of the variance in state response style factors could be explained by trait response style factors, indicating a remarkable amount of response consistency across time and also raising questions about their state-like properties. 
[Concern: Be sure to maintain a distinction between "causes" and "effects" when writing. Others don't do this, but we should be more responsible.]

###Relevant Common Rater Effects  
	Common rater effects are any artifactual covariation introduced by gathering observations on (or from) the same rater @PodsakoffCommonmethodbiases2003. Though there are many common rater effects [@PodsakoffCommonmethodbiases2003], there are four that are particularly relevant for our study: consistency motifs, implicit theories, mood states, and trait affectivity factors. Consistency motifs refer to the propensity for respondents to maintain consistency in their responses to questions. Clearly, the drive to appear consistent should affect response reporting, as individuals will desire to appear rational [@PodsakoffCommonmethodbiases2003]. Later research revealed consistency motifs might bias estimates of covariation [@HarrisonContextCognitionCommon1996]. Similarly, implicit theories or illusory correlations refer to respondents beliefs about the covariation among particular traits, behaviors, and or outcomes that may not accurately reflect reality [@SternbergPeopleconceptionsintelligence1981]. These biases are believed to affect judgments of response appriopriateness [@PodsakoffCommonmethodbiases2003].
	To address consistency motifs and implicit theories, researchers have used cover stories [e.g., @HarrisonContextCognitionCommon1996], which are narratives designed to both disguise the hypotheses under investigation and dispel implicit theories held by the participants [@PodsakoffCommonmethodbiases2003]. Importantly, there is no experimental research evaluating this procedural remedy for these sources of method variance. 
	Somewhat differntly from consistency motifs and implicit theories are mood states and trait affectivity factors, which are clearly interrelated. Mood states refer to respondents momentary or brief mood state. A great deal of research indicates that one's emotional state influences the contents of what is recalled from memory by priming similarly valenced material stored in memory [see @BlaneyAffectmemoryreview1986; @BowerMoodmemory1981; @IsenPositiveaffectfactor1991; @ParrottMoodmemorynatural1990]. Sometimes this has a desirable effect, such as when mood-congruency facilitates recall [@BowerMoodmemory1981; @IsenPositiveaffectfactor1991]. One's mood state should also be related to general affectivity (positive and negative), which refers to a respondent's propensity to view themselves or their environments in positive or negative ways [@PodsakoffCommonmethodbiases2003]. Trait affectivity should exert similar effects on the item response process as mood, and may explain the effect of momentary mood state on the item response process. @BriefShouldnegativeaffectivity1988 observed that negative affectivity contaminates observations of stress, job and life satisfaction, depression, and the amount of affect experienced at work, resulting in biased estimates of covariation. Similarly, @Williamsalternativeapproachmethod1994 found that positive emotionality (analogous to positive affectivity) contaminates self-report measurements of several commonly studied organizational variables (sp. job satisfaction, organizational commitment, leader-contingent reward behavior, and job characteristics). Additionally, they found that negative emotionality (alaogous to negative affectivity) played a weaker role, only affecting  observations of job satisfaction. Similarly, @ChenNegativeaffectivityunderlying1991 and [@Jeximpactnegativeaffectivity1996] observed weak influences of negative affectivity on the relationships between self-reported job stress and strain variables. In short, both trait affectivity and momentary mood states may be a common source of method variance.
	To address the role of mood states, researchers have proposed using a temporal separation of measurement that increases the amount of time between when observations of predictor and criterion variables are made [@PodsakoffCommonmethodbiases2003; @PodsakoffSourcesMethodBias2012]. Though it involves separation by time, this remedy addresses a proximal cause of method variance (i.e., mood state). It is assumed that introducing a temporal separation (e.g., separating measures by one week) will reduce the systematic influence of momentary mood states, resulting in estimates that are less baised. Again, there is no research examining the efficacy of this remedy.
###Relevant Context Effects	
	Context effects refer to any artifactual covariation among observations caused by an item or scale’s location or relationship to other items or scales in a survey (e.g., item/scale priming and item/scale embeddedness effects). @PodsakoffCommonmethodbiases2003 proposed that item context can affect retrieval and judgments of response appropriateness. Though these effects are elusive [i.e., they can be difficult to predict and control a prioi; see @TourangeauCognitiveProcessesUnderlying1988], @TourangeauAttitudestructurebelief1991 demonstrated that participants respond more quickly to similar items placed closer together rather than further apart, suggesting that prior responses were more easily accessible in short-term memory. Such findings also suggest that item intercorrelations may be a function of the consistent ordering of items within a particular instrument. If so, then participants observed data may artificially discriminate on a latent trait. Examining this possibility, @SteinbergContextserialordereffects1994 found that one item in a 20-item scale became slightly more discriminating when it was presented later in the scale rather than as the first item, which Steinberg attributed to the increase in self-awareness that occurs when individuals are asked to repeatedly reflect on their own tendencies. Additionally, @HarrisonContextCognitionCommon1996 found that context effects produced by scale location and scale valence (negative scales presented before positive scales) affected psychometric properties such that scales presented later were less reliable. Further, when negative scales were presented first, estimated inter-scale correlations were much higher, suggesting the presence of scale embeddedness effects. More recently, @WeinbergerItemsContextEffects2006 found that ambiguous items were interpreted differently depending upon the content of the items that preceded them, suggesting that item order and ambiguity are important considerations to make in assessing psychological phenomena.
	To address item priming and item embeddedness effects, researchers have proposed counterbalancing or randomizing the order of item and/or scales within a survey, particular around a filler scale or series of filler scales [@PodsakoffCommonmethodbiases2003; @SalancikExaminationNeedSatisfactionModels1977]. It is assumed that this remedy will reduce the systematic influence of context effects that might introduce common method variance across predictors and criteria, resulting in estimates of scale covariation that are less biased by context. Again, there is no research examining the efficacy of this remedy.
###Measurement-Specific Causes of Both Common and Uncommon Method Variance
  Advocating a more nuanced view of common method variance, @SpectorNewPerspectiveMethod2017 suggest that certain causes of method variance are specific to the measurement strategy employed by researchers. For instance, when gathering observations on both affective/attitudinal and behavioral factors, Spector et al. encouraged researchers to consider ways to capture the mood state exhibited by their participates, as this would be a likely common cause of method variance that would contaminate the response process underlying both sets of observations, resulting in biased estimates of covariation. Addtionally, there may be sources of method variance that are uncommon (i.e., unique) to particular methods of observation. For instance, affective/attitudinal measures might be more strongly affected by response sets (e.g., consistency motifs) than behavioral measures, which would be affected by impression management strategies. Such effects would attenuate scale covariances unless controlled [see @SpectorNewPerspectiveMethod2017]. Addressing these sources of variance requires statistical strategies [e.g., measured cause models; see @WilliamsMethodVarianceMarker2010].
  In line with Spector et al.'s call for controlling both common and uncommon method variance, we built in measures of method variance causes that were shared across our measures and unique to specific mesures. In both of our studies, we used the same measurement model and tested the same underlying theory; namely, that proactive personality relates positively to proactive behaviors (i.e., voice and taking charge) as well as behaviors reflecting task performance (i.e., in-role behavior) and contextual performance (i.e., OCB) (see Figure 1). We decided to study these predictor-criterion relationships for three reasons that are important for both organizational scholars and method variance testing in general. First, these relationships are often described in the literature [e.g.,@FullerJr.Changedrivennature2009; @GrantReversingExtravertedLeadership2011], suggesting that assuming a relationship is important to a broad audience of organizational scholars. Second, prior research suggests that these relationships may be a function of method variance [e.g., @FullerJr.Changedrivennature2009]. For instance, a meta-analysis by @FullerJr.Changedrivennature2009 demonstrated that these relationships are often inflated by common method variance, particularly when observations are gathered using the same source rather than multiple sources (see Table 1). They observed that the relationships between proactive personality and workplace behaviors was substantially inflated by between 129% and 308% when observations were made using a common (rather than independent) source. Though researchers have suggested that such percentages mistate the impact of method variance [e.g., @LanceUseindependentmeasures2015; @SpectorNewPerspectiveMethod2017], it seems clear that methodological differences are resulting and diverging estimates. Third, and most importantly, it is not clear what sources of method variance would explain such these differences. To respolve these disparities, we tested the same measurement model in our two studies, examining the effects of various hypothesized common method factors (e.g., mood, affectivity, and consistency motifs) and uncommon method factors (e.g., negative item wording). Figure b illustrates how the method factors were modeled.
  Lastly, the cognitive psychology literature, specifically on heuristics and biases in decision making and judgments, informs method variance research. For instance, consider anchoring, wherein one's judgment is informed by an arbitrary prior thought in one's conciousness, within and their ability to explain item-order (or item priming) effects. In an experiment, college students were asked the questions (a) how happy are you and (b) how often are you dating. When asked in this order, the correlation between the two questions was low (r = .11). However, when asked in reverse, the correlation was 5 times larger (r = .62). Similar findings emerged with married couples about their sex life [see @StrackPrimingcommunicationSocial1988]. The design of the questionnaire (in this case, the item order) explains the size of the correlation estimated between measures of life satisfaction and dating or frequency of sex, respectively, with anchoring providing the psychological explanation. To address the above methodolgoical issues, @PodsakoffCommonmethodbiases2003 advocated separating measurement in some manner.
  Unfortunately, little research to date has systematically examined the efficacy of procedural remedies that involve separating measurements in some form. This is unfortunate because common method variance is still seen as a common issue plaguing substantive research and the very guidance upon which researchers draw has not be tested adequately. Additionally, to date researchers have adopted two interrelated views for addressing method variance (procedural remedies or statistical remedies). However, few have considered the implications of jointly using both, particularly in studying the efficacy of procedural remedies. Presumably, if a researcher measured a source of methodological contamination (e.g., positive affectivity) while also using a procedural remedy that relates to said source of contamination, then we could test whether the procedural remedy has affected the cause of method variance and more specifically whether the procedural remedy as reduced the role played by the measured cause of method variance. Unfortunately, studying method variance in this way (as we learned) is a rather complicated affair.
##Our Overarching Approach to Examining the Efficacy of Procedural Remedies
  We examined how parameter estimates for a substantive measurement model (i.e., a model containing measures of proactive personality, in-role behavior, and organizational citizenship) were affected by a measured cause of method variance (i.e., positive affectivty). Additionally, we randomoly assigned individuals to receive a non-remedied survey or a survey that was designed to remove any bias in the estimated relationships between between proactive personality and both in-role behavior and organizational citizenship. 
   To study the efficacy of procedural remedies for method variance, we drew upon latent variable modeling strategies proposed by Wiliams and colleagues [e.g., @WilliamsFourResearchDesigns2016; @WilliamsMethodVarianceMarker2010], but adapted these strategies to a multiple group context whereby the efficacy of procedural remedies for method variance was tested. Specifically, we followed a step-wise nested model comparison approach that involved tested key hypotheses regarding the efficacy of procedural remedies for method variance. In our initial step, we simply examined whether the measures for each of these factors loaded on their respective factors. We also examined model data fit. However, unlike Williams et al. we did not concern ourselves with ensuring that the initial model attain relatively good fit because we expected that unaccounted for method variance could be attributable to either the lack of procedural remedies, positive affectivity, or both. Afterward, we moved on to a baseline model whereby the latent covariances linking positive affectivity to the substantive factors were fixed to zero. Theoretical independendence from other latent factors has been considered a requirement linking method factors to substantive factors [see @ConwayWhatReviewersShould2010; @WilliamsIdealnonidealnomarker2015]. In other words, our model testing assumes that positive affectivity contaminates responses to proactive personality, in-role behavior, and ocb [@SpectorMethodologicalUrbanLegends2011]. While this model is compared to the initial model, rejection of this baseline model is not important for our purposes [see @WilliamsFourResearchDesigns2016; @WilliamsMethodVarianceMarker2010]. We then move to a model whereby positive affectivity contaminates responses to the items reflecting proactive personanlity, in-role behavior, and ocb and compare the fit of this model to the baseline. This model (method-U) tests the assumption that positive affectivity contaminates these measures. If this model is superior to the baseline, then method variance (in this case, attributable to positive affectivity) is present and we move to examining the nature of the method variance by comparing this congeneric (method-u) model to a non-congeneric (method-i) whereby method loadings are viewed as equivalent within substantive factors but allowed to vary across substantive factors [@RichardsonTaleThreePerspectives2009; @WilliamsFourResearchDesigns2016]. This tests the assumption that method variance is measure-specific rather than item specific [see @SpectorNewPerspectiveMethod2017]. Further equality constraints can be imposed if necessary [see Williams et al. method-c model; @WilliamsFourResearchDesigns2016]. As this is a multiple group context, we then examine whether the method effects attributable to positive affectivity are equally present across conditions by constraining the method effects attributable to positive affectivity to be equal across conditions while retaining any constraints that survived prior testing (method-xc). If proximal remedies have an impact, then this model should be rejected. Additionally, for proximal remedies to be effective, they must also reduce the amount of method variance attributable to positive affectivity, which is eventually examined. Following this test, we move to exmamining whether proximal remedies have any other indepedent effects by constraining the substantive factor loadings to be equal across conditions. Rejecting this model implies that the substantive loadings vary across conditions, further suggesting that proximal remedies have some kind of impact. 
   Following suggestions from friendly reviewers, other important assumptions can be tested. One key assumption, which is implied in any research that advocates a correction to coefficients that are estimated when procedural remedies have not been employed [e.g., @PodsakoffCommonmethodbiases2003], is that failing to use specific remedies has certain consequences. For example, failing to use item randomization would result in a consistent and systematic inflation of substantive factor loadings. This assumption can be tested by forcing the differences in substantive factor loadings to be equal across conditions, which tests the hypothesis that proximal remedies have a non-congeneric effect in that they cause a difference in the factor loadings of our measurement model. If this is true, then a simple correction is meaningful. If it is not true, and such proximal method variance is congeneric, then such a simple correction cannot be afforded. 
   Once all desired method variance constraints have been tested and method variance has been detected, then tests for method bias can be conducted [see @WilliamsFourResearchDesigns2016; @WilliamsMethodVarianceMarker2010]. Here, the best-fitting model containing method variance is compared to a model with latent construct covariances constrained to levels estimated in the baseline model (Williams et al.'s method-r model). Rejection of this model implies that coefficients are biased the modeled causes of method variance. Additionally, a model can be estimated whereby the latent construct covariances are constrained to be equal across conditions, which tests the assumption that proximal remedies effectively de-bias one's data by affecting unmeasured proximal causes. This model is summarily compared with the best fitting method effect model. Rejection of this model implies that latent construct covariances do vary across conditions and demonstrates that proximal remedies have an impact.
###General Purpose
  In three experiments, we examine the efficacy of procedural remedies for different proximal causes of common method variance while also examining the role played by other proximal causes of method variance that are specific to our measures. Across all three studies, we randomly assigned individuals to conditions where remedies for different proximal causes of CMV have been applied or have not been applied. This allows us to test the causal role of hypothesized mechanisms that give rise method variance and also to test the extent to which these causes produce biased estimates. We focus on relationships between proactive personality and important workplace outcomes for a number of substantive reasons associated with common method variance. 
  First, we chose to study these predictor-criterion relationships because meta-analytic results have demonstrated correlations two-to-three times larger between proactive personality and the workplace outcomes used in our study when relying on self-report data exclusively as compared to distinct-source ratings [@FullerJr.Changedrivennature2009].[^It is worth noting that the difference between same-source and distinct-source designs could be exaggerated by uncommon sources of method variance. Interested readers are directed to @LanceUseindependentmeasures2015; @SpectorNewPerspectiveMethod2017.] Similarly, previous research also has investigated both self-report and significant-other reports of proactively personality. @SeibertProactivepersonalitycareer1999 found regression coefficients representing the impact of proactive personality on workplace outcomes range from 31% to 55% stronger when using self-report ratings rather than significant-other ratings. Together, these findings illustrate the potential for common method variance to confound relationships found when using self-report of proactive personality alongside self-reports of workplace outcomes.
  Second, there are a number of psychometric reasons to suspect common method variance to impact relationships under study in the current research. One issue that makes examining the relationships in the current study is the extent to which method variance influences these types of variables. Typical measures of personality and job performance contain approximately 23% and 25% method variance, respectively [@CoteEstimatingTraitMethod1987; @PodsakoffCommonmethodbiases2003]. Another potential reason the observed relationships in our study may be impacted by method variance is due to social desirability, or the need for social approval and acceptance [@Crownenewscalesocial1960]. Social desirability may increase the mean levels of the constructs under study and produce spurious relationships between our study variables. Commonly used scales to measure the variables under study in our research are also susceptible to common method variance due to both item demand characteristics and positive item wording. Item demand characteristics refer to the potential of items containing cues about how participants should respond to certain items, whereas positive item wording may produce artifactual covariation between constructs [@PodsakoffCommonmethodbiases2003]. Proactive personality item examples include “I am always looking for better ways to do things” and “I excel at identifying opportunities.” Such items are positively worded and may produce socially desirable responses from participants. Our dependent variables are commonly measured with scales that are prone to these same sources of method variance when using self-report data.
  We contribute to the method variance literature by providing an experimental manipulation of commonly used remedies in order to a) examine the extent to which CMV is addressed by each remedy and b) control for alternative explanations through our design via randomized experiment. Our decision to conduct a randomized experiment was driven by two primary justifications. First, CMV is often difficult to model directly, and thus, it is common for authors to combat the presence of CMV by implementing either a) procedural remedies, b) statistical remedies, or c) some combination of procedural and statistical remedies. Thus, while authors often attempt to address CMV through design or analysis, there currently is no heuristic for authors to judge the extent to which CMV may bias correlations in the absence of a specific procedural or statistical remedy(ies). Using experimental design, we are able to examine the efficacy of each remedy individually and have a randomized control group for comparison purposes. Second, while a number of post-hoc remedies exist, there is disagreement about the efficacy of such remedies. For example, authors often use the correlational marker variable technique and unmeasured latent method construct model (ULMC) to statistically rule out common method variance. However, these techniques have been criticized by experts in the area on numerous occasions [e.g., @RichardsonTaleThreePerspectives2009; @SpectorNewPerspectiveMethod2017] Specifically, the ULMC treats method effects as unidimensional, when in reality method effects are multidimensional, and thus “the full effects of the method variance will not be captured and undercorrection of factor correlation errors can occur” [pg. 1592, @WilliamsIdealnonidealnomarker2015].  While we use experimental design to examine the efficacy of individual procedural remedies, we also examine a more recent statistical remedy [@WilliamsMethodVarianceMarker2010], which allows us to test for both noncongeneric and congeneric method effects in an SEM framework, in order to evaluate the efficacy of this remedy as authors often choose one or more statistical remedies that have been criticized in the literature in an attempt to combat CMV. Another contribution of our study is testing the efficacy of procedural and statistical remedies exclusively at the item-level in our models. Researchers [e.g., @JohnsonAssessingimpactcommon2011; @WilliamsMethodVarianceMarker2010; @WilliamsFourResearchDesigns2016] have examined the efficacy of statistical remedies using item parceling, which was done to improve the parameter-to-participant ratio. Unfortunately, method variance is not a theory of parcels but of items. In other words, a central tenet of method variance is that some aspect of the research methodology contaminates item responses (not parcels). By modeling item level responses, we more faithfully test method variance theory. 
#Study 1 - Proximal Separation of Measures 
  In study 1, we examined the efficacy of proximal remedies for method variance. More specifically, we tested whether using a cover story and randomzing items and scales around a filler scale worked (i.e., reduced the presence of method variance). Participants were randomly assigned to a condition where observations were obtained with or without these remedies. For our non-remedied (i.e., control) condition, an online self-reported survey was designed such that all items and scales appeared in the same order, but were separated by different webpages. This was a conventional kind of survey design likely in use by many organizations. For our remedied condition, we used a cover story that was designed to both blind participants to the purpose of our study and dispel implicit theories regarding the substantive intention guiding a study such as ours: test for positive relationships linking proactive personality to workplace behaviors. Also, the presentation of items within scales and also the whole scales were randomized around a series of filler scale consisting of measured method effect factors. We provide more detail for these remedies below.
#Methods - Study 1
##Sample and Procedure
```{r Load Study 1 Data, include=FALSE}
#Load data
data <- read_sav("Datasets/Study 1.sav")

#Count of individuals who agree to participate (Q42=1 OR Q44=1). Note: 1 is control/non-remedied and 2 is treatment/experimental/remedied.
N1 <- as.numeric(freq_vect(data$Q42)[1,"Count"])
N2 <- as.numeric(freq_vect(data$Q44)[1,"Count"])
Nall <- sum(N1,N2)

#Subset in those who agreed to participate and passed the manipulation check question (Q42=1 OR Q44=1 & correctly answered attention checks).
Agree <- subset(data, Q42 == 1 & Q47 == 1 | Q44 == 1 & Q79 == 2)

#Get success rates (SR) for responding correctly across both conditions.
n1 <- as.numeric(freq_vect(Agree$Q42)[1,"Count"])
n2 <- as.numeric(freq_vect(Agree$Q42)[2,"Count"])
n <- n1+n2
sr1 <- n1/N1
sr2 <- n2/N2

#Filter in attentive responders.
Inattent <- subset(Agree, Q26_11 == 1 | Q105_11 ==  1)

#Calculate sum of inattentive responders (iar) that have been screened out of the Inattent dataset for either incorrectly or failing to answer "strongly disagree" to an attention check question. 
iar1 <- freq_vect(Agree$Q26_11)
iar1[3,1] <- "2" 
iar1[4,1] <- "2" 
iar1[5,1] <- "2" 
iar1 <- freq_vect(iar1$data)
iar1 <- as.numeric(iar1[2,"Count"])
iar2 <- freq_vect(Agree$Q105_11)
iar2[2,1] <- "2" 
iar2[3,1] <- "2" 
iar2 <- freq_vect(iar2$data)
iar2 <- as.numeric(iar2[2,"Count"])
iar <- iar1+iar2+(nrow(Agree) - (sum(iar1,iar2)) - nrow(Inattent))

#Delete cases who did not complete the demographic questionnaire and barely completed any tests.
Inattent <- Inattent[-c(1, 275, 276, 277),]

#Setup demographics.
#Rename variables.
Inattent$COND <- Inattent$Q42 
Inattent$AGE <- Inattent$Q33
Inattent$RACE <- Inattent$Q34
Inattent$GENDER <- Inattent$Q35
Inattent$EDUCAT <- Inattent$Q36.0
Inattent$EMPLOYED <- Inattent$Q37
Inattent$JOBTENURE <- Inattent$Q38
Inattent$USREGION <- Inattent$Q40
Inattent$PROFESSION <- Inattent$Q39

#Then, combine data from separate surveys in order to form the final cleaned and well-structured dataset. Note: there were two surveys setup on Qualtrics, hence why data needs to be combined. You'll see redundant items moving forward.
##Convert NAs to 0 to allow merging. Later, you'll need to reasign NAs to conduct a missing data analysis. 
Inattent[is.na(Inattent)] <- 0

#Proactive personality
Inattent$PP1	<-	Inattent$Q26_1	+Inattent$Q105_1 #Wherever I have been, I have been a powerful force for change.
Inattent$PP2	<-	Inattent$Q26_2	+Inattent$Q105_2 #I am constantly on the lookout for new ways to improve my life.
Inattent$PP3	<-	Inattent$Q26_3	+Inattent$Q105_3 #If I see something I don't like, I fix it.
Inattent$PP4	<-	Inattent$Q26_4	+Inattent$Q105_4 #I am always looking for better ways to do things.
Inattent$PP5	<-	Inattent$Q26_5	+Inattent$Q105_5 #No matter what the odds, if I believe in something, I will make it happen.
Inattent$PP6	<-	Inattent$Q26_6	+Inattent$Q105_6 #Nothing is more exciting than seeing my ideas turn into reality.
Inattent$PP7	<-	Inattent$Q26_7	+Inattent$Q105_7 #I love being a champion for my ideas, even against others' opposition.
Inattent$PP8	<-	Inattent$Q26_8	+Inattent$Q105_8 #I excel at identifying opportunities.
Inattent$PP9	<-	Inattent$Q26_9	+Inattent$Q105_9 #If I believe in an idea, no obstacle will prevent me.
Inattent$PP10	<-	Inattent$Q26_10	+Inattent$Q105_10 #I can spot a good opportunity long before others can.

#OCBI
Inattent$OCBI1	<-	Inattent$Q29_1	+	Inattent$Q106_19 #I help others who have been absent.
Inattent$OCBI2	<-	Inattent$Q29_2	+	Inattent$Q106_20 #I help others who have heavy work loads.
Inattent$OCBI3  <-	Inattent$Q29_3	+	Inattent$Q106_21 #I assist my supervisor with his/her work load (when not asked).
Inattent$OCBI4	<-	Inattent$Q29_4	+	Inattent$Q106_22 #I take time to listen to co-workers' problems and worries.
Inattent$OCBI5	<-	Inattent$Q29_5	+	Inattent$Q106_23 #I go out of my way to help new employees.
Inattent$OCBI6	<-	Inattent$Q29_6	+	Inattent$Q106_24 #I take a personal interest in other employees.
Inattent$OCBI7	<-	Inattent$Q29_7	+	Inattent$Q106_25 #I pass along information to co-workers.

#OCBO
Inattent$OCBO1	<-	Inattent$Q30_1	+	Inattent$Q106_27 #My attendance at work is above the norm.
Inattent$OCBO2	<-	Inattent$Q30_2	+	Inattent$Q106_28 #I give advance notice when I'm unable to come to work.
Inattent$OCBO3	<-	Inattent$Q30_3	+	Inattent$Q106_29 #I take undeserved work breaks.
Inattent$OCBO4	<-	Inattent$Q30_4	+	Inattent$Q106_30 #I spend a great deal of time with personal phone conversations.
Inattent$OCBO5	<-	Inattent$Q30_5	+	Inattent$Q106_31 #I complain about insignificant things at work.
Inattent$OCBO6	<-	Inattent$Q30_6	+	Inattent$Q106_32 #I conserve and protect organizational property.
Inattent$OCBO7	<-	Inattent$Q30_7	+	Inattent$Q106_33 #I adhere to informal rules devised to maintain order. 

#IRB
Inattent$IRB1	<-	Inattent$Q31_1	+	Inattent$Q106_35 #I adepquately complete assigned duties.
Inattent$IRB2	<-	Inattent$Q31_2	+	Inattent$Q106_36 #I fulfill responsibilities specific in my job description.
Inattent$IRB3	<-	Inattent$Q31_3	+	Inattent$Q106_37 #I perform tasks that are expected of me.
Inattent$IRB4	<-	Inattent$Q31_4	+	Inattent$Q106_38 #I meet formal performance requirements of the job.
Inattent$IRB5	<-	Inattent$Q31_5	+	Inattent$Q106_39 #I engage in activities that will directly affect my performance.
Inattent$IRB6	<-	Inattent$Q31_6	+	Inattent$Q106_40 #I nelgect aspects of my job that I'm obligated to perform.
Inattent$IRB7	<-	Inattent$Q31_7	+	Inattent$Q106_41 #I fail to perform essential job duties.

#Consistency Motif
#"I am a brave person"
Inattent$CM1 <- Inattent$Q27_7 + Inattent$Q106_7
#"I am a courageous person"
Inattent$CM2 <- Inattent$Q28_11 + Inattent$Q106_18
#"I am a talkative person"
Inattent$CM3 <- Inattent$Q29_8 + Inattent$Q106_26
#"I am a silent person"
Inattent$CM4 <- Inattent$Q30_8 + Inattent$Q106_34
#"I am an optimistic person"
Inattent$CM5 <- Inattent$Q33_6 + Inattent$Q112_6
#"I am a pessimistic person"
Inattent$CM6 <- Inattent$Q41_7 + Inattent$Q116_7
#"I seldom feel blue."
Inattent$CM7 <- Inattent$Q31_8 + Inattent$Q106_42
#"I often feel blue."
Inattent$CM8 <- Inattent$Q32_5 + Inattent$Q111_5

###Create PANAS items.
##PA
#Interested
Inattent$PA1 <- Inattent$Q34_1 + Inattent$Q113_1
#Excited
Inattent$PA2 <- Inattent$Q34_3 + Inattent$Q113_3
#Strong
Inattent$PA3 <- Inattent$Q34_5 + Inattent$Q113_5
#Enthusiastic
Inattent$PA4 <- Inattent$Q34_9 + Inattent$Q113_9
#Proud
Inattent$PA5 <- Inattent$Q34_10 + Inattent$Q113_10
#Alert
Inattent$PA6 <- Inattent$Q35_2 + Inattent$Q114_2
#Inspired
Inattent$PA7 <- Inattent$Q35_4 + Inattent$Q114_4
#Determined
Inattent$PA8 <- Inattent$Q35_6 + Inattent$Q114_6
#Attentive
Inattent$PA9 <- Inattent$Q35_7 + Inattent$Q114_7
#Active
Inattent$PA10 <- Inattent$Q35_9 + Inattent$Q114_9

##NA
#Distressed
Inattent$NA1 <- Inattent$Q34_2 + Inattent$Q113_2
#Upset
Inattent$NA2 <- Inattent$Q34_4 + Inattent$Q113_4
#Guilty
Inattent$NA3 <- Inattent$Q34_6 + Inattent$Q113_6
#Scared
Inattent$NA4 <- Inattent$Q34_7 + Inattent$Q113_7
#Hostile
Inattent$NA5 <- Inattent$Q34_8 + Inattent$Q113_8
#Irritable
Inattent$NA6 <- Inattent$Q35_1 + Inattent$Q114_1
#Ashamed
Inattent$NA7 <- Inattent$Q35_3 + Inattent$Q114_3
#Nervous
Inattent$NA8 <- Inattent$Q35_5 + Inattent$Q114_5
#Jittery
Inattent$NA9 <- Inattent$Q35_8 + Inattent$Q114_8
#Afraid
Inattent$NA10 <- Inattent$Q35_10 + Inattent$Q114_10

#Recode 0 values to missing.
Inattent$PP1[Inattent$PP1==0] <- NA
Inattent$PP2[Inattent$PP2==0] <- NA
Inattent$PP3[Inattent$PP3==0] <- NA
Inattent$PP4[Inattent$PP4==0] <- NA
Inattent$PP5[Inattent$PP5==0] <- NA
Inattent$PP6[Inattent$PP6==0] <- NA
Inattent$PP7[Inattent$PP7==0] <- NA
Inattent$PP8[Inattent$PP8==0] <- NA
Inattent$PP9[Inattent$PP9==0] <- NA
Inattent$PP10[Inattent$PP10==0] <- NA
Inattent$PP1[Inattent$PP1==0] <- NA
Inattent$PP2[Inattent$PP2==0] <- NA
Inattent$PP3[Inattent$PP3==0] <- NA
Inattent$PP4[Inattent$PP4==0] <- NA
Inattent$PP5[Inattent$PP5==0] <- NA
Inattent$PP6[Inattent$PP6==0] <- NA
Inattent$PP7[Inattent$PP7==0] <- NA
Inattent$PP8[Inattent$PP8==0] <- NA
Inattent$PP9[Inattent$PP9==0] <- NA
Inattent$PP10[Inattent$PP10==0] <- NA
Inattent$OCBI1[Inattent$OCBI1==0] <- NA
Inattent$OCBI2[Inattent$OCBI2==0] <- NA
Inattent$OCBI3[Inattent$OCBI3==0] <- NA
Inattent$OCBI4[Inattent$OCBI4==0] <- NA
Inattent$OCBI5[Inattent$OCBI5==0] <- NA
Inattent$OCBI6[Inattent$OCBI6==0] <- NA
Inattent$OCBI7[Inattent$OCBI7==0] <- NA
Inattent$OCBO1[Inattent$OCBO1==0] <- NA
Inattent$OCBO2[Inattent$OCBO2==0] <- NA
Inattent$OCBO3[Inattent$OCBO3==0] <- NA
Inattent$OCBO4[Inattent$OCBO4==0] <- NA
Inattent$OCBO5[Inattent$OCBO5==0] <- NA
Inattent$OCBO6[Inattent$OCBO6==0] <- NA
Inattent$OCBO7[Inattent$OCBO7==0] <- NA
Inattent$IRB1[Inattent$IRB1==0] <- NA
Inattent$IRB2[Inattent$IRB2==0] <- NA
Inattent$IRB3[Inattent$IRB3==0] <- NA
Inattent$IRB4[Inattent$IRB4==0] <- NA
Inattent$IRB5[Inattent$IRB5==0] <- NA
Inattent$IRB6[Inattent$IRB6==0] <- NA
Inattent$IRB7[Inattent$IRB7==0] <- NA
Inattent$PA1[Inattent$PA1==0] <- NA
Inattent$PA2[Inattent$PA2==0] <- NA
Inattent$PA3[Inattent$PA3==0] <- NA
Inattent$PA4[Inattent$PA4==0] <- NA
Inattent$PA5[Inattent$PA5==0] <- NA
Inattent$PA6[Inattent$PA6==0] <- NA
Inattent$PA7[Inattent$PA7==0] <- NA
Inattent$PA8[Inattent$PA8==0] <- NA
Inattent$PA9[Inattent$PA9==0] <- NA
Inattent$PA10[Inattent$PA10==0] <- NA
Inattent$NA1[Inattent$NA1==0] <- NA
Inattent$NA2[Inattent$NA2==0] <- NA
Inattent$NA3[Inattent$NA3==0] <- NA
Inattent$NA4[Inattent$NA4==0] <- NA
Inattent$NA5[Inattent$NA5==0] <- NA
Inattent$NA6[Inattent$NA6==0] <- NA
Inattent$NA7[Inattent$NA7==0] <- NA
Inattent$NA8[Inattent$NA8==0] <- NA
Inattent$NA9[Inattent$NA9==0] <- NA
Inattent$NA10[Inattent$NA10==0] <- NA
Inattent$CM1[Inattent$CM1==0] <- NA
Inattent$CM2[Inattent$CM2==0] <- NA
Inattent$CM3[Inattent$CM3==0] <- NA
Inattent$CM4[Inattent$CM4==0] <- NA
Inattent$CM5[Inattent$CM5==0] <- NA
Inattent$CM6[Inattent$CM6==0] <- NA
Inattent$CM7[Inattent$CM7==0] <- NA
Inattent$CM8[Inattent$CM8==0] <- NA

#Retain only variables used for testing purposes.
data1 <- Inattent[c(215:282)]
N <- as.numeric(nrow(data1))
n1f <- as.numeric(freq_vect(data1$COND)[2,"Count"])
n2f <- as.numeric(freq_vect(data1$COND)[1,"Count"])

#Missing data analysis using 'sapply(data1, function(x) sum(is.na(x)))' revealed some missing likert data. 
init <- mice(data1, maxit = 0)
meth <- init$method
predM <- init$predictorMatrix
meth[c("PP5")]="norm"
meth[c("OCBI5")]="norm"
meth[c("IRB4")]="norm"
imputed <- mice(data1, method=meth, predictorMatrix=predM, m=5)
data1 <- complete(imputed)
#Round imputed data to nearest whole number for estimation purposes. 
data1$PP5 <- ceiling(data1$PP5)
data1$OCBI5 <- ceiling(data1$OCBI5)
data1$IRB4 <- ceiling(data1$IRB4)

#Calculate descriptives
data1$AGE <- as.numeric(data1$AGE)
M <- mean(data1$AGE, na.rm = TRUE)
SD <- sd(data1$AGE, na.rm = TRUE)

#Calculate frequencies
##Recode single "f" to female. 
female.n <- as.numeric(freq_vect(data1$GENDER)[1,"Count"])
female.p <- as.numeric(freq_vect(data1$GENDER)[1,"Percentage"])
white.n <- as.numeric(freq_vect(data1$RACE)[2,"Count"])
white.p <- as.numeric(freq_vect(data1$RACE)[2,"Percentage"])
fulltime.n <- as.numeric(freq_vect(data1$EMPLOYED)[4,"Count"])
fulltime.p <- as.numeric(freq_vect(data1$EMPLOYED)[4,"Percentage"])
```
  Six hundred and twenty-one workers from Amazon's Mechanical Turk were paid $1.30 for completing a survey, of which `r apa(N,0,T)` agreed to participate in our study after reading our informed consent form. These `r apa(N,0,T)` participants were randomly assigned to one of two conditions: non-remedied (n = `r apa(N1,0,T)`) or remedied (n = `r apa(N2,0,T)`). Aproximately `r apa(sr1,2,T)` (n = `r apa(n1,0,T)`) in the non-remedied and approximately `r apa(sr2,2,T)` (n = `r apa(n2,0,T)`) in the remedied condition correctly responded to the manipulation check of proper intrepration of the study purpose and were allowed to continue. Respondents' data were eliminated due to incorrectly or not responding to an attention check item asking individuals to "Click on the first circle indicating "Strongly Disagree?" (n = `r apa(iar,0,T)`) [@MeadeIdentifyingcarelessresponses2012], or not reporting demographics and abandoning the survey (n = 4). This filtering process resulted in a final sample of `r apa(N,0,T)` individuals (`r apa(n1f,0,T)` in the control and `r apa(n2f,0,T)` in the experimental condition). Notwithstanding missing demographic data, the sample was female biased (n = `r apa(female.n,0,T)`, `r apa(female,2,T)`), predominantly Caucasian, and  the average age was *M* = `r apa(M,2,T)` (*SD* = `r apa(SD,2,T)`). The majority (n = `r apa(fulltime.n,0,T)`, *f* = `r apa(fulltime.p,2,T)`) of respondents worked full-time. Three cases of missing item level data were handled using the normal model approach [see @WuComparisonImputationStrategies2015].
  
  Following guidance by @PodsakoffCommonmethodbiases2003, we sought to create a psychological separation of measurement using a cover story. In the experimental condition where the proximal separation of measurement remedy was used, participants were given a cover story designed to disguise the purpose of the study:"In this study, you will be asked to respond to statements about yourself and how you behave at work. Separate researchers built the content of this survey for separate purposes, and so the questions may or may not relate to one another. As such, there are no right or wrong answers, so please provide honest responses." By comparison, in the control condition participants were given a message to disguise the purpose of the study transparent: "The purpose of this study is to test for relationships between proactive personality and workplace behaviors (including taking charge at work, having a voice in the workplace, organizational citizenship behavior at work, and job performance)." These participants were also given a survey with all items and scales presented in the same order (demographics were presented last). Following the randomly assigned cover story, we asked our participants to respond to the following item indicating whether they understood the purpose of our study: "Before you take our survey, please tell us which of the following correctly describes the purpose of this study." Three response options were given: (a) "The purpose of this study is to test for relationships between personality and workplace behaviors. As such, there is a clear purpose to the study." (b) "Separate researchers built the content of this survey for separate purposes, and so the questions may or may not relate to one another. As such, there is no single clear purpose to this study." and (c) "The purpose of this study is to measure emotional intelligence and workplace behaviors." 
  
  In addition to the use of a cover story, we following additional guidance by @PodsakoffCommonmethodbiases2003 and included other procedural remedies for method variance within the experimental condition. We placed filler scales in between the administration of the proactive personality and criteria scales. Several filler scales were included, which contained the positive and negative affective schedule and the consistency motif scales. Additionally, to address scale-order effects, we randomized the placement of proactive personality and criteria scales such that one would be placed first before the other. To address item-order effects, we randomized items within all scales. 

##Measures
```{r Cronbach Alphas, include = FALSE}
rm(list=setdiff(ls(), "data1"))
#Create scale scores
my.keys.list <- list(PP=c("PP1","PP2","PP3","PP4","PP5","PP6","PP7","PP8","PP9","PP10"),
                     IRB=c("IRB1","IRB2","IRB3","IRB4","IRB5","-IRB6","-IRB7"),
                     OCBI=c("OCBI1","OCBI2","OCBI3","OCBI4","OCBI5","OCBI6","OCBI7"),
                     OCBO=c("OCBO1","OCBO2","-OCBO3","-OCBO4","-OCBO5","OCBO6","OCBO7"),
                     PA=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10"),
                     Na=c("NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     AP=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10","NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     CM=c("CM1","CM2","CM3","-CM4","CM5","-CM6","CM7","-CM8"),
                     NIW=c("IRB6","IRB7","OCBO3","OCBO4","OCBO5"))
my.scales <- scoreItems(my.keys.list,data1)
PP.alpha <- my.scales[["alpha"]][1]
IRB.alpha <- my.scales[["alpha"]][2]
OCBI.alpha <- my.scales[["alpha"]][3]
OCBO.alpha <- my.scales[["alpha"]][4]
PA.alpha <- my.scales[["alpha"]][5]
Na.alpha <- my.scales[["alpha"]][6]
AP.alpha <- my.scales[["alpha"]][7]
CM.alpha <- my.scales[["alpha"]][8]
NIW.alpha <- my.scales[["alpha"]][9]
```
###Proactive personality
  We used the  10-item proactive personality scale was used to capture proactive personality [@SeibertProactivepersonalitycareer1999]. Example items include: "I am constantly on the lookout for new ways to improve," "If I see something I don't like, I fix it," and "I excel at identifying opportunities." This, and all scales included in this study, utilized a five-point agreement Likert rating scale (1 = strongly disagree, 5 = strongly agree) ($\alpha$ = `r apa(PP.alpha,2,T)`))

###In-role and organizational citizenship behavior 
  @Williamsalternativeapproachmethod1994 In-Role Performance Behavior (IRB) and Organizational Citizenship Behavior (OCB) scales, the latter of which includes OCBI (OCB directed at the individual) and OCBO (OCB directed at the organization), were used as dependent variables. The items were initially written to reflect a supervisor's perspective and so were adjusted here to be self-referent. Example items (and Cronbach alphas) for each respctive scale: "I perform tasks that are expected of me" ($\alpha$ = `r apa(IRB.alpha,2,T)`), "I take a personal interest in other employees" ($\alpha$ = `r apa(OCBI.alpha,2,T)`), and "I conserve and protect organizational property" ($\alpha$ = `r apa(OCBO.alpha,2,T)`).^[“Across all three studies, our data indicated that the negatively worded items from these scales loaded onto a negative item wording factor, and so we elected to omit these items from our analysis. As we learned, research suggests that negatively worded items often negatively impact survey research, such as by increasing measurement error [@dalalNegativelyWordedItems2015]. Readers who are concerned about inattentive responding or response style issues should know that the inattentive responding detection methods that we have employed are considered superior [see @dalalNegativelyWordedItems2015]. Reviewers who are interested in examining the role of negative item wording can see our data and code, which are publicly available at this link: https://osf.io/wdskv/.”]

###Positive Affectivity
  To assess trait affectivity, we used the positive scale of the PANAS [@WatsonDevelopmentValidationBrief1988]. Participants were asked to read each item and then select the responses that indicate the extent to which they generally feel, on average. Across both conditions, coefficient alpha reliability for was `r apa(PA.alpha,2,T)` for PA.
  
##Analytical Approach
  To test if our chosen procedural remedies for common method variance were effective, we followed the step-wise model comparison approach discussed previously. Positive affectivity was modeled using a single composite indicator approach Given that our measures involved the use of Likert rating scales, which generally produce multivariate non-normal data, we opted for diagonally-weighted least squares. Chi-square difference testing (p < .05) was used to facilitate decisions regarding model rejection.
  
#Results - Study 1
```{r Descriptive Statistics, include = FALSE}
#Create Descriptives Table
scales <- my.scales[["scores"]]
scales <- cbind(data1[c(1,2,4,5)],scales)
scales <- scales[c(1:9)]
```
```{r Proximal Separation Substantive Analyses, include=FALSE}
method.cfa <- '
#Method factors
  PA =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 
  Na =~ NA*NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10
  AP =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 + NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10

#set covariances for bifactor to zero
  PA ~~ 0*Na
  PA ~~ 0*AP
  Na ~~ 0*AP

#set variances to be 1.
  PA ~~ 1*PA
  Na ~~ 1*Na
  AP ~~ 1*AP

#Factor means of the first group are fixed as 0. The factor means of the other groups are freely estimated. 
##Method factors
  PA ~ 0
  Na ~ 0
  AP ~ 0
'
#To see the results of an anlysis of the discriminant validity of the measurement model, see the following object. 
method <- cfa(model = method.cfa, data = data1, parameterization = "theta", estimator = "dwls", information = "expected")
#Get method factor scores
df <- predict(method)

#bind to dataframe
data1 <- cbind(data1,df)

#Note: certain response categories are too few for the estimator to work.  Specifically, the "strongly disagree" and "disagree" response options were simply combined to reflect a "disagree" option. So I combined them:

##Model 1 <- Initial Model
initial.cfa <- '
##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb)*IRB
PP ~~ c(ppocbia,ppocbib)*OCBI
PP ~~ c(ppocboa,ppocbob)*OCBO
PP ~~ c(pppaa,pppab)*PosAff
IRB ~~ c(irbocbia,irbocbib)*OCBI
IRB ~~ c(irbocboa,irbocbob)*OCBO
IRB ~~ c(irbpaa,irbpab)*PosAff
OCBI ~~ c(ocbioa,ocbiob)*OCBO
OCBI ~~ c(ocbipaa,ocbipab)*PosAff
OCBO ~~ c(ocbopaa,ocbopab)*PosAff

#Compute factor covariance differences 
ppirbc := ppirba-ppirbb
ppocbic := ppocbia-ppocbib
ppocboc := ppocboa-ppocbob
pppac := pppaa-pppab
irbocbic := irbocbia-irbocbib
irbocboc := irbocboa-irbocbob
irbpac := irbpaa-irbpab
ocbioc := ocbioa-ocbiob
ocbipac := ocbipaa-ocbipab
ocbopac := ocbopaa-ocbopab

#Factor means of latent factors for both groups are fixed at zero to allow identification, with the exception of the composite indicators.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
initial <- cfa(initial.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)

#Model 2: Baseline. Method and substantive covariances are constrained to zero. Method effects are constrained to zero.
baseline.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factor covariances are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
baseline <- cfa(baseline.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(initial, baseline) #As expected, baseline is much worse. 

#Model 3: Method U model. Freely estimate method effects across groups. Tests for the pressence of method effects attributable to a common sources of variance (proximal causes and positive affectivity). Method effects are allowed to vary across conditions. Factor differences in factor loadings and covariances have been computed to facilitate interpretation of method effects. 
methodu.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences 
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a
papp1c	:=	papp1b	-	papp1a
papp2c	:=	papp2b	-	papp2a
papp3c	:=	papp3b	-	papp3a
papp4c	:=	papp4b	-	papp4a
papp5c	:=	papp5b	-	papp5a
papp6c	:=	papp6b	-	papp6a
papp7c	:=	papp7b	-	papp7a
papp8c	:=	papp8b	-	papp8a
papp9c	:=	papp9b	-	papp9a
papp10c	:=	papp10b	-	papp10a
pairb1c	:=	pairb1b	-	pairb1a
pairb2c	:=	pairb2b	-	pairb2a
pairb3c	:=	pairb3b	-	pairb3a
pairb4c	:=	pairb4b	-	pairb4a
paocbi1c	:=	paocbi1b	-	paocbi1a
paocbi2c	:=	paocbi2b	-	paocbi2a
paocbi3c	:=	paocbi3a	-	paocbi3b
paocbi4c	:=	paocbi4b	-	paocbi4a
paocbi5c	:=	paocbi5b	-	paocbi5a
paocbi6c	:=	paocbi6b	-	paocbi6a
paocbi7c	:=	paocbi7b	-	paocbi7a
paocbo1c	:=	paocbo1b	-	paocbo1a
paocbo2c	:=	paocbo2b	-	paocbo2a
paocbo6c	:=	paocbo6b	-	paocbo6a
paocbo7c	:=	paocbo7b	-	paocbo7a

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Compute factor covariances differences.
PPIRB3 := PPIRB1-PPIRB2
PPOCBI3 := PPOCBI1-PPOCBI2
PPOCBO13 := PPOCBO1-PPOCBO2
IRBOCBI3 := IRBOCBI1-IRBOCBI2
IRBOCBO3 := IRBOCBO1-IRBOCBO2
OCBIO3 := OCBIO1-OCBIO2

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodu <- cfa(methodu.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(baseline,methodu) #Method variance attributable to positive affectivity has been identified. 

#Model 4: Method I model. Constrain estimates of method effects to be equal within substantive variables but different across substantive variables. This tests whether method effects attributable to positive affectivity are present to an equal degree within a given factor but vary across different factors.
methodi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp1a, papp1a)*PP2 + c(papp1a,papp1a)*PP3 + c(papp1a,papp1a)*PP4 + c(papp1a,papp1a)*PP5 + c(papp1a,papp1a)*PP6 + c(papp1a,papp1a)*PP7 + c(papp1a,papp1a)*PP8 + c(papp1a,papp1a)*PP9 + c(papp1a,papp1a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb1a,pairb1a)*IRB2 + c(pairb1a,pairb1a)*IRB3 + c(pairb1a,pairb1a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi1a,paocbi1a)*OCBI2 + c(paocbi1a,paocbi1a)*OCBI3 + c(paocbi1a,paocbi1a)*OCBI4 + c(paocbi1a,paocbi1a)*OCBI5 + c(paocbi1a,paocbi1a)*OCBI6 + c(paocbi1a,paocbi1a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo1a,paocbo1a)*OCBO2 + c(paocbo1a,paocbo1a)*OCBO6 + c(paocbo1a,paocbo1a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. 
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodi <- cfa(methodi.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodi,methodu) #Method variance is congeneric across substantive items. 

#Model 5: Method UC model. Constrain estimates of method effects, which are freely estimated across all factors (i.e., method u), to be equal across conditions. This is done by making the method factor loadings equal across conditions and tests whether method variance attributable to positive affectivity is equally present across conditions. 
methoduc.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp2a, papp2a)*PP2 + c(papp3a,papp3a)*PP3 + c(papp4a,papp4a)*PP4 + c(papp5a,papp5a)*PP5 + c(papp6a,papp6a)*PP6 + c(papp7a,papp7a)*PP7 + c(papp8a,papp8a)*PP8 + c(papp9a,papp9a)*PP9 + c(papp10a,papp10a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences. Done for interpretation purposes. 
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methoduc <- cfa(methoduc.cfa,group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methoduc,methodu) #Method variance attributable to positive affectivity varies across the two conditions. 

#Model 6: Method UP model. Constrain substantive factor loadings to be equal across conditions but free across factors and within factors. This tests the hypothesis that proximal remedies do or do not cause a difference in the factor loadings of our measurement model. If this model is equivalent to methodu, then proximal remedies do not cause a meaningful difference in factor loadings. 

methodup.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4 
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Constrain substantive factor loadings to equality. 
pp1a==pp1b
pp2a==pp2b
pp3a==pp3b
pp4a==pp4b
pp5a==pp5b
pp6a==pp6b
pp7a==pp7b
pp8a==pp8b
pp9a==pp9b
pp10a==pp10b
irb1a==irb1b
irb2a==irb2b
irb3a==irb3b
irb4a==irb4b
ocbi1a==ocbi1b
ocbi2a==ocbi2b
ocbi3a==ocbi3b
ocbi4a==ocbi4b
ocbi5a==ocbi5b
ocbi6a==ocbi6b
ocbi7a==ocbi7b
ocbo1a==ocbo1b
ocbo2a==ocbo2b
ocbo6a==ocbo6b
ocbo7a==ocbo7b

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodup <- cfa(methodup.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodup,methodu) #Method variance attributable to other proximal causes of method variance has been detected. Need to follow up with tests to identify the nature of the proximal causes of method variance (congeneric vs. non-congeneric).

#Model 7: Method UPI model. Allow substantive factor loadings to vary across conditions but (1) force the differences in factor loadings to be equal within factors yet to (2) vary across factors. Tests the hypothesis that proximal causes of method effects addressed by proximal remedies are congeneric (vs. non-congeneric) and is done by (i) computing factor loading differences across conditions and then (ii) forcing the differences to be equal across conditions. If this model is statistically different from method u, then proximal method effects have complex effects and so a simple correction for failing to use proximal remedies will not be viable. However, if the model is not statistically different from method u, then this suggests that proximal method effects in the factor loadings vary across measurement models.
methodupi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodupi <- cfa(methodupi.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodupi,methodu) #Methodupi is not statistically different from method u, but is simpler and so retained via the rule of parsimony. Variance attributable to other proximal causes of method variance appears to vary across measures but is constant within a given measure.  Following up with a test to see if the effect is constant across all measures (and so a simple correction for failing to use a proximal remedy for CMV is viable) or if the correction would have to be within measures. 

#Model 8: Tests for constant proximal method effect. Same as model 7 with one exception: force the differences in factor loadings to be equal across all factors. Tests the hypothesis that proximal causes of method effects addressed by proximal remedies are constant. If this model is not statistically different from method upi, then proximal method effects are a constant and can be corrected simply. In other words, proximal method effects would be as simple as has been appreciated in the literature.

methodupc.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
pp10c==irb1c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
irb4c==ocbi1c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodupc <- cfa(methodupc.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodupi,methodupc) #Methodupi is statistically different from methodupc and a better fit. Therefore, a  correction for failing to use a proximal remedy for CMV is viable) or if the correction would have to be measure specific, which is consistent with a measure-centric view of method variance (Spector et al., 2017). *More research is needed to verify this (especially if replicated in study 2). 

#Model 9: Method RAff model. Constrain estimates of covariances to be equal to baseline levels in respective conditions. Test method bias due to positive affectivity and proximal causes of method variance. 
methodrupi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Latent covariances come from the 
PP ~~ c(.279,.296)*IRB
PP ~~ c(.459,.573)*OCBI
PP ~~ c(.464,.403)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(.351,.475)*OCBI
IRB ~~ c(.738,.591)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(.690,.635)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodrupi <- cfa(methodrupi.cfa, group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodrupi,methodupi) #No evidence of bias attributable to the accounted for method effects (i.e., positive affectivity and method effects). 

#Model 10: Constrain the between-condition factor covariances that are statistically indistinguishable from zero (p > .05; as identified by the best-fitting model, which in this case is the Method U model) to be equal. This helps to show that assuming equal covariances across conditions (i.e., method variance without bias) is tenable. 
methodupic.cfa<- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Constrain factor covariances to equality
PPIRB1==PPIRB2
PPOCBI1==PPOCBI2
PPOCBO1==PPOCBO2
IRBOCBI1==IRBOCBI2
OCBIO1==OCBIO2

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodupic <- cfa(methodupic.cfa,group = "COND", data = data1, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(initial, methodu, methodi, methoduc, methodup, methodupi, methodupic, methodrupi) #Interestingly, all covariances appeared invariant across conditions. In other words, proximal remediess, though appearing to reduce method variance (i.e., method variance varies across condi), do not cause differences in the substantive parameter estimates. This may suggest that proximal causes of CMV are not be powerful enough alone to cause substantial amounts of bias. By contrast, the method bias that was observed in this study was attributable to positive affectivity. 

## extract fit indices tables
fitm.initial <- fitmeasures(initial)      #Model 1: Initial model.
fitm.baseline <- fitmeasures(baseline)    #Model 2: Baseline model.
fitm.methodu <- fitmeasures(methodu)      #Model 3: Unconstrained method effects model. (Presence of method effects).
fitm.methodi <- fitmeasures(methodi)      #Model 4: Method effects vary across substantive constructs. (Congeneric vs. Noncongeneric CMV).
fitm.methoduc <- fitmeasures(methoduc)    #Model 5: Constrain method effects to equality across conditions. (Proximal method variance equal across remedied vs. non-remedied).
fitm.methodup <- fitmeasures(methodup)    #Model 6: Constrain substantive factor loadings to be equal across conditions (proximal remedies decontaminate measurement models).
fitm.methodupi <- fitmeasures(methodupi)  #Model 7: Force factor loadings to be equal within factors but vary across factors (congeneric vs. noncongeneric proximal method effects).
fitm.methodupc <-  fitmeasures(methodupc) #Model 8: Tests for constant proximal method effect.
fitm.methodru <- fitmeasures(methodrupi)  #Model 9: Constrain latent covariances to baseline levels in respective conditions (test for method bias).
fitm.methodru <- fitmeasures(methodupic)  #Model 10: Constrain the between-condition factor covariances to be equal. 

#Build table
greeks=c(alpha='\u03b1', tau='\u03c4', sigma='\u03c3', beta='\u03b2', gamma='\u03b3', chi='\u03c7', delta='\u0394')
Model <- c("Initial CFA", "Baseline", "Method U", "Method I", "Method Uc", "Method Up", "Method Upi", "Method Ru", "Method U")
chi.square <- c(paste0(greeks['chi'],'^2^'))
df <- c("df")
chi.square.p.value <- c("*p* value")
RMSEA <- c("RMSEA")
RMSEA.lower <- c("90% LCL")
RMSEA.upper <- c("90% UCL")
RMSEA.pvalue <- c("RMSEA p value")
SRMR <- c("SRMR")
table <- as.data.frame(cbind(Model,chi.square,df,"p value","CF","RMSEA","90% LCL","90% UCL","RMSEA p value","SRMR"))
colnames(table)[2] <- paste0(greeks['chi'],'^2')
colnames(table)[3] <- df
colnames(table)[4] <- c("p value")
colnames(table)[5] <- c("CFI")
colnames(table)[6] <- RMSEA
colnames(table)[7] <- RMSEA.lower
colnames(table)[8] <- RMSEA.upper
colnames(table)[9] <- RMSEA.pvalue
colnames(table)[10] <- SRMR
#Convert collumns 2 through 9 to numeric.
table$`χ^2` <- as.numeric(table$χ)
table$df <- as.numeric(table$df)
table$`p value` <- as.numeric(table$`p value`)
table$CFI <- as.numeric(table$CFI)
table$RMSEA <- as.numeric(table$RMSEA)
table$`90% LCL` <- as.numeric(table$`90% LCL`)
table$`90% UCL` <- as.numeric(table$`90% UCL`)
table$`RMSEA p value` <- as.numeric(table$`RMSEA p value`)
table$SRMR <- as.numeric(table$SRMR)

#Insert stats
##Chi-Square
table[1,2]<- round(as.numeric(fitMeasures(initial)[3]), digits = 2)
table[2,2]<- round(as.numeric(fitmeasures(baseline)[3]), digits = 2)
table[3,2]<- round(as.numeric(fitmeasures(methodu)[3]), digits = 2)
table[4,2]<- round(as.numeric(fitmeasures(methodi)[3]), digits = 2)
table[5,2]<- round(as.numeric(fitmeasures(methoduc)[3]), digits = 2)
table[6,2]<- round(as.numeric(fitmeasures(methodup)[3]), digits = 2)
table[7,2]<- round(as.numeric(fitmeasures(methodupi)[3]), digits = 2)
table[8,2]<- round(as.numeric(fitmeasures(methodru)[3]), digits = 2)
table[9,2]<- round(as.numeric(fitmeasures(methoduu)[3]), digits = 2)

##df
table[1,3]<- round(as.numeric(fitMeasures(initial)[4]), digits = 2)
table[2,3]<- round(as.numeric(fitmeasures(baseline)[4]), digits = 2)
table[3,3]<- round(as.numeric(fitmeasures(methodu)[4]), digits = 2)
table[4,3]<- round(as.numeric(fitmeasures(methodi)[4]), digits = 2)
table[5,3]<- round(as.numeric(fitmeasures(methoduc)[4]), digits = 2)
table[6,3]<- round(as.numeric(fitmeasures(methodup)[4]), digits = 2)
table[7,3]<- round(as.numeric(fitmeasures(methodupi)[4]), digits = 2)
table[8,3]<- round(as.numeric(fitmeasures(methodru)[4]), digits = 2)
table[9,3]<- round(as.numeric(fitmeasures(methoduu)[4]), digits = 2)

##Chi-Square p value
#Adapt p-values to table.
pvalr <- function(pvals, sig.limit = .001, digits = 3, html = FALSE) {

  roundr <- function(x, digits = 1) {
    res <- sprintf(paste0('%.', digits, 'f'), x)
    zzz <- paste0('0.', paste(rep('0', digits), collapse = ''))
    res[res == paste0('-', zzz)] <- zzz
    res
  }

  sapply(pvals, function(x, sig.limit) {
    if (x < sig.limit)
      if (html)
        return(sprintf('&lt; %s', format(sig.limit))) else
          return(sprintf('< %s', format(sig.limit)))
    if (x > .1)
      return(roundr(x, digits = 2)) else
        return(roundr(x, digits = digits))
  }, sig.limit = sig.limit)
}
table[1,4]<- pvalr(as.numeric(fitMeasures(initial)[5]), digits = 2)
table[2,4]<- pvalr(as.numeric(fitmeasures(baseline)[5]), digits = 2)
table[3,4]<- pvalr(as.numeric(fitmeasures(methodu)[5]), digits = 2)
table[4,4]<- pvalr(as.numeric(fitmeasures(methodi)[5]), digits = 2)
table[5,4]<- pvalr(as.numeric(fitmeasures(methoduc)[5]), digits = 2)
table[6,4]<- pvalr(as.numeric(fitmeasures(methodup)[5]), digits = 2)
table[7,4]<- pvalr(as.numeric(fitmeasures(methodupi)[5]), digits = 2)
table[8,4]<- pvalr(as.numeric(fitmeasures(methodru)[5]), digits = 2)
table[9,4]<- pvalr(as.numeric(fitmeasures(methoduu)[5]), digits = 2)

#CFI
table[1,5]<- round(as.numeric(fitMeasures(initial)[9]), digits = 3)
table[2,5]<- round(as.numeric(fitmeasures(baseline)[9]), digits = 3)
table[3,5]<- round(as.numeric(fitmeasures(methodu)[9]), digits = 3)
table[4,5]<- round(as.numeric(fitmeasures(methodi)[9]), digits = 3)
table[5,5]<- round(as.numeric(fitmeasures(methoduc)[9]), digits = 3)
table[6,5]<- round(as.numeric(fitmeasures(methodup)[9]), digits = 3)
table[7,5]<- round(as.numeric(fitmeasures(methodupi)[9]), digits = 3)
table[8,5]<- round(as.numeric(fitmeasures(methodru)[9]), digits = 3)
table[9,5]<- round(as.numeric(fitmeasures(methoduu)[9]), digits = 3)

##RMSEA
table[1,6]<- round(as.numeric(fitMeasures(initial)[17]), digits = 3)
table[2,6]<- round(as.numeric(fitmeasures(baseline)[17]), digits = 3)
table[3,6]<- round(as.numeric(fitmeasures(methodu)[17]), digits = 3)
table[4,6]<- round(as.numeric(fitmeasures(methodi)[17]), digits = 3)
table[5,6]<- round(as.numeric(fitmeasures(methoduc)[17]), digits = 3)
table[6,6]<- round(as.numeric(fitmeasures(methodup)[17]), digits = 3)
table[7,6]<- round(as.numeric(fitmeasures(methodupi)[17]), digits = 3)
table[8,6]<- round(as.numeric(fitmeasures(methodru)[17]), digits = 3)
table[9,6]<- round(as.numeric(fitmeasures(methoduu)[17]), digits = 3)

#RMSEA lower
table[1,7]<- round(as.numeric(fitMeasures(initial)[18]), digits = 3)
table[2,7]<- round(as.numeric(fitmeasures(baseline)[18]), digits = 3)
table[3,7]<- round(as.numeric(fitmeasures(methodu)[18]), digits = 3)
table[4,7]<- round(as.numeric(fitmeasures(methodi)[18]), digits = 3)
table[5,7]<- round(as.numeric(fitmeasures(methoduc)[18]), digits = 3)
table[6,7]<- round(as.numeric(fitmeasures(methodup)[18]), digits = 3)
table[7,7]<- round(as.numeric(fitmeasures(methodupi)[18]), digits = 3)
table[8,7]<- round(as.numeric(fitmeasures(methodru)[18]), digits = 3)
table[9,7]<- round(as.numeric(fitmeasures(methoduu)[18]), digits = 3)

#RMSEA upper
table[1,8]<- round(as.numeric(fitMeasures(initial)[19]), digits = 3)
table[2,8]<- round(as.numeric(fitmeasures(baseline)[19]), digits = 3)
table[3,8]<- round(as.numeric(fitmeasures(methodu)[19]), digits = 3)
table[4,8]<- round(as.numeric(fitmeasures(methodi)[19]), digits = 3)
table[5,8]<- round(as.numeric(fitmeasures(methoduc)[19]), digits = 3)
table[6,8]<- round(as.numeric(fitmeasures(methodup)[19]), digits = 3)
table[7,8]<- round(as.numeric(fitmeasures(methodupi)[19]), digits = 3)
table[8,8]<- round(as.numeric(fitmeasures(methodru)[19]), digits = 3)
table[9,8]<- round(as.numeric(fitmeasures(methoduu)[19]), digits = 3)

#RMSEA p-value
table[1,9]<- pvalr(as.numeric(fitMeasures(initial)[20]), digits = 3)
table[2,9]<- pvalr(as.numeric(fitmeasures(baseline)[20]), digits = 3)
table[3,9]<- pvalr(as.numeric(fitmeasures(methodu)[20]), digits = 3)
table[4,9]<- pvalr(as.numeric(fitmeasures(methodi)[20]), digits = 3)
table[5,9]<- pvalr(as.numeric(fitmeasures(methoduc)[20]), digits = 3)
table[6,9]<- pvalr(as.numeric(fitmeasures(methodup)[20]), digits = 3)
table[7,9]<- pvalr(as.numeric(fitmeasures(methodupi)[20]), digits = 3)
table[8,9]<- pvalr(as.numeric(fitmeasures(methodru)[20]), digits = 3)
table[9,9]<- pvalr(as.numeric(fitmeasures(methoduu)[20]), digits = 3)

#SRMR
table[1,10]<- round(as.numeric(fitMeasures(initial)[23]), digits = 3)
table[2,10]<- round(as.numeric(fitmeasures(baseline)[23]), digits = 3)
table[3,10]<- round(as.numeric(fitmeasures(methodu)[23]), digits = 3)
table[4,10]<- round(as.numeric(fitmeasures(methodi)[23]), digits = 3)
table[5,10]<- round(as.numeric(fitmeasures(methoduc)[23]), digits = 3)
table[6,10]<- round(as.numeric(fitmeasures(methodup)[23]), digits = 3)
table[7,10]<- round(as.numeric(fitmeasures(methodupi)[23]), digits = 3)
table[8,10]<- round(as.numeric(fitmeasures(methodru)[23]), digits = 3)
table[9,10]<- round(as.numeric(fitmeasures(methoduu)[23]), digits = 3)

#Relable table to table 2.
table2 <- table

#Build table. These codes need to be fixed. 
Model <- c("Baseline vs. Method U", "Method U vs. Method I", "Method U vs. Method Uc", "Method U vs. Method Up", "Method U vs. Method Upi", "Method U vs. Method Ru", "Method U vs. Method Uu")
chi.square <- c(paste0(greeks['delta']),paste0(greeks['chi']), "^2^")
df <- c(paste0(greeks['delta']),"df")
chi.square.critical.value <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
table <- as.data.frame(cbind(Model,chi.square,df,chi.square.critical.value,"pvalue"))
colnames(table)[2] <- c(paste0(greeks['chi']))
colnames(table)[3] <- c("df")
colnames(table)[4] <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
colnames(table)[5] <- c("p value")

#Convert collumns 2 through 4 to numeric.
table$χ <- as.numeric(table$χ)    #chi-square
table$df <- as.numeric(table$df)  #df
table$`χ^2^ critical value; 0.05` <- as.numeric(table$`χ^2^ critical value; 0.05`)  #critical-value
table$`p value` <- as.numeric(table$`p value`)

#Insert stats
#Chi-square difference
table[1,2]<- abs(table2$`χ^2`[2] - table2$`χ^2`[3])
table[2,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[4])
table[3,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[5])
table[4,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[6])
table[5,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[7])
table[6,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[8])
table[7,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[9])

#df difference
table[1,3]<- abs(table2$df[2] - table2$df[3])
table[2,3]<- abs(table2$df[3] - table2$df[4])
table[3,3]<- abs(table2$df[3] - table2$df[5])
table[4,3]<- abs(table2$df[3] - table2$df[6])
table[5,3]<- abs(table2$df[3] - table2$df[7])
table[6,3]<- abs(table2$df[3] - table2$df[8])
table[7,3]<- abs(table2$df[3] - table2$df[9])

#chi-square critical value
table[1,4]<- round(qchisq(.05, table$df[1], lower.tail=FALSE), digits = 2)
table[2,4]<- round(qchisq(.05, table$df[2], lower.tail=FALSE), digits = 2)
table[3,4]<- round(qchisq(.05, table$df[3], lower.tail=FALSE), digits = 2)
table[4,4]<- round(qchisq(.05, table$df[4], lower.tail=FALSE), digits = 2)
table[5,4]<- round(qchisq(.05, table$df[5], lower.tail=FALSE), digits = 2)
table[6,4]<- round(qchisq(.05, table$df[6], lower.tail=FALSE), digits = 2)
table[7,4]<- round(qchisq(.05, table$df[7], lower.tail=FALSE), digits = 2)

#p value
table[1,5]<- pvalr(pchisq(table$χ[1], table$df[1], lower.tail=FALSE), digits = 2)
table[2,5]<- pvalr(pchisq(table$χ[2], table$df[2], lower.tail=FALSE), digits = 2)
table[3,5]<- pvalr(pchisq(table$χ[3], table$df[3], lower.tail=FALSE), digits = 2)
table[4,5]<- pvalr(pchisq(table$χ[4], table$df[4], lower.tail=FALSE), digits = 2)
table[5,5]<- pvalr(pchisq(table$χ[5], table$df[5], lower.tail=FALSE), digits = 2)
table[6,5]<- pvalr(pchisq(table$χ[6], table$df[6], lower.tail=FALSE), digits = 2)
table[7,5]<- pvalr(pchisq(table$χ[7], table$df[7], lower.tail=FALSE), digits = 2)

#Relable table to table 3.
table3 <- table

#Factor loadings table for Method U.
PT <- inspect(methodu, what = "std")
PT.Remedied <- PT[["0"]][["lambda"]]
PT.NonRemedied <- PT[["1"]][["lambda"]]
##Organize cells
###Remedied
PTR.p <- round(as.data.frame(PT.Remedied[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.i <- round(as.data.frame(PT.Remedied[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.oi <- round(as.data.frame(PT.Remedied[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.oo <- round(as.data.frame(PT.Remedied[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Remedied)"
PT.Remedied <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.Remedied$residualsr <- round(1-(PT.Remedied$`Substantive Factor Loading (Remedied)`^2+PT.Remedied$`Method Factor Loading (Remedied)`^2), digits = 2)

#Non-Remedied
PTR.p <- round(as.data.frame(PT.NonRemedied[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.i <- round(as.data.frame(PT.NonRemedied[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.oi <- round(as.data.frame(PT.NonRemedied[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.oo <- round(as.data.frame(PT.NonRemedied[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PT.NonRemedied <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.NonRemedied$residualsnr <- round(1-(PT.NonRemedied$`Substantive Factor Loading (Non-Remedied)`^2 + PT.NonRemedied$`Method Factor Loading (Non-Remedied)`^2), digits = 2)
#Combine
PT.full <- cbind(PT.Remedied,PT.NonRemedied)
#Make PT.full all positive to avoid calculation issues
PT.full <- abs(PT.full)

#Method and substantive reliability table.
Model <- c("Proactive Personality", "In-Role Behavior", "Org. Citizenship Behavior (Org.)", "Org. Citizenship Behavior (Ind.)", "Positive Affectivity")
table <- as.data.frame(cbind(Model,"V1","V2","V3","V4","V5","V6","V7","V8"))
colnames(table)[1] <- c("Latent Variable")
colnames(table)[2] <- c("Total Reliability (Remedied)")
colnames(table)[3] <- c("Substantive Reliability (Remedied)")
colnames(table)[4] <- c("Method Reliability (Remedied)")
colnames(table)[5] <- c("% Reliable Method Variance (Remedied)")
colnames(table)[6] <- c("Total Reliability (Non-Remedied)")
colnames(table)[7] <- c("Substantive Reliability (Non-Remedied)")
colnames(table)[8] <- c("Method Reliability (Non-Remedied)")
colnames(table)[9] <- c("% Reliable Method Variance (Non-Remedied)")

#Convert collumns 2 through 5 to numeric.
table$`Total Reliability (Remedied)` <- as.numeric(table$`Total Reliability (Remedied)`)
table$`Substantive Reliability (Remedied)` <- as.numeric(table$`Substantive Reliability (Remedied)`)
table$`Method Reliability (Remedied)` <- as.numeric(table$`Method Reliability (Remedied)`)
table$`% Reliable Method Variance (Remedied)` <- as.numeric(table$`% Reliable Method Variance (Remedied)`)
table$`Total Reliability (Non-Remedied)` <- as.numeric(table$`Total Reliability (Non-Remedied)`)
table$`Substantive Reliability (Non-Remedied)` <- as.numeric(table$`Substantive Reliability (Non-Remedied)`)
table$`Method Reliability (Non-Remedied)` <- as.numeric(table$`Method Reliability (Non-Remedied)`)
table$`% Reliable Method Variance (Non-Remedied)` <- as.numeric(table$`% Reliable Method Variance (Non-Remedied)`)

#Insert stats

##Substantive Reliability: Remedied
table[1,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[2,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[3,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[4,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Remedied
table[1,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[2,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[3,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[4,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Remedied
table[1,2] <- sum(table[1,3],table[1,4])
table[2,2] <- sum(table[2,3],table[2,4])
table[3,2] <- sum(table[3,3],table[3,4])
table[4,2] <- sum(table[4,3],table[4,4])

##% Reliable Method Variance: Remedied
table[1,5] <- round(table[1,4]/table[1,2], digits = 2)
table[2,5] <- round(table[2,4]/table[2,2], digits = 2)
table[3,5] <- round(table[3,4]/table[3,2], digits = 2)
table[4,5] <- round(table[4,4]/table[4,2], digits = 2)

##Substantive Reliability: Non-Remedied
table[1,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2) + sum(PT.full$residualsnr[1:10])), digits = 2)
table[2,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2) + sum(PT.full$residualsnr[11:17])), digits = 2)
table[3,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2) + sum(PT.full$residualsnr[18:24])), digits = 2)
table[4,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2) + sum(PT.full$residualsnr[25:31])), digits = 2)

##Method Reliability: Non-Remedied
table[1,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2) + sum(PT.full$residualsnr[1:10])), digits = 2)
table[2,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2) + sum(PT.full$residualsnr[11:17])), digits = 2)
table[3,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2) + sum(PT.full$residualsnr[18:24])), digits = 2)
table[4,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2) + sum(PT.full$residualsnr[25:31])), digits = 2)

##Total Reliability: Non-Remedied
table[1,6] <- sum(table[1,7],table[1,8])
table[2,6] <- sum(table[2,7],table[2,8])
table[3,6] <- sum(table[3,7],table[3,8])
table[4,6] <- sum(table[4,7],table[4,8])

##% Reliable Method Variance: Non-Remedied
table[1,9] <- round(table[1,8]/table[1,6], digits = 2)
table[2,9] <- round(table[2,8]/table[2,6], digits = 2)
table[3,9] <- round(table[3,8]/table[3,6], digits = 2)
table[4,9] <- round(table[4,8]/table[4,6], digits = 2)

#Insert PA data.
table[5,2] <- round(PA.alpha, digits = 2)
table[5,3] <- round(PA.alpha, digits = 2)
table[5,4] <- 0
table[5,5] <- NA
table[5,6] <- round(PA.alpha, digits = 2)
table[5,7] <- round(PA.alpha, digits = 2)
table[5,8] <- 0
table[5,9] <- NA

#Relable table to table 4.
table4 <- table
```
  Descriptive statistics for study variables can be found in table 1. 
  
 
```{r Table 1 Descriptives Study 1, include = TRUE}
table1 <- apa.cor.table(scales)
```
```{r Table 2 Model-Data Fit Study 1, include = TRUE}
table2
```
```{r Table 3 Model-Comparison Table Study 1, include = TRUE}
table3
```
```{r Table 4 Variance Decomposition Study 1, include = TRUE}
table4
```

  The results of our tests and model comparisons are available in table x. The model data fit for our baseline models (i.e., models without method effects included) were generally unacceptable, which is common when method effects have not been modeled [see @WilliamsMethodVarianceMarker2010]. As can be seen, modeling method effects improved the fit of the model to the data relative to baseline levels. The best-fitting method effect models were the most flexible with some consistency to both substantive and method effects in terms of direction and magnitude. Across all models, the predictor-criterion relationships were positive. The series of model comparisons consistently (as in across conditions) revealed congeneric (unequal) method effects attributable to positive affectivity, negative affectivity, mood, and negative item wording. However, consistency motif effects were observed in the non-remedied condition for two of the OCBO parcels. While this does suggest that consistency motifs played a role in our non-remedied condition, and were absent in the remedied condition, the magnitude of these effects seem negligible. In fact, overall tests for method bias in the control condition failed to support method bias attributable to all method variance sources. Additionally, as expected, a blocking factor emerged in the remedied condition and exerted a constant effect on the measured variables for our criteria. Further testing revealed that all method effects in the remedied condition were enough to bias the observed correlations and that once these method effects were modeled, the proactive personality-role behavior relationships became non-significant. All other substantive effects were reduced in magnitude. The magnitude and direction of all method effects can be observed in table x. 

  Table z displays the decomposed reliabilities of each scale as a function of substantive and method variance and also lists the percentage of overall method variance attributable to these different sources. As can be seen, there were multiple sources of method variance evident in our measurement model. Consistently, positive affectivity exerted an influence over responses to measures of proactive personality, voice, taking charge, in-role behavior, and OCBI. For OCBO, which was primarily method variance (63% in the control vs. 74% in the remedied condition), multiple method sources were present. 

#Discussion Study 1
  With our first study, we examined the role played by multiple sources of method variance (i.e., consistency motif, measurement context, affectivity, negative item wording, and measurement context). More specifically, we tested experimentally proximal remedies for method variance, allowing us to test the causal role played by the targets of proximal causes of method variance in a realistic research setting. Additionally, following guidance from method variance reserachers [@PodsakoffCommonmethodbiases2003; @SpectorNewPerspectiveMethod2017; @WilliamsFourResearchDesigns2016; @WilliamsMethodVarianceMarker2010], we examined a variety of other alternative methodological explainations for our substantive hypotheses, allowing us to estimate the magnitude of proximal causal effects of method variance.   

  Generally speaking, our results cast doubt onto the strength of consistency motifs and provide mixed support for measurement context effects. For consistency motifs, we observered that they played stronger role in our non-remedied condition compared to our remedied condition, but lacked the potency for causing method bias in this condition. Consistency motifs were absent in our remedied condition. This suggests that our treatment (e.g., a cover story) weakens consistency motifs. Specifically, we found only two significant effects (p < .05) linking consistency motif scores to our parcels. Though this was in the expected direction (i.e., increasing consistency) and in the expected condition (non-remedied), their magnitude was small and ultimately negligible (factor loadings = .13 and .14). These effects were not observed in our remedied condition. Therefore, our findings call into question the potency of consistency motifs as a cause of method bias.

#Study 2 - Efficacy of Individual Proximal Remedies
  With this study, we examined the efficacy of individual proximal remeides for method variance.^[A friendly reviewer, Alyssa McGonagle, recommended that we pursue this course of action.] In other words, the same measurement model was run but individuals were randomly assigned to receive one of the proximal remedies tested in study 1: either (a) a cover story, (b) randomized items, (c) randomized scales, (d) a set of filler scales, or were randomly assigned to a conrol condition whereby no remeides were applied. This allowed us to isolate the effects of specific remedies. 
##Methods - Study 2
##Sample and Procedure
```{r Load Study 2 Data, message = FALSE, warning = FALSE}
data <- read_sav("Datasets/Study 2.sav")
N <- as.numeric(nrow(data))

#Count of individuals who agree to participate.
N1 <- as.numeric(freq_vect(data$IC1)[1,"Count"])  #Control
N2 <- as.numeric(freq_vect(data$IC2)[1,"Count"])  #Coverstory
N3 <- as.numeric(freq_vect(data$IC3)[1,"Count"])  #Randomized Scales
N4 <- as.numeric(freq_vect(data$FOR4)[1,"Count"]) #Randomized Items Within Scales
N5 <- as.numeric(freq_vect(data$FOR5)[1,"Count"]) #Filler Scales Used
Nall <- sum(N1,N2,N3,N4,N5)

#Recode consent and manipulation check so that only those who passed have their data examined. 
data$IC1[data$IC1 =="I Agree"] <- 1
data$IC2[data$IC2 =="I Agree"] <- 1
data$IC3[data$IC3 =="I Agree"] <- 1
data$FOR4[data$FOR4 =="I Agree"] <- 1
data$FOR5[data$FOR5 =="I Agree"] <- 1

#Subset in those who Likertd to participate.
Likert <- subset(data, IC1 == "1" & Dupe1 == "1" | IC2 == "1" & Dupe1 == "2" | IC3 == "1" & Dupe1 == "1" | FOR4 == "1" & Dupe1 == "1" |  FOR5 == "1" & Dupe1 == "1")

#Delete cases who did not complete the didn't complete the demographic questionnaire.
Likert <- Likert[-c(116,418:421),]

#Get success rates (SR) for responding correctly across both conditions.
n1 <- as.numeric(freq_vect(Likert$IC1)[1,"Count"])  #Control
n2 <- as.numeric(freq_vect(Likert$IC2)[1,"Count"])  #Coverstory
n3 <- as.numeric(freq_vect(Likert$IC3)[1,"Count"])  #Randomized Scales
n4 <- as.numeric(freq_vect(Likert$FOR4)[1,"Count"]) #Randomized Items Within Scales
n5 <- as.numeric(freq_vect(Likert$FOR5)[1,"Count"]) #Filler Scales Used
n <- n1+n2+n2+n4+n5
sr1 <- n1/N1
sr2 <- n2/N2
sr3 <- n3/N3
sr4 <- n4/N4
sr5 <- n5/N5
srall <- n/(N1+N2+N3+N4+N5)

##Collapse like data across columns.
###Conditions; build independent data sets and then rename the condition variable.
###1 Control
Likert$`Demand&ConsitMotif1`[is.na(Likert$`Demand&ConsitMotif1`)] <- 0
Likert$`Demand&ConsitMotif1` <- as.numeric(Likert$`Demand&ConsitMotif1`)
###2 Cover Story Manipulation
Likert$CoverStoryManip <- ifelse(Likert$CoverStoryManip == 1, c("2"))
Likert$CoverStoryManip[is.na(Likert$CoverStoryManip)] <- 0
Likert$CoverStoryManip <- as.numeric(Likert$CoverStoryManip)
###3 Randomized Items
Likert$`Demand&ConsitMotif3` <- ifelse(Likert$`Demand&ConsitMotif3` == 1, c("3"))
Likert$`Demand&ConsitMotif3`[is.na(Likert$`Demand&ConsitMotif3`)] <- 0
Likert$`Demand&ConsitMotif3` <- as.numeric(Likert$`Demand&ConsitMotif3`)
###4 Filler Scales
Likert$`Demand&ConsitMotif4` <- ifelse(Likert$`Demand&ConsitMotif4` == 1, c("4"))
Likert$`Demand&ConsitMotif4`[is.na(Likert$`Demand&ConsitMotif4`)] <- 0
Likert$`Demand&ConsitMotif4` <- as.numeric(Likert$`Demand&ConsitMotif4`)
###5 Randomized Scales
Likert$`Demand&ConsitMotif2` <- ifelse(Likert$`Demand&ConsitMotif2` == 1, c("5"))
Likert$`Demand&ConsitMotif2`[is.na(Likert$`Demand&ConsitMotif2`)] <- 0
Likert$`Demand&ConsitMotif2` <- as.numeric(Likert$`Demand&ConsitMotif2`)
#Combine condition Likert into single variable column
Likert$COND <- Likert$`Demand&ConsitMotif1` + Likert$CoverStoryManip + Likert$`Demand&ConsitMotif3` + Likert$`Demand&ConsitMotif4` + Likert$`Demand&ConsitMotif2`
#Apply value lables
Likert$COND <- factor(Likert$COND, levels = c(1,2,3,4,5), labels = c("Control", "CSManipulation","ItemRand","FillerScales","ScaleRand"))

#Consolidate item response measures
##Form Likert datasets, re-lable values, convert to numeric data, consolidate measures, and delete data.
agree <- Likert[c(11:50,82:121,153:192,224:235,261:288,295:334)]
agree <- ifelse(agree == "Strongly Disagree", 1, ifelse(agree == "Disagree", 2, ifelse(agree == "Neither Agree nor Disagree", 3, ifelse(agree == "Agree", 4, ifelse(agree == "Strongly Agree", 5,0)))))
agree <- as.data.frame(agree)
agree[is.na(agree)] <- 0

#####Proactive Personality 
agree$PP1	<-	agree$PP1_1	+	agree$PP2_1	+	agree$PP5_1	+	agree$PP6_1	+	agree$PPx_1
agree$PP2	<-	agree$PP1_2	+	agree$PP2_2	+	agree$PP5_2	+	agree$PP6_2	+	agree$PPx_2
agree$PP3	<-	agree$PP1_3	+	agree$PP2_3	+	agree$PP5_3	+	agree$PP6_3	+	agree$PPx_3
agree$PP4	<-	agree$PP1_4	+	agree$PP2_4	+	agree$PP5_4	+	agree$PP6_4	+	agree$PPx_4
agree$PP5	<-	agree$PP1_5	+	agree$PP2_5	+	agree$PP5_5	+	agree$PP6_5	+	agree$PPx_5
agree$PP6	<-	agree$PP1_6	+	agree$PP2_6	+	agree$PP5_6	+	agree$PP6_6	+	agree$PPx_6
agree$PP7	<-	agree$PP1_7	+	agree$PP2_7	+	agree$PP5_7	+	agree$PP6_7	+	agree$PPx_7
agree$PP8	<-	agree$PP1_8	+	agree$PP2_8	+	agree$PP5_8	+	agree$PP6_8	+	agree$PPx_8
agree$PP9	<-	agree$PP1_9	+	agree$PP2_9	+	agree$PP5_9	+	agree$PP6_9	+	agree$PPx_9
agree$PP10	<-	agree$PP1_10	+	agree$PP2_10	+	agree$PP5_10	+	agree$PP6_10	+	agree$PPx_10
#####OCBI
agree$OCBI1	<-	agree$OCBI1_1	+	agree$OCBI2_1	+	agree$OCBI5_1	+	agree$OCBI6_1	+	agree$OCBIx_1
agree$OCBI2	<-	agree$OCBI1_3	+	agree$OCBI2_3	+	agree$OCBI5_3	+	agree$OCBI6_3	+	agree$OCBIx_3
agree$OCBI3	<-	agree$OCBI1_4	+	agree$OCBI2_4	+	agree$OCBI5_4	+	agree$OCBI6_4	+	agree$OCBIx_4
agree$OCBI4	<-	agree$OCBI1_5	+	agree$OCBI2_5	+	agree$OCBI5_5	+	agree$OCBI6_5	+	agree$OCBIx_5
agree$OCBI5	<-	agree$OCBI1_6	+	agree$OCBI2_6	+	agree$OCBI5_6	+	agree$OCBI6_6	+	agree$OCBIx_6
agree$OCBI6	<-	agree$OCBI1_7	+	agree$OCBI2_7	+	agree$OCBI5_7	+	agree$OCBI6_7	+	agree$OCBIx_7
agree$OCBI7	<-	agree$OCBI1_8	+	agree$OCBI2_8	+	agree$OCBI5_8	+	agree$OCBI6_8	+	agree$OCBIx_8
#####OCBO
agree$OCBO1	<-	agree$OCBO1_1	+	agree$OCBO2_1	+	agree$OCBO5_1	+	agree$OCBO6_1	+	agree$OCBOx_1
agree$OCBO2	<-	agree$OCBO1_2	+	agree$OCBO2_2	+	agree$OCBO5_2	+	agree$OCBO6_2	+	agree$OCBOx_2
agree$OCBO3	<-	agree$OCBO1_3	+	agree$OCBO2_3	+	agree$OCBO5_3	+	agree$OCBO6_3	+	agree$OCBOx_3
agree$OCBO4	<-	agree$OCBO1_5	+	agree$OCBO2_5	+	agree$OCBO5_5	+	agree$OCBO6_5	+	agree$OCBOx_5
agree$OCBO5	<-	agree$OCBO1_6	+	agree$OCBO2_6	+	agree$OCBO5_6	+	agree$OCBO6_6	+	agree$OCBOx_6
agree$OCBO6	<-	agree$OCBO1_7	+	agree$OCBO2_7	+	agree$OCBO5_7	+	agree$OCBO6_7	+	agree$OCBOx_7
agree$OCBO7	<-	agree$OCBO1_8	+	agree$OCBO2_8	+	agree$OCBO5_8	+	agree$OCBO6_8	+	agree$OCBOx_8
#####IRB
agree$IRB1	<-	agree$IRB1_1	+	agree$IRB2_1	+	agree$IRB5_1	+	agree$IRB6_1	+	agree$IRBx_1
agree$IRB2	<-	agree$IRB1_3	+	agree$IRB2_3	+	agree$IRB5_3	+	agree$IRB6_3	+	agree$IRBx_3
agree$IRB3	<-	agree$IRB1_4	+	agree$IRB2_4	+	agree$IRB5_4	+	agree$IRB6_4	+	agree$IRBx_4
agree$IRB4	<-	agree$IRB1_5	+	agree$IRB2_5	+	agree$IRB5_5	+	agree$IRB6_5	+	agree$IRBx_5
agree$IRB5	<-	agree$IRB1_6	+	agree$IRB2_6	+	agree$IRB5_6	+	agree$IRB6_6	+	agree$IRBx_6
agree$IRB6	<-	agree$IRB1_8	+	agree$IRB2_8	+	agree$IRB5_8	+	agree$IRB6_8	+	agree$IRBx_8
agree$IRB7	<-	agree$IRB1_9	+	agree$IRB2_9	+	agree$IRB5_9	+	agree$IRB6_9	+	agree$IRBx_9
#####Inattentive Responding
agree$IR	<-	agree$PP1_11	+	agree$PP2_11	+	agree$PP5_11	+	agree$PP6_11	+	agree$PPx_11
#####Consistency Motif
#Brave
agree$CM1	<-	agree$PP1_12	+	agree$PP2_12	+	agree$PP5_12	+	agree$PP6_12	+	agree$PPx_12
#Courageous
agree$CM2	<-	agree$IRB1_2	+	agree$IRB2_2	+	agree$IRB5_2	+	agree$IRB6_2	+	agree$IRBx_2
#Talkative
agree$CM3	<-	agree$OCBI1_9	+	agree$OCBI2_9	+	agree$OCBI5_9	+	agree$OCBI6_9	+	agree$OCBIx_9
#Silent Person
agree$CM4	<-	agree$OCBO1_9	+	agree$OCBO2_9	+	agree$OCBO5_9	+	agree$OCBO6_9	+	agree$OCBOx_9
#Optimistic 
agree$CM5	<-	agree$IRB1_7	+	agree$IRB2_7	+	agree$IRB5_7	+	agree$IRB6_7	+	agree$IRBx_7
#Pessimistic Person
agree$CM6	<-	agree$OCBO1_4	+	agree$OCBO2_4	+	agree$OCBO5_4	+	agree$OCBO6_4	+	agree$OCBOx_4
#Seldom feel blue.
agree$CM7	<-	agree$IRB1_10	+	agree$IRB2_10	+	agree$IRB5_10	+	agree$IRB6_10	+	agree$IRBx_10
#Often feel blue.
agree$CM8	<-	agree$OCBI1_2	+	agree$OCBI2_2	+	agree$OCBI5_2	+	agree$OCBI6_2	+	agree$OCBIx_2
#Consolidate agree data
agree <- agree[c(201:231,233:240)]

#PANAS
PANAS <- Likert[c(55:74,126:145,197:216,240:259,339:358)]
PANAS <- ifelse(PANAS == "Very slightly or not at all", 1, ifelse(PANAS == "A little", 2, ifelse(PANAS == "Moderately", 3, ifelse(PANAS == "Quite a bit", 4, ifelse(PANAS == "Extremely", 5, 0)))))
PANAS <- as.data.frame(PANAS)
PANAS[is.na(PANAS)] <- 0
PANAS$PA1	<-	PANAS$PAff1_1	+	PANAS$PAff2_1	+	PANAS$PAff5_1	+	PANAS$PAff6_1	+	PANAS$PAffx_1
PANAS$PA2	<-	PANAS$PAff1_2	+	PANAS$PAff2_2	+	PANAS$PAff5_2	+	PANAS$PAff6_2	+	PANAS$PAffx_2
PANAS$PA3	<-	PANAS$PAff1_3	+	PANAS$PAff2_3	+	PANAS$PAff5_3	+	PANAS$PAff6_3	+	PANAS$PAffx_3
PANAS$PA4	<-	PANAS$PAff1_4	+	PANAS$PAff2_4	+	PANAS$PAff5_4	+	PANAS$PAff6_4	+	PANAS$PAffx_4
PANAS$PA5	<-	PANAS$PAff1_5	+	PANAS$PAff2_5	+	PANAS$PAff5_5	+	PANAS$PAff6_5	+	PANAS$PAffx_5
PANAS$PA6	<-	PANAS$PAff1_6	+	PANAS$PAff2_6	+	PANAS$PAff5_6	+	PANAS$PAff6_6	+	PANAS$PAffx_6
PANAS$PA7	<-	PANAS$PAff1_7	+	PANAS$PAff2_7	+	PANAS$PAff5_7	+	PANAS$PAff6_7	+	PANAS$PAffx_7
PANAS$PA8	<-	PANAS$PAff1_8	+	PANAS$PAff2_8	+	PANAS$PAff5_8	+	PANAS$PAff6_8	+	PANAS$PAffx_8
PANAS$PA9	<-	PANAS$PAff1_9	+	PANAS$PAff2_9	+	PANAS$PAff5_9	+	PANAS$PAff6_9	+	PANAS$PAffx_9
PANAS$PA10	<-	PANAS$PAff1_10	+	PANAS$PAff2_10	+	PANAS$PAff5_10	+	PANAS$PAff6_10	+	PANAS$PAffx_10
PANAS$NA1	<-	PANAS$NAff1_1	+	PANAS$NAff2_1	+	PANAS$NAff5_1	+	PANAS$NAff6_1	+	PANAS$NAffx_1
PANAS$NA2	<-	PANAS$NAff1_2	+	PANAS$NAff2_2	+	PANAS$NAff5_2	+	PANAS$NAff6_2	+	PANAS$NAffx_2
PANAS$NA3	<-	PANAS$NAff1_3	+	PANAS$NAff2_3	+	PANAS$NAff5_3	+	PANAS$NAff6_3	+	PANAS$NAffx_3
PANAS$NA4	<-	PANAS$NAff1_4	+	PANAS$NAff2_4	+	PANAS$NAff5_4	+	PANAS$NAff6_4	+	PANAS$NAffx_4
PANAS$NA5	<-	PANAS$NAff1_5	+	PANAS$NAff2_5	+	PANAS$NAff5_5	+	PANAS$NAff6_5	+	PANAS$NAffx_5
PANAS$NA6	<-	PANAS$NAff1_6	+	PANAS$NAff2_6	+	PANAS$NAff5_6	+	PANAS$NAff6_6	+	PANAS$NAffx_6
PANAS$NA7	<-	PANAS$NAff1_7	+	PANAS$NAff2_7	+	PANAS$NAff5_7	+	PANAS$NAff6_7	+	PANAS$NAffx_7
PANAS$NA8	<-	PANAS$NAff1_8	+	PANAS$NAff2_8	+	PANAS$NAff5_8	+	PANAS$NAff6_8	+	PANAS$NAffx_8
PANAS$NA9	<-	PANAS$NAff1_9	+	PANAS$NAff2_9	+	PANAS$NAff5_9	+	PANAS$NAff6_9	+	PANAS$NAffx_9
PANAS$NA10	<-	PANAS$NAff1_10	+	PANAS$NAff2_10	+	PANAS$NAff5_10	+	PANAS$NAff6_10	+	PANAS$NAffx_10
#Consolidate "PANAS" dataset.
PANAS <- PANAS[c(101:120)]

#Retain only variables used for testing purposes.
data2 <- cbind(Likert[c(379:386,399)],agree,PANAS)
n <- as.numeric(nrow(data2))

#Setup demographics.
#Rename variables.
colnames(data2)[colnames(data2)=="Age"] <- "AGE"
colnames(data2)[colnames(data2)=="Race"] <- "RACE"
colnames(data2)[colnames(data2)=="Gender"] <- "GENDER"
colnames(data2)[colnames(data2)=="Education"] <- "EDUCAT"
colnames(data2)[colnames(data2)=="EmployStat"] <- "EMPLOYED"
colnames(data2)[colnames(data2)=="EmployStatYrs"] <- "JOBTENURE"
colnames(data2)[colnames(data2)=="JobTitle"] <- "PROF_SPECIFY"

#Recode 0 to missing for mice. 
data2$PP1[data2$PP1==0] <- NA
data2$PP2[data2$PP2==0] <- NA
data2$PP3[data2$PP3==0] <- NA
data2$PP4[data2$PP4==0] <- NA
data2$PP5[data2$PP5==0] <- NA
data2$PP6[data2$PP6==0] <- NA
data2$PP7[data2$PP7==0] <- NA
data2$PP8[data2$PP8==0] <- NA
data2$PP9[data2$PP9==0] <- NA
data2$PP10[data2$PP10==0] <- NA
data2$PP1[data2$PP1==0] <- NA
data2$PP2[data2$PP2==0] <- NA
data2$PP3[data2$PP3==0] <- NA
data2$PP4[data2$PP4==0] <- NA
data2$PP5[data2$PP5==0] <- NA
data2$PP6[data2$PP6==0] <- NA
data2$PP7[data2$PP7==0] <- NA
data2$PP8[data2$PP8==0] <- NA
data2$PP9[data2$PP9==0] <- NA
data2$PP10[data2$PP10==0] <- NA
data2$OCBI1[data2$OCBI1==0] <- NA
data2$OCBI2[data2$OCBI2==0] <- NA
data2$OCBI3[data2$OCBI3==0] <- NA
data2$OCBI4[data2$OCBI4==0] <- NA
data2$OCBI5[data2$OCBI5==0] <- NA
data2$OCBI6[data2$OCBI6==0] <- NA
data2$OCBI7[data2$OCBI7==0] <- NA
data2$OCBO1[data2$OCBO1==0] <- NA
data2$OCBO2[data2$OCBO2==0] <- NA
data2$OCBO3[data2$OCBO3==0] <- NA
data2$OCBO4[data2$OCBO4==0] <- NA
data2$OCBO5[data2$OCBO5==0] <- NA
data2$OCBO6[data2$OCBO6==0] <- NA
data2$OCBO7[data2$OCBO7==0] <- NA
data2$IRB1[data2$IRB1==0] <- NA
data2$IRB2[data2$IRB2==0] <- NA
data2$IRB3[data2$IRB3==0] <- NA
data2$IRB3[data2$IRB3==6] <- NA
data2$IRB4[data2$IRB4==0] <- NA
data2$IRB5[data2$IRB5==0] <- NA
data2$IRB6[data2$IRB6==0] <- NA
data2$IRB7[data2$IRB7==0] <- NA
data2$PA1[data2$PA1==0] <- NA
data2$PA2[data2$PA2==0] <- NA
data2$PA3[data2$PA3==0] <- NA
data2$PA4[data2$PA4==0] <- NA
data2$PA5[data2$PA5==0] <- NA
data2$PA6[data2$PA6==0] <- NA
data2$PA7[data2$PA7==0] <- NA
data2$PA8[data2$PA8==0] <- NA
data2$PA9[data2$PA9==0] <- NA
data2$PA10[data2$PA10==0] <- NA
data2$NA1[data2$NA1==0] <- NA
data2$NA2[data2$NA2==0] <- NA
data2$NA3[data2$NA3==0] <- NA
data2$NA4[data2$NA4==0] <- NA
data2$NA5[data2$NA5==0] <- NA
data2$NA6[data2$NA6==0] <- NA
data2$NA7[data2$NA7==0] <- NA
data2$NA8[data2$NA8==0] <- NA
data2$NA9[data2$NA9==0] <- NA
data2$NA10[data2$NA10==0] <- NA
data2$CM1[data2$CM1==0] <- NA
data2$CM2[data2$CM2==0] <- NA
data2$CM3[data2$CM3==0] <- NA
data2$CM4[data2$CM4==0] <- NA
data2$CM5[data2$CM5==0] <- NA
data2$CM6[data2$CM6==0] <- NA
data2$CM7[data2$CM7==0] <- NA
data2$CM8[data2$CM8==0] <- NA

#Missing data analysis using 'sapply(data2, function(x) sum(is.na(x)))' revealed some missing likert data. 
init <- mice(data2[c(-8)], maxit = 0)
meth <- init$method
predM <- init$predictorMatrix
meth[c("IRB3")]="norm"
meth[c("NA3")]="norm"
imputed <- mice(data2[c(-8)], method=meth, predictorMatrix=predM, m=5)
data2 <- complete(imputed)
#Round imputed data to nearest whole number for estimation purposes. 
data2$IRB3 <- ceiling(data2$IRB3)
data2$NA3 <- ceiling(data2$NA3)

#Calculate descriptives
M <- mean(data2$AGE, na.rm = TRUE)
SD <- sd(data2$AGE, na.rm = TRUE)

#Calculate frequencies
##Recode single "f" to female. 
#data2$GENDER[data2$GENDER=="f"] <- 1
female.n <- as.numeric(freq_vect(data2$GENDER)[1,"Count"])
female.p <- as.numeric(freq_vect(data2$GENDER)[1,"Percentage"])
white.n <- as.numeric(freq_vect(data2$RACE)[7,"Count"])
white.p <- as.numeric(freq_vect(data2$RACE)[7,"Percentage"])
fulltime.n <- as.numeric(freq_vect(data2$EMPLOYED)[3,"Count"])
fulltime.p <- as.numeric(freq_vect(data2$EMPLOYED)[3,"Percentage"])

#Note: certain response categories are too few for the estimator to work.  Specifically, the "strongly disagree" and "disagree" response options were simply combined to reflect a "disagree" option. So I combined them:
data2$PA9[data2$PA9==1] <- 2
data2$NA9[data2$NA9==5] <- 4
data2$NA7[data2$NA7==5] <- 4
data2$NA8[data2$NA8==5] <- 4
data2$NA10[data2$NA10==5] <- 4
data2$PP2[data2$PP2==1] <- 2
data2$PP3[data2$PP3==1] <- 2
data2$PP5[data2$PP5==1] <- 2
data2$PP6[data2$PP6==1] <- 2
data2$PP7[data2$PP7==1] <- 2
data2$PP8[data2$PP8==1] <- 2
data2$PP10[data2$PP10==1] <- 2
data2$IRB1[data2$IRB1==1] <- 2
data2$IRB2[data2$IRB2==1] <- 2
data2$IRB2[data2$IRB2==2] <- 3
data2$IRB3[data2$IRB3==1] <- 2
data2$IRB3[data2$IRB3==2] <- 3
data2$IRB4[data2$IRB4==2] <- 3
data2$IRB6[data2$IRB6==5] <- 4
data2$OCBI1[data2$OCBI1==1] <- 2
data2$OCBI2[data2$OCBI2==1] <- 2
data2$OCBI3[data2$OCBI3==1] <- 2
data2$OCBI4[data2$OCBI4==1] <- 2
data2$OCBI5[data2$OCBI5==1] <- 2
data2$OCBI7[data2$OCBI7==1] <- 2
data2$OCBI7[data2$OCBI7==2] <- 3
data2$OCBO1[data2$OCBO1==1] <- 2
data2$OCBO2[data2$OCBO2==1] <- 2
data2$OCBO3[data2$OCBO3==5] <- 4
data2$OCBO5[data2$OCBO5==5] <- 4
data2$OCBO7[data2$OCBO7==1] <- 2
```
  Among the `r apa(N,0,T)` workers from Amazon's Mechanical Turk who considered participating in our study, `r apa(Nall,0,T)` consented to participating in our study. These `r apa(Nall,0,T)` participants were randomly assigned to one of five conditions: a control or non-remedied condition (n = `r apa(N1,0,T)`), a condition where a cover story was used to blind the purpose of the study (n = `r apa(N2,0,T)`), a condition where scale order was randomized (n = `r apa(N3,0,T)`), a condition where items within scales were randomized (n = `r apa(N4,0,T)`), or a condition wherein filler scales were employed (n = `r apa(N5,0,T)`). Respondents who incorrectly responded to an attention check item were excluded from the survey during administration and so their data were not collected. Five more cases were removed for failing to report demographics and abandoning the survey. The rates for successfully passing our manipulation check for the study purpose were between `r apa(sr5,2,T)` and `r apa(sr4,2,T)` with an overall success rate of `r apa(srall,2,T` and were much higher than study 1. ^[Our relatively higher success rates, compared to study 1, can be attributed tentatively to our using both a video to communicate the purpose of the survey and/or requiring participants to restate the purpose of our study in their own terms in wriitng prior to participating in our study.] This filtering process resulted in a final sample of `r apa(n1,0,T)` individuals in the control condition, `r apa(n2,0,T)` in the coverstory condition, `r apa(n3,0,T)` in the randomized scales condition, `r apa(n4,0,T)` in the randomized items within scales condition, and `r apa(n5,0,T)` in the filler scales condition. Notwithstanding missing demographic data, the sample was female biased (n = `r apa(female.n,0,T)`, `r apa(female,2,T)`), predominantly Caucasian, and  the average age was *M* = `r apa(M,2,T)` (*SD* = `r apa(SD,2,T)`).  The majority (n = `r apa(fulltime.n,0,T)`, *f* = `r apa(fulltime.p,2,T)`) of respondents worked full-time. The same measures used in study 1 and 2 were used in study 3. Cronbach alphas ranged from `r apa(OCBO.alpha)` for OCBO to `r apa(NA.alpha)` for negative affectivity. Again, cases of missing item level data were handled using the normal model approach [see @WuComparisonImputationStrategies2015]. The same measurement model used in study 1 was again tested in study 2. Cronbach alphas ranged from `r apa(OCBO.alpha)` for OCBO to `r apa(IRB.alpha)` for IRB. 
```{r Cronbach Alphas, include = FALSE}
rm(list=setdiff(ls(),"data2"))
#Create scale scores
my.keys.list <- list(PP=c("PP1","PP2","PP3","PP4","PP5","PP6","PP7","PP8","PP9","PP10"),
                     IRB=c("IRB1","IRB2","IRB3","IRB4","IRB5","-IRB6","-IRB7"),
                     OCBI=c("OCBI1","OCBI2","OCBI3","OCBI4","OCBI5","OCBI6","OCBI7"),
                     OCBO=c("OCBO1","OCBO2","-OCBO3","-OCBO4","-OCBO5","OCBO6","OCBO7"),
                     PA=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10"),
                     Na=c("NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     AP=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10","NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     CM=c("CM1","CM2","CM3","-CM4","CM5","-CM6","CM7","-CM8"),
                     NIW=c("IRB6","IRB7","OCBO3","OCBO4","OCBO5"))
my.scales <- scoreItems(my.keys.list,data2)
PP.alpha <- my.scales[["alpha"]][1]
IRB.alpha <- my.scales[["alpha"]][2]
OCBI.alpha <- my.scales[["alpha"]][3]
OCBO.alpha <- my.scales[["alpha"]][4]
PA.alpha <- my.scales[["alpha"]][5]
Na.alpha <- my.scales[["alpha"]][6]
AP.alpha <- my.scales[["alpha"]][7]
CM.alpha <- my.scales[["alpha"]][8]
NIW.alpha <- my.scales[["alpha"]][9]
```
##Results - Study 2
```{r Descriptive Statistics, include=FALSE}
#Create Descriptives Table
scales <- my.scales[["scores"]]
scales <- cbind(data2[c(1,2,4,5)],scales)
scales <- scales[c(1:9)]
```
```{r Multi-Proximal Separation Substantive Analyses, include=FALSE}
method.cfa <- '
#Method factors
  PA =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 
  Na =~ NA*NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10
  AP =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 + NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10

#set covariances for bifactor to zero
  PA ~~ 0*Na
  PA ~~ 0*AP
  Na ~~ 0*AP

#set variances to be 1.
  PA ~~ 1*PA
  Na ~~ 1*Na
  AP ~~ 1*AP

#Factor means of the first group are fixed as 0. The factor means of the other groups are freely estimated. 
##Method factors
  PA ~ 0
  Na ~ 0
  AP ~ 0
'

#To see the results of an anlysis of the discriminant validity of the measurement model, see the following object. 
method <- cfa(model = method.cfa, data = data2, parameterization = "theta", estimator = "dwls", information = "expected")
#Get method factor scores
df <- predict(method)

#bind to dataframe
data2 <- cbind(data2,df)

##Model 1 <- Initial Model
initial.cfa <- '
##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo7c,ocbo7d,ocbo7e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(pppaa,pppab,pppac,pppad,pppae)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(irbpaa,irbpab,irbpac,irbpad,irbpae)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(ocbipaa,ocbipab,ocbipac,ocbipad,ocbipae)*PosAff
OCBO ~~ c(ocbopaa,ocbopab,ocbopac,ocbopad,ocbopae)*PosAff

#Compute factor covariance differences 
ppirbab := ppirba-ppirbb
ppirbac := ppirba-ppirbc
ppirbad := ppirba-ppirbd
ppirbae := ppirba-ppirbe
ppirbbc := ppirbb-ppirbc
ppirbbd := ppirbb-ppirbd
ppirbbe := ppirbb-ppirbe
ppirbcd := ppirbc-ppirbd
ppirbcd := ppirbc-ppirbe
ppirbde := ppirbd-ppirbe
ppocbiab := ppocbia-ppocbib
ppocbiac := ppocbia-ppocbic
ppocbiad := ppocbia-ppocbid
ppocbiae := ppocbia-ppocbie
ppocbibc := ppocbib-ppocbic
ppocbibd := ppocbib-ppocbid
ppocbibe := ppocbib-ppocbie
ppocbicd := ppocbic-ppocbid
ppocbicd := ppocbic-ppocbie
ppocbide := ppocbid-ppocbie
ppocboab := ppocboa-ppocbob
ppocboac := ppocboa-ppocboc
ppocboad := ppocboa-ppocbod
ppocboae := ppocboa-ppocboe
ppocbobc := ppocbob-ppocboc
ppocbobd := ppocbob-ppocbod
ppocbobe := ppocbob-ppocboe
ppocbocd := ppocboc-ppocbod
ppocbocd := ppocboc-ppocboe
ppocbode := ppocbod-ppocboe
pppaab := pppaa-pppab
pppaac := pppaa-pppac
pppaad := pppaa-pppad
pppaae := pppaa-pppae
pppabc := pppab-pppac
pppabd := pppab-pppad
pppabe := pppab-pppae
pppacd := pppac-pppad
pppacd := pppac-pppae
pppade := pppad-pppae
irbocbiab := irbocbia-irbocbib
irbocbiac := irbocbia-irbocbic
irbocbiad := irbocbia-irbocbid
irbocbiae := irbocbia-irbocbie
irbocbibc := irbocbib-irbocbic
irbocbibd := irbocbib-irbocbid
irbocbibe := irbocbib-irbocbie
irbocbicd := irbocbic-irbocbid
irbocbicd := irbocbic-irbocbie
irbocbide := irbocbid-irbocbie
irbocboab := irbocboa-irbocbob
irbocboac := irbocboa-irbocboc
irbocboad := irbocboa-irbocbod
irbocboae := irbocboa-irbocboe
irbocbobc := irbocbob-irbocboc
irbocbobd := irbocbob-irbocbod
irbocbobe := irbocbob-irbocboe
irbocbocd := irbocboc-irbocbod
irbocbocd := irbocboc-irbocboe
irbocbode := irbocbod-irbocboe
irbpaab := irbpaa-irbpab
irbpaac := irbpaa-irbpac
irbpaad := irbpaa-irbpad
irbpaae := irbpaa-irbpae
irbpabc := irbpab-irbpac
irbpabd := irbpab-irbpad
irbpabe := irbpab-irbpae
irbpacd := irbpac-irbpad
irbpacd := irbpac-irbpae
irbpade := irbpad-irbpae
ocbioab := ocbioa-ocbiob
ocbioac := ocbioa-ocbioc
ocbioad := ocbioa-ocbiod
ocbioae := ocbioa-ocbioe
ocbiobc := ocbiob-ocbioc
ocbiobd := ocbiob-ocbiod
ocbiobe := ocbiob-ocbioe
ocbiocd := ocbioc-ocbiod
ocbiocd := ocbioc-ocbioe
ocbiode := ocbiod-ocbioe
ocbipaab := ocbipaa-ocbipab
ocbipaac := ocbipaa-ocbipac
ocbipaad := ocbipaa-ocbipad
ocbipaae := ocbipaa-ocbipae
ocbipabc := ocbipab-ocbipac
ocbipabd := ocbipab-ocbipad
ocbipabe := ocbipab-ocbipae
ocbipacd := ocbipac-ocbipad
ocbipacd := ocbipac-ocbipae
ocbipade := ocbipad-ocbipae
ocbopaab := ocbopaa-ocbopab
ocbopaac := ocbopaa-ocbopac
ocbopaad := ocbopaa-ocbopad
ocbopaae := ocbopaa-ocbopae
ocbopabc := ocbopab-ocbopac
ocbopabd := ocbopab-ocbopad
ocbopabe := ocbopab-ocbopae
ocbopacd := ocbopac-ocbopad
ocbopacd := ocbopac-ocbopae
ocbopade := ocbopad-ocbopae

#Factor means of latent factors for both groups are fixed at zero to allow identification, with the exception of the composite indicators.
##Substantive factors
PP ~ c(0,0,0,0,0)*1
IRB ~ c(0,0,0,0,0)*1
OCBI ~ c(0,0,0,0,0)*1
OCBO ~ c(0,0,0,0,0)*1
'
initial <- cfa(initial.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)

#Model 2: Baseline. Method and substantive covariances are constrained to zero. Method effects are constrained to zero.
baseline.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2+ c(ocbo6a,ocbo6b,ocbo7c,ocbo7d,ocbo7e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
baseline <- cfa(baseline.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(initial, baseline) #As expected, baseline is much worse. 

#Model 3: Method U model. Freely estimate method effects across groups. Tests for the pressence of method effects attributable to a common source of variance. Method effects are allowed to vary across conditions. Note that factor differences in factor loadings and covariances have been computed. This is because (1) subsequent testing revealed that this model was the best fitting method effect model and (2) estimating the size of the differences allowed us to determine which scales and covariances were most affected by proximal causes of method variance. 
methodu.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo6c,ocbo6d,ocbo6e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1b,papp1c,papp1d,papp1e)*PP1 + c(papp2a, papp2b,papp2c,papp2d,papp2e)*PP2 + c(papp3a,papp3b,papp3c,papp3d,papp3e)*PP3 + c(papp4a,papp4b,papp4c,papp4d,papp4e)*PP4 + c(papp5a,papp5b,papp5c,papp5d,papp5e)*PP5 + c(papp6a,papp6b,papp6c,papp6d,papp6e)*PP6 + c(papp7a,papp7b,papp7c,papp7d,papp7e)*PP7 + c(papp8a,papp8b,papp8c,papp8d,papp8e)*PP8 + c(papp9a,papp9b,papp9c,papp9d,papp9e)*PP9 + c(papp10a,papp10b,papp10c,papp10d,papp10e)*PP10 + c(pairb1a,pairb1b,pairb1c,pairb1d,pairb1e)*IRB1 + c(pairb2a,pairb2b,pairb2c,pairb2d,pairb2e)*IRB2 + c(pairb3a,pairb3b,pairb3c,pairb3d,pairb3e)*IRB3 + c(pairb4a,pairb4b,pairb4c,pairb4d,pairb4e)*IRB4 + c(paocbi1a,paocbi1b,paocbi1c,paocbi1d,paocbi1e)*OCBI1 + c(paocbi2a,paocbi2b,paocbi2c,paocbi2d,paocbi2e)*OCBI2 + c(paocbi3a,paocbi3b,paocbi3c,paocbi3d,paocbi3e)*OCBI3 + c(paocbi4a,paocbi4b,paocbi4c,paocbi4d,paocbi4e)*OCBI4 + c(paocbi5a,paocbi5b,paocbi5c,paocbi5d,paocbi5e)*OCBI5 + c(paocbi6a,paocbi6b,paocbi6c,paocbi6d,paocbi6e)*OCBI6 + c(paocbi7a,paocbi7b,paocbi7c,paocbi7d,paocbi7e)*OCBI7 + c(paocbo1a,paocbo1b,paocbo1c,paocbo1d,paocbo1e)*OCBO1 + c(paocbo2a,paocbo2b,paocbo2c,paocbo2d,paocbo2e)*OCBO2 + c(paocbo6a,paocbo6b,paocbo6c,paocbo6d,paocbo6e)*OCBO6 + c(paocbo7a,paocbo7b,paocbo7c,paocbo7d,paocbo7e)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Compute factor loading differences 
pp1ab := pp1a-pp1b
pp1ac := pp1a-pp1c
pp1ad := pp1a-pp1d
pp1ae := pp1a-pp1e
pp1bc := pp1b-pp1c
pp1bd := pp1b-pp1d
pp1be := pp1b-pp1e
pp1cd := pp1c-pp1d
pp1ce := pp1c-pp1e
pp1de := pp1d-pp1e
pp2ab := pp2a-pp2b
pp2ac := pp2a-pp2c
pp2ad := pp2a-pp2d
pp2ae := pp2a-pp2e
pp2bc := pp2b-pp2c
pp2bd := pp2b-pp2d
pp2be := pp2b-pp2e
pp2cd := pp2c-pp2d
pp2ce := pp2c-pp2e
pp2de := pp2d-pp2e
pp3ab := pp3a-pp3b
pp3ac := pp3a-pp3c
pp3ad := pp3a-pp3d
pp3ae := pp3a-pp3e
pp3bc := pp3b-pp3c
pp3bd := pp3b-pp3d
pp3be := pp3b-pp3e
pp3cd := pp3c-pp3d
pp3ce := pp3c-pp3e
pp3de := pp3d-pp3e
pp4ab := pp4a-pp4b
pp4ac := pp4a-pp4c
pp4ad := pp4a-pp4d
pp4ae := pp4a-pp4e
pp4bc := pp4b-pp4c
pp4bd := pp4b-pp4d
pp4be := pp4b-pp4e
pp4cd := pp4c-pp4d
pp4ce := pp4c-pp4e
pp4de := pp4d-pp4e
pp5ab := pp5a-pp5b
pp5ac := pp5a-pp5c
pp5ad := pp5a-pp5d
pp5ae := pp5a-pp5e
pp5bc := pp5b-pp5c
pp5bd := pp5b-pp5d
pp5be := pp5b-pp5e
pp5cd := pp5c-pp5d
pp5ce := pp5c-pp5e
pp5de := pp5d-pp5e
pp6ab := pp6a-pp6b
pp6ac := pp6a-pp6c
pp6ad := pp6a-pp6d
pp6ae := pp6a-pp6e
pp6bc := pp6b-pp6c
pp6bd := pp6b-pp6d
pp6be := pp6b-pp6e
pp6cd := pp6c-pp6d
pp6ce := pp6c-pp6e
pp6de := pp6d-pp6e
pp7ab := pp7a-pp7b
pp7ac := pp7a-pp7c
pp7ad := pp7a-pp7d
pp7ae := pp7a-pp7e
pp7bc := pp7b-pp7c
pp7bd := pp7b-pp7d
pp7be := pp7b-pp7e
pp7cd := pp7c-pp7d
pp7ce := pp7c-pp7e
pp7de := pp7d-pp7e
pp8ab := pp8a-pp8b
pp8ac := pp8a-pp8c
pp8ad := pp8a-pp8d
pp8ae := pp8a-pp8e
pp8bc := pp8b-pp8c
pp8bd := pp8b-pp8d
pp8be := pp8b-pp8e
pp8cd := pp8c-pp8d
pp8ce := pp8c-pp8e
pp8de := pp8d-pp8e
pp9ab := pp9a-pp9b
pp9ac := pp9a-pp9c
pp9ad := pp9a-pp9d
pp9ae := pp9a-pp9e
pp9bc := pp9b-pp9c
pp9bd := pp9b-pp9d
pp9be := pp9b-pp9e
pp9cd := pp9c-pp9d
pp9ce := pp9c-pp9e
pp9de := pp9d-pp9e
pp10ab := pp10a-pp10b
pp10ac := pp10a-pp10c
pp10ad := pp10a-pp10d
pp10ae := pp10a-pp10e
pp10bc := pp10b-pp10c
pp10bd := pp10b-pp10d
pp10be := pp10b-pp10e
pp10cd := pp10c-pp10d
pp10ce := pp10c-pp10e
pp10de := pp10d-pp10e
irb1ab := irb1a-irb1b
irb1ac := irb1a-irb1c
irb1ad := irb1a-irb1d
irb1ae := irb1a-irb1e
irb1bc := irb1b-irb1c
irb1bd := irb1b-irb1d
irb1be := irb1b-irb1e
irb1cd := irb1c-irb1d
irb1ce := irb1c-irb1e
irb1de := irb1d-irb1e
irb2ab := irb2a-irb2b
irb2ac := irb2a-irb2c
irb2ad := irb2a-irb2d
irb2ae := irb2a-irb2e
irb2bc := irb2b-irb2c
irb2bd := irb2b-irb2d
irb2be := irb2b-irb2e
irb2cd := irb2c-irb2d
irb2ce := irb2c-irb2e
irb2de := irb2d-irb2e
irb3ab := irb3a-irb3b
irb3ac := irb3a-irb3c
irb3ad := irb3a-irb3d
irb3ae := irb3a-irb3e
irb3bc := irb3b-irb3c
irb3bd := irb3b-irb3d
irb3be := irb3b-irb3e
irb3cd := irb3c-irb3d
irb3ce := irb3c-irb3e
irb3de := irb3d-irb3e
irb4ab := irb4a-irb4b
irb4ac := irb4a-irb4c
irb4ad := irb4a-irb4d
irb4ae := irb4a-irb4e
irb4bc := irb4b-irb4c
irb4bd := irb4b-irb4d
irb4be := irb4b-irb4e
irb4cd := irb4c-irb4d
irb4ce := irb4c-irb4e
irb4de := irb4d-irb4e
ocbi1ab := ocbi1a-ocbi1b
ocbi1ac := ocbi1a-ocbi1c
ocbi1ad := ocbi1a-ocbi1d
ocbi1ae := ocbi1a-ocbi1e
ocbi1bc := ocbi1b-ocbi1c
ocbi1bd := ocbi1b-ocbi1d
ocbi1be := ocbi1b-ocbi1e
ocbi1cd := ocbi1c-ocbi1d
ocbi1ce := ocbi1c-ocbi1e
ocbi1de := ocbi1d-ocbi1e
ocbi2ab := ocbi2a-ocbi2b
ocbi2ac := ocbi2a-ocbi2c
ocbi2ad := ocbi2a-ocbi2d
ocbi2ae := ocbi2a-ocbi2e
ocbi2bc := ocbi2b-ocbi2c
ocbi2bd := ocbi2b-ocbi2d
ocbi2be := ocbi2b-ocbi2e
ocbi2cd := ocbi2c-ocbi2d
ocbi2ce := ocbi2c-ocbi2e
ocbi2de := ocbi2d-ocbi2e
ocbi3ab := ocbi3a-ocbi3b
ocbi3ac := ocbi3a-ocbi3c
ocbi3ad := ocbi3a-ocbi3d
ocbi3ae := ocbi3a-ocbi3e
ocbi3bc := ocbi3b-ocbi3c
ocbi3bd := ocbi3b-ocbi3d
ocbi3be := ocbi3b-ocbi3e
ocbi3cd := ocbi3c-ocbi3d
ocbi3ce := ocbi3c-ocbi3e
ocbi3de := ocbi3d-ocbi3e
ocbi4ab := ocbi4a-ocbi4b
ocbi4ac := ocbi4a-ocbi4c
ocbi4ad := ocbi4a-ocbi4d
ocbi4ae := ocbi4a-ocbi4e
ocbi4bc := ocbi4b-ocbi4c
ocbi4bd := ocbi4b-ocbi4d
ocbi4be := ocbi4b-ocbi4e
ocbi4cd := ocbi4c-ocbi4d
ocbi4ce := ocbi4c-ocbi4e
ocbi4de := ocbi4d-ocbi4e
ocbi5ab := ocbi5a-ocbi5b
ocbi5ac := ocbi5a-ocbi5c
ocbi5ad := ocbi5a-ocbi5d
ocbi5ae := ocbi5a-ocbi5e
ocbi5bc := ocbi5b-ocbi5c
ocbi5bd := ocbi5b-ocbi5d
ocbi5be := ocbi5b-ocbi5e
ocbi5cd := ocbi5c-ocbi5d
ocbi5ce := ocbi5c-ocbi5e
ocbi5de := ocbi5d-ocbi5e
ocbi6ab := ocbi6a-ocbi6b
ocbi6ac := ocbi6a-ocbi6c
ocbi6ad := ocbi6a-ocbi6d
ocbi6ae := ocbi6a-ocbi6e
ocbi6bc := ocbi6b-ocbi6c
ocbi6bd := ocbi6b-ocbi6d
ocbi6be := ocbi6b-ocbi6e
ocbi6cd := ocbi6c-ocbi6d
ocbi6ce := ocbi6c-ocbi6e
ocbi6de := ocbi6d-ocbi6e
ocbi7ab := ocbi7a-ocbi7b
ocbi7ac := ocbi7a-ocbi7c
ocbi7ad := ocbi7a-ocbi7d
ocbi7ae := ocbi7a-ocbi7e
ocbi7bc := ocbi7b-ocbi7c
ocbi7bd := ocbi7b-ocbi7d
ocbi7be := ocbi7b-ocbi7e
ocbi7cd := ocbi7c-ocbi7d
ocbi7ce := ocbi7c-ocbi7e
ocbi7de := ocbi7d-ocbi7e
ocbo1ab := ocbo1a-ocbo1b
ocbo1ac := ocbo1a-ocbo1c
ocbo1ad := ocbo1a-ocbo1d
ocbo1ae := ocbo1a-ocbo1e
ocbo1bc := ocbo1b-ocbo1c
ocbo1bd := ocbo1b-ocbo1d
ocbo1be := ocbo1b-ocbo1e
ocbo1cd := ocbo1c-ocbo1d
ocbo1ce := ocbo1c-ocbo1e
ocbo1de := ocbo1d-ocbo1e
ocbo2ab := ocbo2a-ocbo2b
ocbo2ac := ocbo2a-ocbo2c
ocbo2ad := ocbo2a-ocbo2d
ocbo2ae := ocbo2a-ocbo2e
ocbo2bc := ocbo2b-ocbo2c
ocbo2bd := ocbo2b-ocbo2d
ocbo2be := ocbo2b-ocbo2e
ocbo2cd := ocbo2c-ocbo2d
ocbo2ce := ocbo2c-ocbo2e
ocbo2de := ocbo2d-ocbo2e
ocbo6ab := ocbo6a-ocbo6b
ocbo6ac := ocbo6a-ocbo6c
ocbo6ad := ocbo6a-ocbo6d
ocbo6ae := ocbo6a-ocbo6e
ocbo6bc := ocbo6b-ocbo6c
ocbo6bd := ocbo6b-ocbo6d
ocbo6be := ocbo6b-ocbo6e
ocbo6cd := ocbo6c-ocbo6d
ocbo6ce := ocbo6c-ocbo6e
ocbo6de := ocbo6d-ocbo6e
ocbo7ab := ocbo7a-ocbo7b
ocbo7ac := ocbo7a-ocbo7c
ocbo7ad := ocbo7a-ocbo7d
ocbo7ae := ocbo7a-ocbo7e
ocbo7bc := ocbo7b-ocbo7c
ocbo7bd := ocbo7b-ocbo7d
ocbo7be := ocbo7b-ocbo7e
ocbo7cd := ocbo7c-ocbo7d
ocbo7ce := ocbo7c-ocbo7e
ocbo7de := ocbo7d-ocbo7e
papp1ab := papp1a-papp1b
papp1ac := papp1a-papp1c
papp1ad := papp1a-papp1d
papp1ae := papp1a-papp1e
papp1bc := papp1b-papp1c
papp1bd := papp1b-papp1d
papp1be := papp1b-papp1e
papp1cd := papp1c-papp1d
papp1ce := papp1c-papp1e
papp1de := papp1d-papp1e
papp2ab := papp2a-papp2b
papp2ac := papp2a-papp2c
papp2ad := papp2a-papp2d
papp2ae := papp2a-papp2e
papp2bc := papp2b-papp2c
papp2bd := papp2b-papp2d
papp2be := papp2b-papp2e
papp2cd := papp2c-papp2d
papp2ce := papp2c-papp2e
papp2de := papp2d-papp2e
papp3ab := papp3a-papp3b
papp3ac := papp3a-papp3c
papp3ad := papp3a-papp3d
papp3ae := papp3a-papp3e
papp3bc := papp3b-papp3c
papp3bd := papp3b-papp3d
papp3be := papp3b-papp3e
papp3cd := papp3c-papp3d
papp3ce := papp3c-papp3e
papp3de := papp3d-papp3e
papp4ab := papp4a-papp4b
papp4ac := papp4a-papp4c
papp4ad := papp4a-papp4d
papp4ae := papp4a-papp4e
papp4bc := papp4b-papp4c
papp4bd := papp4b-papp4d
papp4be := papp4b-papp4e
papp4cd := papp4c-papp4d
papp4ce := papp4c-papp4e
papp4de := papp4d-papp4e
papp5ab := papp5a-papp5b
papp5ac := papp5a-papp5c
papp5ad := papp5a-papp5d
papp5ae := papp5a-papp5e
papp5bc := papp5b-papp5c
papp5bd := papp5b-papp5d
papp5be := papp5b-papp5e
papp5cd := papp5c-papp5d
papp5ce := papp5c-papp5e
papp5de := papp5d-papp5e
papp6ab := papp6a-papp6b
papp6ac := papp6a-papp6c
papp6ad := papp6a-papp6d
papp6ae := papp6a-papp6e
papp6bc := papp6b-papp6c
papp6bd := papp6b-papp6d
papp6be := papp6b-papp6e
papp6cd := papp6c-papp6d
papp6ce := papp6c-papp6e
papp6de := papp6d-papp6e
papp7ab := papp7a-papp7b
papp7ac := papp7a-papp7c
papp7ad := papp7a-papp7d
papp7ae := papp7a-papp7e
papp7bc := papp7b-papp7c
papp7bd := papp7b-papp7d
papp7be := papp7b-papp7e
papp7cd := papp7c-papp7d
papp7ce := papp7c-papp7e
papp7de := papp7d-papp7e
papp8ab := papp8a-papp8b
papp8ac := papp8a-papp8c
papp8ad := papp8a-papp8d
papp8ae := papp8a-papp8e
papp8bc := papp8b-papp8c
papp8bd := papp8b-papp8d
papp8be := papp8b-papp8e
papp8cd := papp8c-papp8d
papp8ce := papp8c-papp8e
papp8de := papp8d-papp8e
papp9ab := papp9a-papp9b
papp9ac := papp9a-papp9c
papp9ad := papp9a-papp9d
papp9ae := papp9a-papp9e
papp9bc := papp9b-papp9c
papp9bd := papp9b-papp9d
papp9be := papp9b-papp9e
papp9cd := papp9c-papp9d
papp9ce := papp9c-papp9e
papp9de := papp9d-papp9e
papp10ab := papp10a-papp10b
papp10ac := papp10a-papp10c
papp10ad := papp10a-papp10d
papp10ae := papp10a-papp10e
papp10bc := papp10b-papp10c
papp10bd := papp10b-papp10d
papp10be := papp10b-papp10e
papp10cd := papp10c-papp10d
papp10ce := papp10c-papp10e
papp10de := papp10d-papp10e
pairb1ab := pairb1a-pairb1b
pairb1ac := pairb1a-pairb1c
pairb1ad := pairb1a-pairb1d
pairb1ae := pairb1a-pairb1e
pairb1bc := pairb1b-pairb1c
pairb1bd := pairb1b-pairb1d
pairb1be := pairb1b-pairb1e
pairb1cd := pairb1c-pairb1d
pairb1ce := pairb1c-pairb1e
pairb1de := pairb1d-pairb1e
pairb2ab := pairb2a-pairb2b
pairb2ac := pairb2a-pairb2c
pairb2ad := pairb2a-pairb2d
pairb2ae := pairb2a-pairb2e
pairb2bc := pairb2b-pairb2c
pairb2bd := pairb2b-pairb2d
pairb2be := pairb2b-pairb2e
pairb2cd := pairb2c-pairb2d
pairb2ce := pairb2c-pairb2e
pairb2de := pairb2d-pairb2e
pairb3ab := pairb3a-pairb3b
pairb3ac := pairb3a-pairb3c
pairb3ad := pairb3a-pairb3d
pairb3ae := pairb3a-pairb3e
pairb3bc := pairb3b-pairb3c
pairb3bd := pairb3b-pairb3d
pairb3be := pairb3b-pairb3e
pairb3cd := pairb3c-pairb3d
pairb3ce := pairb3c-pairb3e
pairb3de := pairb3d-pairb3e
pairb4ab := pairb4a-pairb4b
pairb4ac := pairb4a-pairb4c
pairb4ad := pairb4a-pairb4d
pairb4ae := pairb4a-pairb4e
pairb4bc := pairb4b-pairb4c
pairb4bd := pairb4b-pairb4d
pairb4be := pairb4b-pairb4e
pairb4cd := pairb4c-pairb4d
pairb4ce := pairb4c-pairb4e
pairb4de := pairb4d-pairb4e
paocbi1ab := paocbi1a-paocbi1b
paocbi1ac := paocbi1a-paocbi1c
paocbi1ad := paocbi1a-paocbi1d
paocbi1ae := paocbi1a-paocbi1e
paocbi1bc := paocbi1b-paocbi1c
paocbi1bd := paocbi1b-paocbi1d
paocbi1be := paocbi1b-paocbi1e
paocbi1cd := paocbi1c-paocbi1d
paocbi1ce := paocbi1c-paocbi1e
paocbi1de := paocbi1d-paocbi1e
paocbi2ab := paocbi2a-paocbi2b
paocbi2ac := paocbi2a-paocbi2c
paocbi2ad := paocbi2a-paocbi2d
paocbi2ae := paocbi2a-paocbi2e
paocbi2bc := paocbi2b-paocbi2c
paocbi2bd := paocbi2b-paocbi2d
paocbi2be := paocbi2b-paocbi2e
paocbi2cd := paocbi2c-paocbi2d
paocbi2ce := paocbi2c-paocbi2e
paocbi2de := paocbi2d-paocbi2e
paocbi3ab := paocbi3a-paocbi3b
paocbi3ac := paocbi3a-paocbi3c
paocbi3ad := paocbi3a-paocbi3d
paocbi3ae := paocbi3a-paocbi3e
paocbi3bc := paocbi3b-paocbi3c
paocbi3bd := paocbi3b-paocbi3d
paocbi3be := paocbi3b-paocbi3e
paocbi3cd := paocbi3c-paocbi3d
paocbi3ce := paocbi3c-paocbi3e
paocbi3de := paocbi3d-paocbi3e
paocbi4ab := paocbi4a-paocbi4b
paocbi4ac := paocbi4a-paocbi4c
paocbi4ad := paocbi4a-paocbi4d
paocbi4ae := paocbi4a-paocbi4e
paocbi4bc := paocbi4b-paocbi4c
paocbi4bd := paocbi4b-paocbi4d
paocbi4be := paocbi4b-paocbi4e
paocbi4cd := paocbi4c-paocbi4d
paocbi4ce := paocbi4c-paocbi4e
paocbi4de := paocbi4d-paocbi4e
paocbi5ab := paocbi5a-paocbi5b
paocbi5ac := paocbi5a-paocbi5c
paocbi5ad := paocbi5a-paocbi5d
paocbi5ae := paocbi5a-paocbi5e
paocbi5bc := paocbi5b-paocbi5c
paocbi5bd := paocbi5b-paocbi5d
paocbi5be := paocbi5b-paocbi5e
paocbi5cd := paocbi5c-paocbi5d
paocbi5ce := paocbi5c-paocbi5e
paocbi5de := paocbi5d-paocbi5e
paocbi6ab := paocbi6a-paocbi6b
paocbi6ac := paocbi6a-paocbi6c
paocbi6ad := paocbi6a-paocbi6d
paocbi6ae := paocbi6a-paocbi6e
paocbi6bc := paocbi6b-paocbi6c
paocbi6bd := paocbi6b-paocbi6d
paocbi6be := paocbi6b-paocbi6e
paocbi6cd := paocbi6c-paocbi6d
paocbi6ce := paocbi6c-paocbi6e
paocbi6de := paocbi6d-paocbi6e
paocbi7ab := paocbi7a-paocbi7b
paocbi7ac := paocbi7a-paocbi7c
paocbi7ad := paocbi7a-paocbi7d
paocbi7ae := paocbi7a-paocbi7e
paocbi7bc := paocbi7b-paocbi7c
paocbi7bd := paocbi7b-paocbi7d
paocbi7be := paocbi7b-paocbi7e
paocbi7cd := paocbi7c-paocbi7d
paocbi7ce := paocbi7c-paocbi7e
paocbi7de := paocbi7d-paocbi7e
paocbo1ab := paocbo1a-paocbo1b
paocbo1ac := paocbo1a-paocbo1c
paocbo1ad := paocbo1a-paocbo1d
paocbo1ae := paocbo1a-paocbo1e
paocbo1bc := paocbo1b-paocbo1c
paocbo1bd := paocbo1b-paocbo1d
paocbo1be := paocbo1b-paocbo1e
paocbo1cd := paocbo1c-paocbo1d
paocbo1ce := paocbo1c-paocbo1e
paocbo1de := paocbo1d-paocbo1e
paocbo2ab := paocbo2a-paocbo2b
paocbo2ac := paocbo2a-paocbo2c
paocbo2ad := paocbo2a-paocbo2d
paocbo2ae := paocbo2a-paocbo2e
paocbo2bc := paocbo2b-paocbo2c
paocbo2bd := paocbo2b-paocbo2d
paocbo2be := paocbo2b-paocbo2e
paocbo2cd := paocbo2c-paocbo2d
paocbo2ce := paocbo2c-paocbo2e
paocbo2de := paocbo2d-paocbo2e
paocbo6ab := paocbo6a-paocbo6b
paocbo6ac := paocbo6a-paocbo6c
paocbo6ad := paocbo6a-paocbo6d
paocbo6ae := paocbo6a-paocbo6e
paocbo6bc := paocbo6b-paocbo6c
paocbo6bd := paocbo6b-paocbo6d
paocbo6be := paocbo6b-paocbo6e
paocbo6cd := paocbo6c-paocbo6d
paocbo6ce := paocbo6c-paocbo6e
paocbo6de := paocbo6d-paocbo6e
paocbo7ab := paocbo7a-paocbo7b
paocbo7ac := paocbo7a-paocbo7c
paocbo7ad := paocbo7a-paocbo7d
paocbo7ae := paocbo7a-paocbo7e
paocbo7bc := paocbo7b-paocbo7c
paocbo7bd := paocbo7b-paocbo7d
paocbo7be := paocbo7b-paocbo7e
paocbo7cd := paocbo7c-paocbo7d
paocbo7ce := paocbo7c-paocbo7e
paocbo7de := paocbo7d-paocbo7e

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated.
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Compute factor covariances differences.
ppirbab := ppirba-ppirbb
ppirbac := ppirba-ppirbc
ppirbad := ppirba-ppirbd
ppirbae := ppirba-ppirbe
ppirbbc := ppirbb-ppirbc
ppirbbd := ppirbb-ppirbd
ppirbbe := ppirbb-ppirbe
ppirbcd := ppirbc-ppirbd
ppirbce := ppirbc-ppirbe
ppirbde := ppirbd-ppirbe
ppocbiab := ppocbia-ppocbib
ppocbiac := ppocbia-ppocbic
ppocbiad := ppocbia-ppocbid
ppocbiae := ppocbia-ppocbie
ppocbibc := ppocbib-ppocbic
ppocbibd := ppocbib-ppocbid
ppocbibe := ppocbib-ppocbie
ppocbicd := ppocbic-ppocbid
ppocbice := ppocbic-ppocbie
ppocbide := ppocbid-ppocbie
ppocboab := ppocboa-ppocbob
ppocboac := ppocboa-ppocboc
ppocboad := ppocboa-ppocbod
ppocboae := ppocboa-ppocboe
ppocbobc := ppocbob-ppocboc
ppocbobd := ppocbob-ppocbod
ppocbobe := ppocbob-ppocboe
ppocbocd := ppocboc-ppocbod
ppocboce := ppocboc-ppocboe
ppocbode := ppocbod-ppocboe
irbocbiab := irbocbia-irbocbib
irbocbiac := irbocbia-irbocbic
irbocbiad := irbocbia-irbocbid
irbocbiae := irbocbia-irbocbie
irbocbibc := irbocbib-irbocbic
irbocbibd := irbocbib-irbocbid
irbocbibe := irbocbib-irbocbie
irbocbicd := irbocbic-irbocbid
irbocbice := irbocbic-irbocbie
irbocbide := irbocbid-irbocbie
irbocboab := irbocboa-irbocbob
irbocboac := irbocboa-irbocboc
irbocboad := irbocboa-irbocbod
irbocboae := irbocboa-irbocboe
irbocbobc := irbocbob-irbocboc
irbocbobd := irbocbob-irbocbod
irbocbobe := irbocbob-irbocboe
irbocbocd := irbocboc-irbocbod
irbocboce := irbocboc-irbocboe
irbocbode := irbocbod-irbocboe
ocbioab := ocbioa-ocbiob
ocbioac := ocbioa-ocbioc
ocbioad := ocbioa-ocbiod
ocbioae := ocbioa-ocbioe
ocbiobc := ocbiob-ocbioc
ocbiobd := ocbiob-ocbiod
ocbiobe := ocbiob-ocbioe
ocbiocd := ocbioc-ocbiod
ocbioce := ocbioc-ocbioe
ocbiode := ocbiod-ocbioe

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methodu <- cfa(methodu.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(baseline,methodu) #Method variance attributable to positive affectivity has been identified. 

#Model 4: Method I model. Constrain estimates of method effects to be equal within substantive variables but different across substantive variables. This tests whether method effects attributable to positive affectivity are present to an equal degree within a given factor but vary across different factors.
methodi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo6c,ocbo6d,ocbo6e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1a,papp1a,papp1a,papp1a)*PP1 + c(papp1a, papp1a,papp1a,papp1a,papp1a)*PP2 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP3 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP4 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP5 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP6 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP7 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP8 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP9 + c(papp1a,papp1a,papp1a,papp1a,papp1a)*PP10 + c(pairb1a,pairb1a,pairb1a,pairb1a,pairb1a)*IRB1 + c(pairb1a,pairb1a,pairb1a,pairb1a,pairb1a)*IRB2 + c(pairb1a,pairb1a,pairb1a,pairb1a,pairb1a)*IRB3 + c(pairb1a,pairb1a,pairb1a,pairb1a,pairb1a)*IRB4 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI1 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI2 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI3 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI4 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI5 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI6 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI7 + c(paocbo1a,paocbo1a,paocbo1a,paocbo1a,paocbo1a)*OCBO1 + c(paocbo1a,paocbo1a,paocbo1a,paocbo1a,paocbo1a)*OCBO2 +  c(paocbo1a,paocbo1a,paocbo1a,paocbo1a,paocbo1a)*OCBO6 + c(paocbo1a,paocbo1a,paocbo1a,paocbo1a,paocbo1a)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methodi <- cfa(methodi.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodi,methodu) #Method variance is congeneric across substantive items. 

#Model 5: Method UC model. Constrain estimates of method effects, which are freely estimated across all factors (i.e., method u), to be equal across conditions. This tests whether method variance attributable to positive affectivity is equally present across conditions. 
methoduc.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4 
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo6c,ocbo6d,ocbo6e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
##Substantive factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1a,papp1a,papp1a,papp1a)*PP1 + c(papp2a, papp2a,papp2a,papp2a,papp2a)*PP2 + c(papp3a,papp3a,papp3a,papp3a,papp3a)*PP3 + c(papp4a,papp4a,papp4a,papp4a,papp4a)*PP4 + c(papp5a,papp5a,papp5a,papp5a,papp5a)*PP5 + c(papp6a,papp6a,papp6a,papp6a,papp6a)*PP6 + c(papp7a,papp7a,papp7a,papp7a,papp7a)*PP7 + c(papp8a,papp8a,papp8a,papp8a,papp8a)*PP8 + c(papp9a,papp9a,papp9a,papp9a,papp9a)*PP9 + c(papp10a,papp10a,papp10a,papp10a,papp10a)*PP10 + c(pairb1a,pairb1a,pairb1a,pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a,pairb2a,pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a,pairb3a,pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a,pairb4a,pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a,paocbi1a,paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a,paocbi2a,paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a,paocbi3a,paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a,paocbi4a,paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a,paocbi5a,paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a,paocbi6a,paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a,paocbi7a,paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a,paocbo1a,paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a,paocbo2a,paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a,paocbo6a,paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a,paocbo7a,paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA


#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methoduc <- cfa(methoduc.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methoduc,methodu) #Method variance attributable to positive affectivity varies across the two conditions. 

#Model 6: Method UP model. Constrain substantive factor loadings to be equal across conditions but free across factors and within factors. This tests the hypothesis that proximal remedies cause a difference in the factor loadings of our measurement model. 
methodup.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1a, pp1a, pp1a, pp1a)*PP1 + c(pp2a, pp2a, pp2a, pp2a, pp2a)*PP2 + c(pp3a,pp3a, pp3a, pp3a, pp3a)*PP3 + c(pp4a,pp4a, pp4a, pp4a, pp4a)*PP4 + c(pp5a,pp5a, pp5a, pp5a, pp5a)*PP5 + c(pp6a,pp6a, pp6a, pp6a, pp6a)*PP6 + c(pp7a,pp7a, pp7a, pp7a, pp7a)*PP7 + c(pp8a,pp8a, pp8a, pp8a, pp8a)*PP8 + c(pp9a,pp9a, pp9a, pp9a, pp9a)*PP9 + c(pp10a,pp10a, pp10a, pp10a, pp10a)*PP10
IRB =~ c(irb1a,irb1a,irb1a,irb1a,irb1a)*IRB1 + c(irb2a,irb2a,irb2a,irb2a,irb2a)*IRB2 + c(irb3a,irb3a,irb3a,irb3a,irb3a)*IRB3 + c(irb4a,irb4a,irb4a,irb4a,irb4a)*IRB4
OCBI =~ c(ocbi1a,ocbi1a,ocbi1a,ocbi1a,ocbi1a)*OCBI1 + c(ocbi2a,ocbi2a,ocbi2a,ocbi2a,ocbi2a)*OCBI2 + c(ocbi3a,ocbi3a,ocbi3a,ocbi3a,ocbi3a)*OCBI3 + c(ocbi4a,ocbi4a,ocbi4a,ocbi4a,ocbi4a)*OCBI4 + c(ocbi5a,ocbi5a,ocbi5a,ocbi5a,ocbi5a)*OCBI5 + c(ocbi6a,ocbi6a,ocbi6a,ocbi6a,ocbi6a)*OCBI6 + c(ocbi7a,ocbi7a,ocbi7a,ocbi7a,ocbi7a)*OCBI7
OCBO =~ c(ocbo1a,ocbo1a,ocbo1a,ocbo1a,ocbo1a)*OCBO1 + c(ocbo2a,ocbo2a,ocbo2a,ocbo2a,ocbo2a)*OCBO2 + c(ocbo6a,ocbo6a,ocbo6a,ocbo6a,ocbo6a)*OCBO6 + c(ocbo7a,ocbo7a,ocbo7a,ocbo7a,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1b,papp1c,papp1d,papp1e)*PP1 + c(papp2a, papp2b,papp2c,papp2d,papp2e)*PP2 + c(papp3a,papp3b,papp3c,papp3d,papp3e)*PP3 + c(papp4a,papp4b,papp4c,papp4d,papp4e)*PP4 + c(papp5a,papp5b,papp5c,papp5d,papp5e)*PP5 + c(papp6a,papp6b,papp6c,papp6d,papp6e)*PP6 + c(papp7a,papp7b,papp7c,papp7d,papp7e)*PP7 + c(papp8a,papp8b,papp8c,papp8d,papp8e)*PP8 + c(papp9a,papp9b,papp9c,papp9d,papp9e)*PP9 + c(papp10a,papp10b,papp10c,papp10d,papp10e)*PP10 + c(pairb1a,pairb1b,pairb1c,pairb1d,pairb1e)*IRB1 + c(pairb2a,pairb2b,pairb2c,pairb2d,pairb2e)*IRB2 + c(pairb3a,pairb3b,pairb3c,pairb3d,pairb3e)*IRB3 + c(pairb4a,pairb4b,pairb4c,pairb4d,pairb4e)*IRB4 + c(paocbi1a,paocbi1b,paocbi1c,paocbi1d,paocbi1e)*OCBI1 + c(paocbi2a,paocbi2b,paocbi2c,paocbi2d,paocbi2e)*OCBI2 + c(paocbi3a,paocbi3b,paocbi3c,paocbi3d,paocbi3e)*OCBI3 + c(paocbi4a,paocbi4b,paocbi4c,paocbi4d,paocbi4e)*OCBI4 + c(paocbi5a,paocbi5b,paocbi5c,paocbi5d,paocbi5e)*OCBI5 + c(paocbi6a,paocbi6b,paocbi6c,paocbi6d,paocbi6e)*OCBI6 + c(paocbi7a,paocbi7b,paocbi7c,paocbi7d,paocbi7e)*OCBI7 + c(paocbo1a,paocbo1b,paocbo1c,paocbo1d,paocbo1e)*OCBO1 + c(paocbo2a,paocbo2b,paocbo2c,paocbo2d,paocbo2e)*OCBO2 + c(paocbo6a,paocbo6b,paocbo6c,paocbo6d,paocbo6e)*OCBO6 + c(paocbo7a,paocbo7b,paocbo7c,paocbo7d,paocbo7e)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methodup <- cfa(methodup.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodup,methodu) #Method variance attributable to other proximal causes of method variance has been detected. Need to follow up with tests to identify the nature of the proximal causes of method variance (congeneric vs. non-congeneric).

#Model 7: Method UPI model. Force the differences in factor loadings to be equal within factors but to vary across factors. Tests the hypothesis that proximal causes of method effects addressed by diffrent proximal remedies have the same effects. If this model is not statistically different from method u, then proximal remedies vary in terms of their effects and so a simple correction for failing to use any single remedies will not be viable. In other words, the effects of proximal remedies are more complex than considered previously. 
methodupi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4 
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo6c,ocbo6d,ocbo6e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1b,papp1c,papp1d,papp1e)*PP1 + c(papp2a, papp2b,papp2c,papp2d,papp2e)*PP2 + c(papp3a,papp3b,papp3c,papp3d,papp3e)*PP3 + c(papp4a,papp4b,papp4c,papp4d,papp4e)*PP4 + c(papp5a,papp5b,papp5c,papp5d,papp5e)*PP5 + c(papp6a,papp6b,papp6c,papp6d,papp6e)*PP6 + c(papp7a,papp7b,papp7c,papp7d,papp7e)*PP7 + c(papp8a,papp8b,papp8c,papp8d,papp8e)*PP8 + c(papp9a,papp9b,papp9c,papp9d,papp9e)*PP9 + c(papp10a,papp10b,papp10c,papp10d,papp10e)*PP10 + c(pairb1a,pairb1b,pairb1c,pairb1d,pairb1e)*IRB1 + c(pairb2a,pairb2b,pairb2c,pairb2d,pairb2e)*IRB2 + c(pairb3a,pairb3b,pairb3c,pairb3d,pairb3e)*IRB3 + c(pairb4a,pairb4b,pairb4c,pairb4d,pairb4e)*IRB4 + c(paocbi1a,paocbi1b,paocbi1c,paocbi1d,paocbi1e)*OCBI1 + c(paocbi2a,paocbi2b,paocbi2c,paocbi2d,paocbi2e)*OCBI2 + c(paocbi3a,paocbi3b,paocbi3c,paocbi3d,paocbi3e)*OCBI3 + c(paocbi4a,paocbi4b,paocbi4c,paocbi4d,paocbi4e)*OCBI4 + c(paocbi5a,paocbi5b,paocbi5c,paocbi5d,paocbi5e)*OCBI5 + c(paocbi6a,paocbi6b,paocbi6c,paocbi6d,paocbi6e)*OCBI6 + c(paocbi7a,paocbi7b,paocbi7c,paocbi7d,paocbi7e)*OCBI7 + c(paocbo1a,paocbo1b,paocbo1c,paocbo1d,paocbo1e)*OCBO1 + c(paocbo2a,paocbo2b,paocbo2c,paocbo2d,paocbo2e)*OCBO2 + c(paocbo6a,paocbo6b,paocbo6c,paocbo6d,paocbo6e)*OCBO6 + c(paocbo7a,paocbo7b,paocbo7c,paocbo7d,paocbo7e)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Compute factor loading differences 
pp1ab := pp1a-pp1b
pp1ac := pp1a-pp1c
pp1ad := pp1a-pp1d
pp1ae := pp1a-pp1e
pp1bc := pp1b-pp1c
pp1bd := pp1b-pp1d
pp1be := pp1b-pp1e
pp1cd := pp1c-pp1d
pp1ce := pp1c-pp1e
pp1de := pp1d-pp1e
pp2ab := pp2a-pp2b
pp2ac := pp2a-pp2c
pp2ad := pp2a-pp2d
pp2ae := pp2a-pp2e
pp2bc := pp2b-pp2c
pp2bd := pp2b-pp2d
pp2be := pp2b-pp2e
pp2cd := pp2c-pp2d
pp2ce := pp2c-pp2e
pp2de := pp2d-pp2e
pp3ab := pp3a-pp3b
pp3ac := pp3a-pp3c
pp3ad := pp3a-pp3d
pp3ae := pp3a-pp3e
pp3bc := pp3b-pp3c
pp3bd := pp3b-pp3d
pp3be := pp3b-pp3e
pp3cd := pp3c-pp3d
pp3ce := pp3c-pp3e
pp3de := pp3d-pp3e
pp4ab := pp4a-pp4b
pp4ac := pp4a-pp4c
pp4ad := pp4a-pp4d
pp4ae := pp4a-pp4e
pp4bc := pp4b-pp4c
pp4bd := pp4b-pp4d
pp4be := pp4b-pp4e
pp4cd := pp4c-pp4d
pp4ce := pp4c-pp4e
pp4de := pp4d-pp4e
pp5ab := pp5a-pp5b
pp5ac := pp5a-pp5c
pp5ad := pp5a-pp5d
pp5ae := pp5a-pp5e
pp5bc := pp5b-pp5c
pp5bd := pp5b-pp5d
pp5be := pp5b-pp5e
pp5cd := pp5c-pp5d
pp5ce := pp5c-pp5e
pp5de := pp5d-pp5e
pp6ab := pp6a-pp6b
pp6ac := pp6a-pp6c
pp6ad := pp6a-pp6d
pp6ae := pp6a-pp6e
pp6bc := pp6b-pp6c
pp6bd := pp6b-pp6d
pp6be := pp6b-pp6e
pp6cd := pp6c-pp6d
pp6ce := pp6c-pp6e
pp6de := pp6d-pp6e
pp7ab := pp7a-pp7b
pp7ac := pp7a-pp7c
pp7ad := pp7a-pp7d
pp7ae := pp7a-pp7e
pp7bc := pp7b-pp7c
pp7bd := pp7b-pp7d
pp7be := pp7b-pp7e
pp7cd := pp7c-pp7d
pp7ce := pp7c-pp7e
pp7de := pp7d-pp7e
pp8ab := pp8a-pp8b
pp8ac := pp8a-pp8c
pp8ad := pp8a-pp8d
pp8ae := pp8a-pp8e
pp8bc := pp8b-pp8c
pp8bd := pp8b-pp8d
pp8be := pp8b-pp8e
pp8cd := pp8c-pp8d
pp8ce := pp8c-pp8e
pp8de := pp8d-pp8e
pp9ab := pp9a-pp9b
pp9ac := pp9a-pp9c
pp9ad := pp9a-pp9d
pp9ae := pp9a-pp9e
pp9bc := pp9b-pp9c
pp9bd := pp9b-pp9d
pp9be := pp9b-pp9e
pp9cd := pp9c-pp9d
pp9ce := pp9c-pp9e
pp9de := pp9d-pp9e
pp10ab := pp10a-pp10b
pp10ac := pp10a-pp10c
pp10ad := pp10a-pp10d
pp10ae := pp10a-pp10e
pp10bc := pp10b-pp10c
pp10bd := pp10b-pp10d
pp10be := pp10b-pp10e
pp10cd := pp10c-pp10d
pp10ce := pp10c-pp10e
pp10de := pp10d-pp10e
irb1ab := irb1a-irb1b
irb1ac := irb1a-irb1c
irb1ad := irb1a-irb1d
irb1ae := irb1a-irb1e
irb1bc := irb1b-irb1c
irb1bd := irb1b-irb1d
irb1be := irb1b-irb1e
irb1cd := irb1c-irb1d
irb1ce := irb1c-irb1e
irb1de := irb1d-irb1e
irb2ab := irb2a-irb2b
irb2ac := irb2a-irb2c
irb2ad := irb2a-irb2d
irb2ae := irb2a-irb2e
irb2bc := irb2b-irb2c
irb2bd := irb2b-irb2d
irb2be := irb2b-irb2e
irb2cd := irb2c-irb2d
irb2ce := irb2c-irb2e
irb2de := irb2d-irb2e
irb3ab := irb3a-irb3b
irb3ac := irb3a-irb3c
irb3ad := irb3a-irb3d
irb3ae := irb3a-irb3e
irb3bc := irb3b-irb3c
irb3bd := irb3b-irb3d
irb3be := irb3b-irb3e
irb3cd := irb3c-irb3d
irb3ce := irb3c-irb3e
irb3de := irb3d-irb3e
irb4ab := irb4a-irb4b
irb4ac := irb4a-irb4c
irb4ad := irb4a-irb4d
irb4ae := irb4a-irb4e
irb4bc := irb4b-irb4c
irb4bd := irb4b-irb4d
irb4be := irb4b-irb4e
irb4cd := irb4c-irb4d
irb4ce := irb4c-irb4e
irb4de := irb4d-irb4e
ocbi1ab := ocbi1a-ocbi1b
ocbi1ac := ocbi1a-ocbi1c
ocbi1ad := ocbi1a-ocbi1d
ocbi1ae := ocbi1a-ocbi1e
ocbi1bc := ocbi1b-ocbi1c
ocbi1bd := ocbi1b-ocbi1d
ocbi1be := ocbi1b-ocbi1e
ocbi1cd := ocbi1c-ocbi1d
ocbi1ce := ocbi1c-ocbi1e
ocbi1de := ocbi1d-ocbi1e
ocbi2ab := ocbi2a-ocbi2b
ocbi2ac := ocbi2a-ocbi2c
ocbi2ad := ocbi2a-ocbi2d
ocbi2ae := ocbi2a-ocbi2e
ocbi2bc := ocbi2b-ocbi2c
ocbi2bd := ocbi2b-ocbi2d
ocbi2be := ocbi2b-ocbi2e
ocbi2cd := ocbi2c-ocbi2d
ocbi2ce := ocbi2c-ocbi2e
ocbi2de := ocbi2d-ocbi2e
ocbi3ab := ocbi3a-ocbi3b
ocbi3ac := ocbi3a-ocbi3c
ocbi3ad := ocbi3a-ocbi3d
ocbi3ae := ocbi3a-ocbi3e
ocbi3bc := ocbi3b-ocbi3c
ocbi3bd := ocbi3b-ocbi3d
ocbi3be := ocbi3b-ocbi3e
ocbi3cd := ocbi3c-ocbi3d
ocbi3ce := ocbi3c-ocbi3e
ocbi3de := ocbi3d-ocbi3e
ocbi4ab := ocbi4a-ocbi4b
ocbi4ac := ocbi4a-ocbi4c
ocbi4ad := ocbi4a-ocbi4d
ocbi4ae := ocbi4a-ocbi4e
ocbi4bc := ocbi4b-ocbi4c
ocbi4bd := ocbi4b-ocbi4d
ocbi4be := ocbi4b-ocbi4e
ocbi4cd := ocbi4c-ocbi4d
ocbi4ce := ocbi4c-ocbi4e
ocbi4de := ocbi4d-ocbi4e
ocbi5ab := ocbi5a-ocbi5b
ocbi5ac := ocbi5a-ocbi5c
ocbi5ad := ocbi5a-ocbi5d
ocbi5ae := ocbi5a-ocbi5e
ocbi5bc := ocbi5b-ocbi5c
ocbi5bd := ocbi5b-ocbi5d
ocbi5be := ocbi5b-ocbi5e
ocbi5cd := ocbi5c-ocbi5d
ocbi5ce := ocbi5c-ocbi5e
ocbi5de := ocbi5d-ocbi5e
ocbi6ab := ocbi6a-ocbi6b
ocbi6ac := ocbi6a-ocbi6c
ocbi6ad := ocbi6a-ocbi6d
ocbi6ae := ocbi6a-ocbi6e
ocbi6bc := ocbi6b-ocbi6c
ocbi6bd := ocbi6b-ocbi6d
ocbi6be := ocbi6b-ocbi6e
ocbi6cd := ocbi6c-ocbi6d
ocbi6ce := ocbi6c-ocbi6e
ocbi6de := ocbi6d-ocbi6e
ocbi7ab := ocbi7a-ocbi7b
ocbi7ac := ocbi7a-ocbi7c
ocbi7ad := ocbi7a-ocbi7d
ocbi7ae := ocbi7a-ocbi7e
ocbi7bc := ocbi7b-ocbi7c
ocbi7bd := ocbi7b-ocbi7d
ocbi7be := ocbi7b-ocbi7e
ocbi7cd := ocbi7c-ocbi7d
ocbi7ce := ocbi7c-ocbi7e
ocbi7de := ocbi7d-ocbi7e
ocbo1ab := ocbo1a-ocbo1b
ocbo1ac := ocbo1a-ocbo1c
ocbo1ad := ocbo1a-ocbo1d
ocbo1ae := ocbo1a-ocbo1e
ocbo1bc := ocbo1b-ocbo1c
ocbo1bd := ocbo1b-ocbo1d
ocbo1be := ocbo1b-ocbo1e
ocbo1cd := ocbo1c-ocbo1d
ocbo1ce := ocbo1c-ocbo1e
ocbo1de := ocbo1d-ocbo1e
ocbo2ab := ocbo2a-ocbo2b
ocbo2ac := ocbo2a-ocbo2c
ocbo2ad := ocbo2a-ocbo2d
ocbo2ae := ocbo2a-ocbo2e
ocbo2bc := ocbo2b-ocbo2c
ocbo2bd := ocbo2b-ocbo2d
ocbo2be := ocbo2b-ocbo2e
ocbo2cd := ocbo2c-ocbo2d
ocbo2ce := ocbo2c-ocbo2e
ocbo2de := ocbo2d-ocbo2e
ocbo6ab := ocbo6a-ocbo6b
ocbo6ac := ocbo6a-ocbo6c
ocbo6ad := ocbo6a-ocbo6d
ocbo6ae := ocbo6a-ocbo6e
ocbo6bc := ocbo6b-ocbo6c
ocbo6bd := ocbo6b-ocbo6d
ocbo6be := ocbo6b-ocbo6e
ocbo6cd := ocbo6c-ocbo6d
ocbo6ce := ocbo6c-ocbo6e
ocbo6de := ocbo6d-ocbo6e
ocbo7ab := ocbo7a-ocbo7b
ocbo7ac := ocbo7a-ocbo7c
ocbo7ad := ocbo7a-ocbo7d
ocbo7ae := ocbo7a-ocbo7e
ocbo7bc := ocbo7b-ocbo7c
ocbo7bd := ocbo7b-ocbo7d
ocbo7be := ocbo7b-ocbo7e
ocbo7cd := ocbo7c-ocbo7d
ocbo7ce := ocbo7c-ocbo7e
ocbo7de := ocbo7d-ocbo7e

#Constrain the differences to be equal within factors but vary across factors.
pp1ab==pp1ac
pp1ac==pp1ad
pp1ad==pp1ae
pp1ae==pp1bc
pp1bc==pp1bd
pp1bd==pp1be
pp1be==pp1cd
pp1cd==pp1ce
pp1ce==pp1de
pp2ab==pp2ac
pp2ac==pp2ad
pp2ad==pp2ae
pp2ae==pp2bc
pp2bc==pp2bd
pp2bd==pp2be
pp2be==pp2cd
pp2cd==pp2ce
pp2ce==pp2de
pp3ab==pp3ac
pp3ac==pp3ad
pp3ad==pp3ae
pp3ae==pp3bc
pp3bc==pp3bd
pp3bd==pp3be
pp3be==pp3cd
pp3cd==pp3ce
pp3ce==pp3de
pp4ab==pp4ac
pp4ac==pp4ad
pp4ad==pp4ae
pp4ae==pp4bc
pp4bc==pp4bd
pp4bd==pp4be
pp4be==pp4cd
pp4cd==pp4ce
pp4ce==pp4de
pp5ab==pp5ac
pp5ac==pp5ad
pp5ad==pp5ae
pp5ae==pp5bc
pp5bc==pp5bd
pp5bd==pp5be
pp5be==pp5cd
pp5cd==pp5ce
pp5ce==pp5de
pp6ab==pp6ac
pp6ac==pp6ad
pp6ad==pp6ae
pp6ae==pp6bc
pp6bc==pp6bd
pp6bd==pp6be
pp6be==pp6cd
pp6cd==pp6ce
pp6ce==pp6de
pp7ab==pp7ac
pp7ac==pp7ad
pp7ad==pp7ae
pp7ae==pp7bc
pp7bc==pp7bd
pp7bd==pp7be
pp7be==pp7cd
pp7cd==pp7ce
pp7ce==pp7de
pp8ab==pp8ac
pp8ac==pp8ad
pp8ad==pp8ae
pp8ae==pp8bc
pp8bc==pp8bd
pp8bd==pp8be
pp8be==pp8cd
pp8cd==pp8ce
pp8ce==pp8de
pp9ab==pp9ac
pp9ac==pp9ad
pp9ad==pp9ae
pp9ae==pp9bc
pp9bc==pp9bd
pp9bd==pp9be
pp9be==pp9cd
pp9cd==pp9ce
pp9ce==pp9de
pp10ab==pp10ac
pp10ac==pp10ad
pp10ad==pp10ae
pp10ae==pp10bc
pp10bc==pp10bd
pp10bd==pp10be
pp10be==pp10cd
pp10cd==pp10ce
pp10ce==pp10de
irb1ab==irb1ac
irb1ac==irb1ad
irb1ad==irb1ae
irb1ae==irb1bc
irb1bc==irb1bd
irb1bd==irb1be
irb1be==irb1cd
irb1cd==irb1ce
irb1ce==irb1de
irb2ab==irb2ac
irb2ac==irb2ad
irb2ad==irb2ae
irb2ae==irb2bc
irb2bc==irb2bd
irb2bd==irb2be
irb2be==irb2cd
irb2cd==irb2ce
irb2ce==irb2de
irb3ab==irb3ac
irb3ac==irb3ad
irb3ad==irb3ae
irb3ae==irb3bc
irb3bc==irb3bd
irb3bd==irb3be
irb3be==irb3cd
irb3cd==irb3ce
irb3ce==irb3de
irb4ab==irb4ac
irb4ac==irb4ad
irb4ad==irb4ae
irb4ae==irb4bc
irb4bc==irb4bd
irb4bd==irb4be
irb4be==irb4cd
irb4cd==irb4ce
irb4ce==irb4de
ocbi1ab==ocbi1ac
ocbi1ac==ocbi1ad
ocbi1ad==ocbi1ae
ocbi1ae==ocbi1bc
ocbi1bc==ocbi1bd
ocbi1bd==ocbi1be
ocbi1be==ocbi1cd
ocbi1cd==ocbi1ce
ocbi1ce==ocbi1de
ocbi2ab==ocbi2ac
ocbi2ac==ocbi2ad
ocbi2ad==ocbi2ae
ocbi2ae==ocbi2bc
ocbi2bc==ocbi2bd
ocbi2bd==ocbi2be
ocbi2be==ocbi2cd
ocbi2cd==ocbi2ce
ocbi2ce==ocbi2de
ocbi3ab==ocbi3ac
ocbi3ac==ocbi3ad
ocbi3ad==ocbi3ae
ocbi3ae==ocbi3bc
ocbi3bc==ocbi3bd
ocbi3bd==ocbi3be
ocbi3be==ocbi3cd
ocbi3cd==ocbi3ce
ocbi3ce==ocbi3de
ocbi4ab==ocbi4ac
ocbi4ac==ocbi4ad
ocbi4ad==ocbi4ae
ocbi4ae==ocbi4bc
ocbi4bc==ocbi4bd
ocbi4bd==ocbi4be
ocbi4be==ocbi4cd
ocbi4cd==ocbi4ce
ocbi4ce==ocbi4de
ocbi5ab==ocbi5ac
ocbi5ac==ocbi5ad
ocbi5ad==ocbi5ae
ocbi5ae==ocbi5bc
ocbi5bc==ocbi5bd
ocbi5bd==ocbi5be
ocbi5be==ocbi5cd
ocbi5cd==ocbi5ce
ocbi5ce==ocbi5de
ocbi6ab==ocbi6ac
ocbi6ac==ocbi6ad
ocbi6ad==ocbi6ae
ocbi6ae==ocbi6bc
ocbi6bc==ocbi6bd
ocbi6bd==ocbi6be
ocbi6be==ocbi6cd
ocbi6cd==ocbi6ce
ocbi6ce==ocbi6de
ocbi7ab==ocbi7ac
ocbi7ac==ocbi7ad
ocbi7ad==ocbi7ae
ocbi7ae==ocbi7bc
ocbi7bc==ocbi7bd
ocbi7bd==ocbi7be
ocbi7be==ocbi7cd
ocbi7cd==ocbi7ce
ocbi7ce==ocbi7de
ocbo1ab==ocbo1ac
ocbo1ac==ocbo1ad
ocbo1ad==ocbo1ae
ocbo1ae==ocbo1bc
ocbo1bc==ocbo1bd
ocbo1bd==ocbo1be
ocbo1be==ocbo1cd
ocbo1cd==ocbo1ce
ocbo1ce==ocbo1de
ocbo2ab==ocbo2ac
ocbo2ac==ocbo2ad
ocbo2ad==ocbo2ae
ocbo2ae==ocbo2bc
ocbo2bc==ocbo2bd
ocbo2bd==ocbo2be
ocbo2be==ocbo2cd
ocbo2cd==ocbo2ce
ocbo2ce==ocbo2de
ocbo6ab==ocbo6ac
ocbo6ac==ocbo6ad
ocbo6ad==ocbo6ae
ocbo6ae==ocbo6bc
ocbo6bc==ocbo6bd
ocbo6bd==ocbo6be
ocbo6be==ocbo6cd
ocbo6cd==ocbo6ce
ocbo6ce==ocbo6de
ocbo7ab==ocbo7ac
ocbo7ac==ocbo7ad
ocbo7ad==ocbo7ae
ocbo7ae==ocbo7bc
ocbo7bc==ocbo7bd
ocbo7bd==ocbo7be
ocbo7be==ocbo7cd
ocbo7cd==ocbo7ce
ocbo7ce==ocbo7de

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb,ppirbc,ppirbd,ppirbe)*IRB
PP ~~ c(ppocbia,ppocbib,ppocbic,ppocbid,ppocbie)*OCBI
PP ~~ c(ppocboa,ppocbob,ppocboc,ppocbod,ppocboe)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbib,irbocbic,irbocbid,irbocbie)*OCBI
IRB ~~ c(irbocboa,irbocbob,irbocboc,irbocbod,irbocboe)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbiob,ocbioc,ocbiod,ocbioe)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methodupi <- cfa(methodupi.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodupi,methodu) #Method variance attributable to other proximal causes of method variance is congeneric. Therefore, a simple correction for failing to use a proximal remedy for CMV is overly simplistic. 

#Model 8: Method RAff model. Constrain estimates of covariances to be equal to baseline levels in respective conditions. Test method bias due to positive affectivity and proximal causes of method variance. 
methodru.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo6a,ocbo6b,ocbo6c,ocbo6d,ocbo6e)*OCBO6 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1b,papp1c,papp1d,papp1e)*PP1 + c(papp2a, papp2b,papp2c,papp2d,papp2e)*PP2 + c(papp3a,papp3b,papp3c,papp3d,papp3e)*PP3 + c(papp4a,papp4b,papp4c,papp4d,papp4e)*PP4 + c(papp5a,papp5b,papp5c,papp5d,papp5e)*PP5 + c(papp6a,papp6b,papp6c,papp6d,papp6e)*PP6 + c(papp7a,papp7b,papp7c,papp7d,papp7e)*PP7 + c(papp8a,papp8b,papp8c,papp8d,papp8e)*PP8 + c(papp9a,papp9b,papp9c,papp9d,papp9e)*PP9 + c(papp10a,papp10b,papp10c,papp10d,papp10e)*PP10 + c(pairb1a,pairb1b,pairb1c,pairb1d,pairb1e)*IRB1 + c(pairb2a,pairb2b,pairb2c,pairb2d,pairb2e)*IRB2 + c(pairb3a,pairb3b,pairb3c,pairb3d,pairb3e)*IRB3 + c(pairb4a,pairb4b,pairb4c,pairb4d,pairb4e)*IRB4 + c(paocbi1a,paocbi1b,paocbi1c,paocbi1d,paocbi1e)*OCBI1 + c(paocbi2a,paocbi2b,paocbi2c,paocbi2d,paocbi2e)*OCBI2 + c(paocbi3a,paocbi3b,paocbi3c,paocbi3d,paocbi3e)*OCBI3 + c(paocbi4a,paocbi4b,paocbi4c,paocbi4d,paocbi4e)*OCBI4 + c(paocbi5a,paocbi5b,paocbi5c,paocbi5d,paocbi5e)*OCBI5 + c(paocbi6a,paocbi6b,paocbi6c,paocbi6d,paocbi6e)*OCBI6 + c(paocbi7a,paocbi7b,paocbi7c,paocbi7d,paocbi7e)*OCBI7 + c(paocbo1a,paocbo1b,paocbo1c,paocbo1d,paocbo1e)*OCBO1 + c(paocbo2a,paocbo2b,paocbo2c,paocbo2d,paocbo2e)*OCBO2 + c(paocbo6a,paocbo6b,paocbo6c,paocbo6d,paocbo6e)*OCBO6 + c(paocbo7a,paocbo7b,paocbo7c,paocbo7d,paocbo7e)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are allowed to covary. Conditions are (1) Cover Story Manipulation, (2) Control, (3) Item Randomization, (4) Filler Scales, and (5) Scale Randomization.
PP ~~ c(.321,.401,.532,.534,.466)*IRB
PP ~~ c(.712,.689,.540,.382,.538)*OCBI
PP ~~ c(.758,.617,.572,.469,.440)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(.620,.469,.576,.501,.636)*OCBI
IRB ~~ c(.775,.836,.693,.737,.681)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(.757,.618,.710,.670,.661)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methodru <- cfa(methodru.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodru,methodu) #Method bias attributable to positive affectivity and proximal causes of method variance has not been detected.

#Model 9: Constrain the between-condition factor covariances that are statistically indistinguishable from zero (p > .05; as identified by the best-fitting model (which in this case is the Method U model) to be equal. This helps to see how complex method variance is. For this particular model, only the IRB~OCBI and IRB~OCBO relationships seemingly affected.
methoduu.cfa<- '

##Substantive factors
PP =~ c(pp1a, pp1b, pp1c, pp1d, pp1e)*PP1 + c(pp2a, pp2b, pp2c, pp2d, pp2e)*PP2 + c(pp3a,pp3b, pp3c, pp3d, pp3e)*PP3 + c(pp4a,pp4b, pp4c, pp4d, pp4e)*PP4 + c(pp5a,pp5b, pp5c, pp5d, pp5e)*PP5 + c(pp6a,pp6b, pp6c, pp6d, pp6e)*PP6 + c(pp7a,pp7b, pp7c, pp7d, pp7e)*PP7 + c(pp8a,pp8b, pp8c, pp8d, pp8e)*PP8 + c(pp9a,pp9b, pp9c, pp9d, pp9e)*PP9 + c(pp10a,pp10b, pp10c, pp10d, pp10e)*PP10
IRB =~ c(irb1a,irb1b,irb1c,irb1d,irb1e)*IRB1 + c(irb2a,irb2b,irb2c,irb2d,irb2e)*IRB2 + c(irb3a,irb3b,irb3c,irb3d,irb3e)*IRB3 + c(irb4a,irb4b,irb4c,irb4d,irb4e)*IRB4
OCBI =~ c(ocbi1a,ocbi1b,ocbi1c,ocbi1d,ocbi1e)*OCBI1 + c(ocbi2a,ocbi2b,ocbi2c,ocbi2d,ocbi2e)*OCBI2 + c(ocbi3a,ocbi3b,ocbi3c,ocbi3d,ocbi3e)*OCBI3 + c(ocbi4a,ocbi4b,ocbi4c,ocbi4d,ocbi4e)*OCBI4 + c(ocbi5a,ocbi5b,ocbi5c,ocbi5d,ocbi5e)*OCBI5 + c(ocbi6a,ocbi6b,ocbi6c,ocbi6d,ocbi6e)*OCBI6 + c(ocbi7a,ocbi7b,ocbi7c,ocbi7d,ocbi7e)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b,ocbo1c,ocbo1d,ocbo1e)*OCBO1 + c(ocbo2a,ocbo2b,ocbo2c,ocbo2d,ocbo2e)*OCBO2 + c(ocbo7a,ocbo7b,ocbo7c,ocbo7d,ocbo7e)*OCBO7

##Method factors
PosAff =~ c(1,1,1,1,1)*PA + c(papp1a, papp1b,papp1c,papp1d,papp1e)*PP1 + c(papp2a, papp2b,papp2c,papp2d,papp2e)*PP2 + c(papp3a,papp3b,papp3c,papp3d,papp3e)*PP3 + c(papp4a,papp4b,papp4c,papp4d,papp4e)*PP4 + c(papp5a,papp5b,papp5c,papp5d,papp5e)*PP5 + c(papp6a,papp6b,papp6c,papp6d,papp6e)*PP6 + c(papp7a,papp7b,papp7c,papp7d,papp7e)*PP7 + c(papp8a,papp8b,papp8c,papp8d,papp8e)*PP8 + c(papp9a,papp9b,papp9c,papp9d,papp9e)*PP9 + c(papp10a,papp10b,papp10c,papp10d,papp10e)*PP10 + c(pairb1a,pairb1b,pairb1c,pairb1d,pairb1e)*IRB1 + c(pairb2a,pairb2b,pairb2c,pairb2d,pairb2e)*IRB2 + c(pairb3a,pairb3b,pairb3c,pairb3d,pairb3e)*IRB3 + c(pairb4a,pairb4b,pairb4c,pairb4d,pairb4e)*IRB4 + c(paocbi1a,paocbi1b,paocbi1c,paocbi1d,paocbi1e)*OCBI1 + c(paocbi2a,paocbi2b,paocbi2c,paocbi2d,paocbi2e)*OCBI2 + c(paocbi3a,paocbi3b,paocbi3c,paocbi3d,paocbi3e)*OCBI3 + c(paocbi4a,paocbi4b,paocbi4c,paocbi4d,paocbi4e)*OCBI4 + c(paocbi5a,paocbi5b,paocbi5c,paocbi5d,paocbi5e)*OCBI5 + c(paocbi6a,paocbi6b,paocbi6c,paocbi6d,paocbi6e)*OCBI6 + c(paocbi7a,paocbi7b,paocbi7c,paocbi7d,paocbi7e)*OCBI7 + c(paocbo1a,paocbo1b,paocbo1c,paocbo1d,paocbo1e)*OCBO1 + c(paocbo2a,paocbo2b,paocbo2c,paocbo2d,paocbo2e)*OCBO2 + c(paocbo6a,paocbo6b,paocbo6c,paocbo6d,paocbo6e)*OCBO6 + c(paocbo7a,paocbo7b,paocbo7c,paocbo7d,paocbo7e)*OCBO7
PA ~~ ((1-.925)*0.4259783)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1,1,1,1)*PP
IRB ~~ c(1,1,1,1,1)*IRB
OCBI ~~ c(1,1,1,1,1)*OCBI
OCBO ~~ c(1,1,1,1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). Constrain the factor covariance differences to be equal within factors but vary across factors.
PP ~~ c(ppirba,ppirba,ppirba,ppirba,ppirba)*IRB
PP ~~ c(ppocbia,ppocbia,ppocbia,ppocbia,ppocbia)*OCBI
PP ~~ c(ppocboa,ppocboa,ppocboa,ppocboa,ppocboa)*OCBO
PP ~~ c(0,0,0,0,0)*PosAff
IRB ~~ c(irbocbia,irbocbia,irbocbia,irbocbia,irbocbia)*OCBI
IRB ~~ c(irbocboa,irbocboa,irbocboa,irbocboa,irbocboa)*OCBO
IRB ~~ c(0,0,0,0,0)*PosAff
OCBI ~~ c(ocbioa,ocbioa,ocbioa,ocbioa,ocbioa)*OCBO
OCBI ~~ c(0,0,0,0,0)*PosAff
OCBO ~~ c(0,0,0,0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0,0,0,0)*1
IRB ~ c(0, 0,0,0,0)*1
OCBI ~ c(0, 0,0,0,0)*1
OCBO ~ c(0, 0,0,0,0)*1
'
methoduu <- cfa(methoduu.cfa, group = "COND", data = data2, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(initial, methodu, methodi, methoduc, methodup, methodupi, methoduu, methodru) 

## extract fit indices tables
fitm.initial <- fitmeasures(initial)      #Model 1: Initial model.
fitm.baseline <- fitmeasures(baseline)    #Model 2: Baseline model.
fitm.methodu <- fitmeasures(methodu)      #Model 3: Unconstrained method effects model. (Presence of method effects).
fitm.methodi <- fitmeasures(methodi)      #Model 4: Method effects vary across substantive constructs. (Congeneric vs. Noncongeneric CMV).
fitm.methoduc <- fitmeasures(methoduc)    #Model 5: Constrain method effects to equality across conditions. (Proximal method variance equal across remedied vs. non-remedied).
fitm.methodup <- fitmeasures(methodup)    #Model 6: Constrain substantive factor loadings to be equal across conditions (proximal remedies decontaminate measurement models).
fitm.methodupi <- fitmeasures(methodupi)  #Model 7: Force factor loadings to be equal within factors but vary across factors (congeneric vs. noncongeneric proximal method effects).
fitm.methodru <- fitmeasures(methodru)    #Model 8: Constrain latent covariances to baseline levels in respective conditions (test for method bias).
fitm.methodru <- fitmeasures(methoduu)    #Model 9: Constrain the between-condition factor covariances that are statistically indistinguishable from zero (p > .05).

#Build table
greeks=c(alpha='\u03b1', tau='\u03c4', sigma='\u03c3', beta='\u03b2', gamma='\u03b3', chi='\u03c7', delta='\u0394')
Model <- c("Initial CFA", "Baseline", "Method U", "Method I", "Method Uc", "Method Up", "Method Upi", "Method Ru", "Method Uu")
chi.square <- c(paste0(greeks['chi'],'^2^'))
df <- c("df")
chi.square.p.value <- c("*p* value")
RMSEA <- c("RMSEA")
RMSEA.lower <- c("90% LCL")
RMSEA.upper <- c("90% UCL")
RMSEA.pvalue <- c("RMSEA p value")
SRMR <- c("SRMR")
table <- as.data.frame(cbind(Model,chi.square,df,"p value","CF","RMSEA","90% LCL","90% UCL","RMSEA p value","SRMR"))
colnames(table)[2] <- paste0(greeks['chi'],'^2')
colnames(table)[3] <- df
colnames(table)[4] <- c("p value")
colnames(table)[5] <- c("CFI")
colnames(table)[6] <- RMSEA
colnames(table)[7] <- RMSEA.lower
colnames(table)[8] <- RMSEA.upper
colnames(table)[9] <- RMSEA.pvalue
colnames(table)[10] <- SRMR
#Convert collumns 2 through 9 to numeric.
table$`χ^2` <- as.numeric(table$χ)
table$df <- as.numeric(table$df)
table$`p value` <- as.numeric(table$`p value`)
table$CFI <- as.numeric(table$CFI)
table$RMSEA <- as.numeric(table$RMSEA)
table$`90% LCL` <- as.numeric(table$`90% LCL`)
table$`90% UCL` <- as.numeric(table$`90% UCL`)
table$`RMSEA p value` <- as.numeric(table$`RMSEA p value`)
table$SRMR <- as.numeric(table$SRMR)

#Insert stats
##Chi-Square
table[1,2]<- round(as.numeric(fitMeasures(initial)[3]), digits = 2)
table[2,2]<- round(as.numeric(fitmeasures(baseline)[3]), digits = 2)
table[3,2]<- round(as.numeric(fitmeasures(methodu)[3]), digits = 2)
table[4,2]<- round(as.numeric(fitmeasures(methodi)[3]), digits = 2)
table[5,2]<- round(as.numeric(fitmeasures(methoduc)[3]), digits = 2)
table[6,2]<- round(as.numeric(fitmeasures(methodup)[3]), digits = 2)
table[7,2]<- round(as.numeric(fitmeasures(methodupi)[3]), digits = 2)
table[8,2]<- round(as.numeric(fitmeasures(methodru)[3]), digits = 2)
table[9,2]<- round(as.numeric(fitmeasures(methoduu)[3]), digits = 2)

##df
table[1,3]<- round(as.numeric(fitMeasures(initial)[4]), digits = 2)
table[2,3]<- round(as.numeric(fitmeasures(baseline)[4]), digits = 2)
table[3,3]<- round(as.numeric(fitmeasures(methodu)[4]), digits = 2)
table[4,3]<- round(as.numeric(fitmeasures(methodi)[4]), digits = 2)
table[5,3]<- round(as.numeric(fitmeasures(methoduc)[4]), digits = 2)
table[6,3]<- round(as.numeric(fitmeasures(methodup)[4]), digits = 2)
table[7,3]<- round(as.numeric(fitmeasures(methodupi)[4]), digits = 2)
table[8,3]<- round(as.numeric(fitmeasures(methodru)[4]), digits = 2)
table[9,3]<- round(as.numeric(fitmeasures(methoduu)[4]), digits = 2)

##Chi-Square p value
#Adapt p-values to table.
pvalr <- function(pvals, sig.limit = .001, digits = 3, html = FALSE) {

  roundr <- function(x, digits = 1) {
    res <- sprintf(paste0('%.', digits, 'f'), x)
    zzz <- paste0('0.', paste(rep('0', digits), collapse = ''))
    res[res == paste0('-', zzz)] <- zzz
    res
  }

  sapply(pvals, function(x, sig.limit) {
    if (x < sig.limit)
      if (html)
        return(sprintf('&lt; %s', format(sig.limit))) else
          return(sprintf('< %s', format(sig.limit)))
    if (x > .1)
      return(roundr(x, digits = 2)) else
        return(roundr(x, digits = digits))
  }, sig.limit = sig.limit)
}
table[1,4]<- pvalr(as.numeric(fitMeasures(initial)[5]), digits = 2)
table[2,4]<- pvalr(as.numeric(fitmeasures(baseline)[5]), digits = 2)
table[3,4]<- pvalr(as.numeric(fitmeasures(methodu)[5]), digits = 2)
table[4,4]<- pvalr(as.numeric(fitmeasures(methodi)[5]), digits = 2)
table[5,4]<- pvalr(as.numeric(fitmeasures(methoduc)[5]), digits = 2)
table[6,4]<- pvalr(as.numeric(fitmeasures(methodup)[5]), digits = 2)
table[7,4]<- pvalr(as.numeric(fitmeasures(methodupi)[5]), digits = 2)
table[8,4]<- pvalr(as.numeric(fitmeasures(methodru)[5]), digits = 2)
table[9,4]<- pvalr(as.numeric(fitmeasures(methoduu)[5]), digits = 2)

#CFI
table[1,5]<- round(as.numeric(fitMeasures(initial)[9]), digits = 3)
table[2,5]<- round(as.numeric(fitmeasures(baseline)[9]), digits = 3)
table[3,5]<- round(as.numeric(fitmeasures(methodu)[9]), digits = 3)
table[4,5]<- round(as.numeric(fitmeasures(methodi)[9]), digits = 3)
table[5,5]<- round(as.numeric(fitmeasures(methoduc)[9]), digits = 3)
table[6,5]<- round(as.numeric(fitmeasures(methodup)[9]), digits = 3)
table[7,5]<- round(as.numeric(fitmeasures(methodupi)[9]), digits = 3)
table[8,5]<- round(as.numeric(fitmeasures(methodru)[9]), digits = 3)
table[9,5]<- round(as.numeric(fitmeasures(methoduu)[9]), digits = 3)

##RMSEA
table[1,6]<- round(as.numeric(fitMeasures(initial)[17]), digits = 3)
table[2,6]<- round(as.numeric(fitmeasures(baseline)[17]), digits = 3)
table[3,6]<- round(as.numeric(fitmeasures(methodu)[17]), digits = 3)
table[4,6]<- round(as.numeric(fitmeasures(methodi)[17]), digits = 3)
table[5,6]<- round(as.numeric(fitmeasures(methoduc)[17]), digits = 3)
table[6,6]<- round(as.numeric(fitmeasures(methodup)[17]), digits = 3)
table[7,6]<- round(as.numeric(fitmeasures(methodupi)[17]), digits = 3)
table[8,6]<- round(as.numeric(fitmeasures(methodru)[17]), digits = 3)
table[9,6]<- round(as.numeric(fitmeasures(methoduu)[17]), digits = 3)

#RMSEA lower
table[1,7]<- round(as.numeric(fitMeasures(initial)[18]), digits = 3)
table[2,7]<- round(as.numeric(fitmeasures(baseline)[18]), digits = 3)
table[3,7]<- round(as.numeric(fitmeasures(methodu)[18]), digits = 3)
table[4,7]<- round(as.numeric(fitmeasures(methodi)[18]), digits = 3)
table[5,7]<- round(as.numeric(fitmeasures(methoduc)[18]), digits = 3)
table[6,7]<- round(as.numeric(fitmeasures(methodup)[18]), digits = 3)
table[7,7]<- round(as.numeric(fitmeasures(methodupi)[18]), digits = 3)
table[8,7]<- round(as.numeric(fitmeasures(methodru)[18]), digits = 3)
table[9,7]<- round(as.numeric(fitmeasures(methoduu)[18]), digits = 3)

#RMSEA upper
table[1,8]<- round(as.numeric(fitMeasures(initial)[19]), digits = 3)
table[2,8]<- round(as.numeric(fitmeasures(baseline)[19]), digits = 3)
table[3,8]<- round(as.numeric(fitmeasures(methodu)[19]), digits = 3)
table[4,8]<- round(as.numeric(fitmeasures(methodi)[19]), digits = 3)
table[5,8]<- round(as.numeric(fitmeasures(methoduc)[19]), digits = 3)
table[6,8]<- round(as.numeric(fitmeasures(methodup)[19]), digits = 3)
table[7,8]<- round(as.numeric(fitmeasures(methodupi)[19]), digits = 3)
table[8,8]<- round(as.numeric(fitmeasures(methodru)[19]), digits = 3)
table[9,8]<- round(as.numeric(fitmeasures(methoduu)[19]), digits = 3)

#RMSEA p-value
table[1,9]<- pvalr(as.numeric(fitMeasures(initial)[20]), digits = 3)
table[2,9]<- pvalr(as.numeric(fitmeasures(baseline)[20]), digits = 3)
table[3,9]<- pvalr(as.numeric(fitmeasures(methodu)[20]), digits = 3)
table[4,9]<- pvalr(as.numeric(fitmeasures(methodi)[20]), digits = 3)
table[5,9]<- pvalr(as.numeric(fitmeasures(methoduc)[20]), digits = 3)
table[6,9]<- pvalr(as.numeric(fitmeasures(methodup)[20]), digits = 3)
table[7,9]<- pvalr(as.numeric(fitmeasures(methodupi)[20]), digits = 3)
table[8,9]<- pvalr(as.numeric(fitmeasures(methodru)[20]), digits = 3)
table[9,9]<- pvalr(as.numeric(fitmeasures(methoduu)[20]), digits = 3)

#SRMR
table[1,10]<- round(as.numeric(fitMeasures(initial)[23]), digits = 3)
table[2,10]<- round(as.numeric(fitmeasures(baseline)[23]), digits = 3)
table[3,10]<- round(as.numeric(fitmeasures(methodu)[23]), digits = 3)
table[4,10]<- round(as.numeric(fitmeasures(methodi)[23]), digits = 3)
table[5,10]<- round(as.numeric(fitmeasures(methoduc)[23]), digits = 3)
table[6,10]<- round(as.numeric(fitmeasures(methodup)[23]), digits = 3)
table[7,10]<- round(as.numeric(fitmeasures(methodupi)[23]), digits = 3)
table[8,10]<- round(as.numeric(fitmeasures(methodru)[23]), digits = 3)
table[9,10]<- round(as.numeric(fitmeasures(methoduu)[23]), digits = 3)

#Relable table to table 2.
table2 <- table

#Build table. These codes need to be fixed. 
Model <- c("Initial vs. Baseline","Baseline vs. Method U", "Method U vs. Method I", "Method U vs. Method Uc", "Method U vs. Method Up", "Method U vs. Method Upi", "Method U vs. Method Ru", "Method U vs. Method Uu")
chi.square <- c(paste0(greeks['delta']),paste0(greeks['chi']), "^2^")
df <- c(paste0(greeks['delta']),"df")
chi.square.critical.value <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
table <- as.data.frame(cbind(Model,chi.square,df,chi.square.critical.value,"pvalue"))
colnames(table)[2] <- c(paste0(greeks['chi']))
colnames(table)[3] <- c("df")
colnames(table)[4] <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
colnames(table)[5] <- c("p value")

#Convert collumns 2 through 4 to numeric.
table$χ <- as.numeric(table$χ)    #chi-square
table$df <- as.numeric(table$df)  #df
table$`χ^2^ critical value; 0.05` <- as.numeric(table$`χ^2^ critical value; 0.05`)  #critical-value
table$`p value` <- as.numeric(table$`p value`)

#Insert stats
#Chi-square difference
table[1,2]<- abs(table2$`χ^2`[2] - table2$`χ^2`[1])
table[2,2]<- abs(table2$`χ^2`[2] - table2$`χ^2`[3])
table[3,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[4])
table[4,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[5])
table[5,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[6])
table[6,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[7])
table[7,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[8])
table[8,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[9])

#df difference
table[1,3]<- abs(table2$df[2] - table2$df[1])
table[2,3]<- abs(table2$df[2] - table2$df[3])
table[3,3]<- abs(table2$df[3] - table2$df[4])
table[4,3]<- abs(table2$df[3] - table2$df[5])
table[5,3]<- abs(table2$df[3] - table2$df[6])
table[6,3]<- abs(table2$df[3] - table2$df[7])
table[7,3]<- abs(table2$df[3] - table2$df[8])
table[8,3]<- abs(table2$df[3] - table2$df[9])

#chi-square critical value
table[1,4]<- round(qchisq(.05, table$df[1], lower.tail=FALSE), digits = 2)
table[2,4]<- round(qchisq(.05, table$df[2], lower.tail=FALSE), digits = 2)
table[3,4]<- round(qchisq(.05, table$df[3], lower.tail=FALSE), digits = 2)
table[4,4]<- round(qchisq(.05, table$df[4], lower.tail=FALSE), digits = 2)
table[5,4]<- round(qchisq(.05, table$df[5], lower.tail=FALSE), digits = 2)
table[6,4]<- round(qchisq(.05, table$df[6], lower.tail=FALSE), digits = 2)
table[7,4]<- round(qchisq(.05, table$df[7], lower.tail=FALSE), digits = 2)
table[8,4]<- round(qchisq(.05, table$df[8], lower.tail=FALSE), digits = 2)

#p value
table[1,5]<- pvalr(pchisq(table$χ[1], table$df[1], lower.tail=FALSE), digits = 2)
table[2,5]<- pvalr(pchisq(table$χ[2], table$df[2], lower.tail=FALSE), digits = 2)
table[3,5]<- pvalr(pchisq(table$χ[3], table$df[3], lower.tail=FALSE), digits = 2)
table[4,5]<- pvalr(pchisq(table$χ[4], table$df[4], lower.tail=FALSE), digits = 2)
table[5,5]<- pvalr(pchisq(table$χ[5], table$df[5], lower.tail=FALSE), digits = 2)
table[6,5]<- pvalr(pchisq(table$χ[6], table$df[6], lower.tail=FALSE), digits = 2)
table[7,5]<- pvalr(pchisq(table$χ[7], table$df[7], lower.tail=FALSE), digits = 2)
table[8,5]<- pvalr(pchisq(table$χ[8], table$df[8], lower.tail=FALSE), digits = 2)

#Relable table to table 3.
table3 <- table

#Factor loadings table for Method U.
PT <- inspect(methodu, what = "std")
PT.Control <- PT[["Control"]][["lambda"]]
PT.CSManipulation <- PT[["CSManipulation"]][["lambda"]]
PT.ItemRand <- PT[["ItemRand"]][["lambda"]]
PT.FillerScales <- PT[["FillerScales"]][["lambda"]]
PT.ScaleRand <- PT[["ScaleRand"]][["lambda"]]

##Organize cells
###Control
PTR.p <- round(as.data.frame(PT.Control[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Control)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Control)"
PTR.i <- round(as.data.frame(PT.Control[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Control)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Control)"
PTR.oi <- round(as.data.frame(PT.Control[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Control)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Control)"
PTR.oo <- round(as.data.frame(PT.Control[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Control)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Control)"
PT.Control <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.Control$residualsr <- round(1-(PT.Control$`Substantive Factor Loading (Control)`^2+PT.Control$`Method Factor Loading (Control)`^2), digits = 2)

#CSManipulation
PTR.p <- round(as.data.frame(PT.CSManipulation[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Cover Story)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Cover Story)"
PTR.i <- round(as.data.frame(PT.CSManipulation[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Cover Story)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Cover Story)"
PTR.oi <- round(as.data.frame(PT.CSManipulation[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Cover Story)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Cover Story)"
PTR.oo <- round(as.data.frame(PT.CSManipulation[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Cover Story)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Cover Story)"
PT.CSManipulation <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.CSManipulation$residualsnr <- round(1-(PT.CSManipulation$`Substantive Factor Loading (Cover Story)`^2 + PT.CSManipulation$`Method Factor Loading (Cover Story)`^2), digits = 2)

#Item Randomization
PTR.p <- round(as.data.frame(PT.ItemRand[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Item Randomization)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Item Randomization)"
PTR.i <- round(as.data.frame(PT.ItemRand[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Item Randomization)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Item Randomization)"
PTR.oi <- round(as.data.frame(PT.ItemRand[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Item Randomization)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Item Randomization)"
PTR.oo <- round(as.data.frame(PT.ItemRand[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Item Randomization)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Item Randomization)"
PT.ItemRand <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.ItemRand$residualsnr <- round(1-(PT.ItemRand$`Substantive Factor Loading (Item Randomization)`^2 + PT.ItemRand$`Method Factor Loading (Item Randomization)`^2), digits = 2)

#Filler Scales
PTR.p <- round(as.data.frame(PT.FillerScales[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Filler Scales)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Filler Scales)"
PTR.i <- round(as.data.frame(PT.FillerScales[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Filler Scales)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Filler Scales)"
PTR.oi <- round(as.data.frame(PT.FillerScales[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Filler Scales)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Filler Scales)"
PTR.oo <- round(as.data.frame(PT.FillerScales[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Filler Scales)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Filler Scales)"
PT.FillerScales <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.FillerScales$residualsnr <- round(1-(PT.FillerScales$`Substantive Factor Loading (Filler Scales)`^2 + PT.FillerScales$`Method Factor Loading (Filler Scales)`^2), digits = 2)

#Scale Randomization
PTR.p <- round(as.data.frame(PT.ScaleRand[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Scale Randomization)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Scale Randomization)"
PTR.i <- round(as.data.frame(PT.ScaleRand[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Scale Randomization)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Scale Randomization)"
PTR.oi <- round(as.data.frame(PT.ScaleRand[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Scale Randomization)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Scale Randomization)"
PTR.oo <- round(as.data.frame(PT.ScaleRand[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Scale Randomization)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Scale Randomization)"
PT.ScaleRand <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.ScaleRand$residualsnr <- round(1-(PT.ScaleRand$`Substantive Factor Loading (Scale Randomization)`^2 + PT.ScaleRand$`Method Factor Loading (Scale Randomization)`^2), digits = 2)

#Combine
PT.full <- cbind(PT.Control,PT.CSManipulation,PT.FillerScales,PT.ItemRand,PT.ScaleRand)
#Make PT.full all positive to avoid calculation issues
PT.full <- abs(PT.full)

#Method and substantive reliability table.
Model <- c("Proactive Personality (Control)", "Proactive Personality (Cover Story)", "Proactive Personality (Filler Scales)","Proactive Personality (Item Randomization)","Proactive Personality (Scale Randomization)","In-Role Behavior (Control)", "In-Role Behavior (Cover Story)", "In-Role Behavior (Filler Scales)","In-Role Behavior (Item Randomization)","In-Role Behavior (Scale Randomization)", "Org. Citizenship (Org.) (Control)", "Org. Citizenship (Org.) (Cover Story)", "Org. Citizenship (Org.) (Filler Scales)","Org. Citizenship (Org.) (Item Randomization)","Org. Citizenship (Org.) (Scale Randomization)","Org. Citizenship (Ind.) (Control)", "Org. Citizenship (Ind.) (Cover Story)", "Org. Citizenship (Ind.) (Filler Scales)","Org. Citizenship (Ind.) (Item Randomization)","Org. Citizenship (Ind.) (Scale Randomization)")
table <- as.data.frame(cbind(Model,"V1","V2","V3","V4"))
colnames(table)[1] <- c("Latent Variable")
colnames(table)[2] <- c("Total Reliability")
colnames(table)[3] <- c("Substantive Reliability")
colnames(table)[4] <- c("Method Reliability")
colnames(table)[5] <- c("% Reliable Method Variance")

#Convert collumns 2 through 5 to numeric.
table$`Total Reliability` <- as.numeric(table$`Total Reliability`)
table$`Substantive Reliability` <- as.numeric(table$`Substantive Reliability`)
table$`Method Reliability` <- as.numeric(table$`Method Reliability`)
table$`% Reliable Method Variance` <- as.numeric(table$`% Reliable Method Variance`)
table$`Total Reliability` <- as.numeric(table$`Total Reliability`)
table$`Substantive Reliability` <- as.numeric(table$`Substantive Reliability`)
table$`Method Reliability` <- as.numeric(table$`Method Reliability`)
table$`% Reliable Method Variance` <- as.numeric(table$`% Reliable Method Variance`)

#Insert stats
##Substantive Reliability: Control
table[1,3]<- round(sum(PT.full$`Substantive Factor Loading (Control)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[1:10])^2+sum(PT.full$`Method Factor Loading (Control)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[6,3]<- round(sum(PT.full$`Substantive Factor Loading (Control)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[11:17])^2+sum(PT.full$`Method Factor Loading (Control)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[11,3]<- round(sum(PT.full$`Substantive Factor Loading (Control)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[18:24])^2+sum(PT.full$`Method Factor Loading (Control)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[16,3]<- round(sum(PT.full$`Substantive Factor Loading (Control)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[25:31])^2+sum(PT.full$`Method Factor Loading (Control)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Control
table[1,4]<- round(sum(PT.full$`Method Factor Loading (Control)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[1:10])^2+sum(PT.full$`Method Factor Loading (Control)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[6,4]<- round(sum(PT.full$`Method Factor Loading (Control)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[11:17])^2+sum(PT.full$`Method Factor Loading (Control)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[11,4]<- round(sum(PT.full$`Method Factor Loading (Control)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[18:24])^2+sum(PT.full$`Method Factor Loading (Control)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[16,4]<- round(sum(PT.full$`Method Factor Loading (Control)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Control)`[25:31])^2+sum(PT.full$`Method Factor Loading (Control)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Control
table[1,2] <- sum(table[1,3],table[1,4])
table[6,2] <- sum(table[6,3],table[6,4])
table[11,2] <- sum(table[11,3],table[11,4])
table[16,2] <- sum(table[16,3],table[16,4])

##% Reliable Method Variance: Control
table[1,5] <- round(table[1,4]/table[1,2], digits = 2)
table[6,5] <- round(table[6,4]/table[6,2], digits = 2)
table[11,5] <- round(table[11,4]/table[11,2], digits = 2)
table[16,5] <- round(table[16,4]/table[16,2], digits = 2)

##Substantive Reliability: Cover Story
table[2,3]<- round(sum(PT.full$`Substantive Factor Loading (Cover Story)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[1:10])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[7,3]<- round(sum(PT.full$`Substantive Factor Loading (Cover Story)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[11:17])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[12,3]<- round(sum(PT.full$`Substantive Factor Loading (Cover Story)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[18:24])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[17,3]<- round(sum(PT.full$`Substantive Factor Loading (Cover Story)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[25:31])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Cover Story
table[2,4]<- round(sum(PT.full$`Method Factor Loading (Cover Story)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[1:10])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[7,4]<- round(sum(PT.full$`Method Factor Loading (Cover Story)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[11:17])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[12,4]<- round(sum(PT.full$`Method Factor Loading (Cover Story)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[18:24])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[17,4]<- round(sum(PT.full$`Method Factor Loading (Cover Story)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Cover Story)`[25:31])^2+sum(PT.full$`Method Factor Loading (Cover Story)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Cover Story
table[2,2] <- sum(table[2,3],table[2,4])
table[7,2] <- sum(table[7,3],table[7,4])
table[12,2] <- sum(table[12,3],table[12,4])
table[17,2] <- sum(table[17,3],table[17,4])

##% Reliable Method Variance: Cover Story
table[2,5] <- round(table[2,4]/table[2,2], digits = 2)
table[7,5] <- round(table[7,4]/table[7,2], digits = 2)
table[12,5] <- round(table[12,4]/table[12,2], digits = 2)
table[17,5] <- round(table[17,4]/table[17,2], digits = 2)

##Substantive Reliability: Filler Scales
table[3,3]<- round(sum(PT.full$`Substantive Factor Loading (Filler Scales)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[1:10])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[8,3]<- round(sum(PT.full$`Substantive Factor Loading (Filler Scales)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[11:17])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[13,3]<- round(sum(PT.full$`Substantive Factor Loading (Filler Scales)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[18:24])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[18,3]<- round(sum(PT.full$`Substantive Factor Loading (Filler Scales)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[25:31])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Filler Scales
table[3,4]<- round(sum(PT.full$`Method Factor Loading (Filler Scales)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[1:10])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[8,4]<- round(sum(PT.full$`Method Factor Loading (Filler Scales)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[11:17])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[13,4]<- round(sum(PT.full$`Method Factor Loading (Filler Scales)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[18:24])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[18,4]<- round(sum(PT.full$`Method Factor Loading (Filler Scales)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Filler Scales)`[25:31])^2+sum(PT.full$`Method Factor Loading (Filler Scales)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Filler Scales
table[3,2] <- sum(table[3,3],table[3,4])
table[8,2] <- sum(table[8,3],table[8,4])
table[13,2] <- sum(table[13,3],table[13,4])
table[18,2] <- sum(table[18,3],table[18,4])

##% Reliable Method Variance: Filler Scales
table[3,5] <- round(table[3,4]/table[3,2], digits = 2)
table[8,5] <- round(table[8,4]/table[8,2], digits = 2)
table[13,5] <- round(table[13,4]/table[13,2], digits = 2)
table[18,5] <- round(table[18,4]/table[18,2], digits = 2)

##Substantive Reliability: Item Randomization
table[4,3]<- round(sum(PT.full$`Substantive Factor Loading (Item Randomization)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[1:10])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[9,3]<- round(sum(PT.full$`Substantive Factor Loading (Item Randomization)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[11:17])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[14,3]<- round(sum(PT.full$`Substantive Factor Loading (Item Randomization)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[18:24])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[19,3]<- round(sum(PT.full$`Substantive Factor Loading (Item Randomization)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[25:31])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Item Randomization
table[4,4]<- round(sum(PT.full$`Method Factor Loading (Item Randomization)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[1:10])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[9,4]<- round(sum(PT.full$`Method Factor Loading (Item Randomization)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[11:17])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[14,4]<- round(sum(PT.full$`Method Factor Loading (Item Randomization)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[18:24])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[19,4]<- round(sum(PT.full$`Method Factor Loading (Item Randomization)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Item Randomization)`[25:31])^2+sum(PT.full$`Method Factor Loading (Item Randomization)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Item Randomization
table[4,2] <- sum(table[4,3],table[4,4])
table[9,2] <- sum(table[9,3],table[9,4])
table[14,2] <- sum(table[14,3],table[14,4])
table[19,2] <- sum(table[19,3],table[19,4])

##% Reliable Method Variance: Item Randomization
table[4,5] <- round(table[4,4]/table[4,2], digits = 2)
table[9,5] <- round(table[9,4]/table[9,2], digits = 2)
table[14,5] <- round(table[14,4]/table[14,2], digits = 2)
table[19,5] <- round(table[19,4]/table[19,2], digits = 2)

##Substantive Reliability: Scale Randomization
table[5,3]<- round(sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[1:10])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[10,3]<- round(sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[11:17])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[15,3]<- round(sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[18:24])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[20,3]<- round(sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[25:31])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Scale Randomization
table[5,4]<- round(sum(PT.full$`Method Factor Loading (Scale Randomization)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[1:10])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[10,4]<- round(sum(PT.full$`Method Factor Loading (Scale Randomization)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[11:17])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[15,4]<- round(sum(PT.full$`Method Factor Loading (Scale Randomization)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[18:24])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[20,4]<- round(sum(PT.full$`Method Factor Loading (Scale Randomization)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Scale Randomization)`[25:31])^2+sum(PT.full$`Method Factor Loading (Scale Randomization)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Scale Randomization
table[5,2] <- sum(table[5,3],table[5,4])
table[10,2] <- sum(table[10,3],table[10,4])
table[15,2] <- sum(table[15,3],table[15,4])
table[20,2] <- sum(table[20,3],table[20,4])

##% Reliable Method Variance: Scale Randomization
table[5,5] <- round(table[5,4]/table[5,2], digits = 2)
table[10,5] <- round(table[10,4]/table[10,2], digits = 2)
table[15,5] <- round(table[15,4]/table[15,2], digits = 2)
table[20,5] <- round(table[20,4]/table[20,2], digits = 2)

#Relable table to table 4.
table4 <- table
```
```{r Table 5 Descriptives Study 2, include = TRUE}
table1 <- apa.cor.table(scales)
```
```{r Table 6 Model-Data Fit Study 2, include = TRUE}
table2
```
```{r Table 7 Model-Comparison Table Study 2, include = TRUE}
table3
```
```{r Table 8 Variance Decomposition Study 2, include = TRUE}
table4
```
##Study 3 - Temporal Separation of Measures
#Method - Study 3
##Sample
```{r Load Study 3 Data, include=FALSE}
data3 <- read_sav("Datasets/Study 3.sav")

#Address the misnamed OCB variables. Fix OCBO ordering to align with other datasets.
colnames(data3)[colnames(data3)=="OCBI7"] <- "OCBO1new"
colnames(data3)[colnames(data3)=="OCBO7"] <- "OCBI7new"
colnames(data3)[colnames(data3)=="OCBO6"] <- "OCBO7"
colnames(data3)[colnames(data3)=="OCBO5"] <- "OCBO6"
colnames(data3)[colnames(data3)=="OCBO4"] <- "OCBO5"
colnames(data3)[colnames(data3)=="OCBO3"] <- "OCBO4"
colnames(data3)[colnames(data3)=="OCBO2"] <- "OCBO3"
colnames(data3)[colnames(data3)=="OCBO1"] <- "OCBO2"
colnames(data3)[colnames(data3)=="OCBO1new"] <- "OCBO1"
colnames(data3)[colnames(data3)=="OCBI7new"] <- "OCBI7"

#Re-order variables.
data3 <- data3[c(2,3,87,88,89,4:13,30:35,43,37:42,36,44:50,60:79)]

#Analyses revealed that some cases of data had been imputed. Missing data appears to have been dealt with by simply imputing an average of sorts. This could be problematic (see Enders, C. K. (2003). Using the expectation maximization algorithm to estimate coefficient alpha for scales with item-level missing data. Psychological Methods, 8(3), 322-337.; Enders, C. K. (2010). Applied missing data analysis: New York, NY: The Guilford Press. Additionally, and more importantly, the required estimation methods are not maximum likelihood but are ordinal, further requiring the each response category be represented (i.e., averages do not fall into a particular response category).  Reversing this decision:
data3$PA2[data3$PA2==3.23] <- NA
data3$PA5[data3$PA5==3.58] <- NA
data3$PA6[data3$PA6==3.59] <- NA
data3$PA8[data3$PA8==3.77] <- NA
data3$PA9[data3$PA9==3.75] <- NA
data3$PA10[data3$PA10==3.57] <- NA
data3$PA3[data3$PA3==3.44] <- NA
data3$PA4[data3$PA4==3.56] <- NA
data3$PA7[data3$PA7==3.45] <- NA
data3$NA9[data3$NA9==1.87] <- NA
data3$NA2[data3$NA2==3.23] <- NA
data3$NA3[data3$NA3==1.72] <- NA
data3$NA6[data3$NA6==2.17] <- NA
data3$NA7[data3$NA7==1.57] <- NA
data3$NA8[data3$NA8==2.11] <- NA
data3$PP1[data3$PP1==3.49] <- NA
data3$PP3[data3$PP3==3.92] <- NA
data3$PP3[data3$PP3==0] <- NA
data3$PP8[data3$PP8==3.57] <- NA
data3$PP9[data3$PP9==3.53] <- NA
data3$PP10[data3$PP10==3.45] <- NA
data3$IRB1[data3$IRB1==4.47] <- NA
data3$IRB2[data3$IRB2==4.47] <- NA
data3$IRB4[data3$IRB4==4.49] <- NA
data3$IRB5[data3$IRB5==3.59] <- NA
data3$IRB5[data3$IRB5==3.96] <- NA
data3$IRB6[data3$IRB6==1.88] <- NA
data3$IRB7[data3$IRB7==1.65] <- NA
data3$IRB7[data3$IRB7==0] <- NA
data3$OCBI3[data3$OCBI3==3.7] <- NA
data3$OCBI3[data3$OCBI3==0] <- NA
data3$OCBI5[data3$OCBI5==3.99] <- NA
data3$OCBI7[data3$OCBI7==4.06] <- NA
data3$OCBO2[data3$OCBO2==4.24] <- NA
data3$OCBO4[data3$OCBO4==1.92] <- NA
data3$OCBO4[data3$OCBO4==0] <- NA
data3$OCBO5[data3$OCBO5==2.12] <- NA
data3$OCBO5[data3$OCBO5==0] <- NA
data3$OCBO6[data3$OCBO6==2.12] <- NA
data3$OCBO7[data3$OCBO7==3.89] <- NA

#Examine missingness pattern.
#MDAplot <-  aggr(data3, col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(data3), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
#Delete cases who did not complete the didn't complete the demographic questionnaire.
data3 <- data3[-c(38,94,141,153,161,165,170,183,188,190,193,195,196,231,300),]
#MDAplot <-  aggr(data3, col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(data3), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
#MDA <- LittleMCAR(data3[c(6:31,33:56)]) #Only 50 items can be analyzed, so one item with full data was dropped from the analysis. 

##Thirty six missing data patterns and a just significant LittleMCAR test suggest that data may not be MCAR. Though imputation is used to fill in gaps, this should be taken as a limitation.

#Count of individuals who agree to participate.
N1 <- as.numeric(freq_vect(data3$COND)[1,"Count"])  #Cross-sectional/Control
N2 <- as.numeric(freq_vect(data3$COND)[2,"Count"])  #Temporal Separation of Measurement

#Missing data analysis using 'sapply(data3, function(x) sum(is.na(x)))' which likert data were missing. 
init <- mice(data3, maxit = 0)
meth <- init$method
predM <- init$predictorMatrix
meth[c("PP1")]="norm"
meth[c("PP3")]="norm"
meth[c("PP8")]="norm"
meth[c("PP9")]="norm"
meth[c("PP10")]="norm"
meth[c("OCBI3")]="norm"
meth[c("OCBI5")]="norm"
meth[c("OCBO1")]="norm"
meth[c("OCBO3")]="norm"
meth[c("OCBO4")]="norm"
meth[c("OCBO5")]="norm"
meth[c("OCBO6")]="norm"
meth[c("OCBO7")]="norm"
meth[c("IRB2")]="norm"
meth[c("IRB4")]="norm"
meth[c("IRB5")]="norm"
meth[c("IRB6")]="norm"
meth[c("IRB7")]="norm"
meth[c("PA1")]="norm"
meth[c("PA2")]="norm"
meth[c("PA3")]="norm"
meth[c("PA4")]="norm"
meth[c("PA5")]="norm"
meth[c("PA6")]="norm"
meth[c("PA7")]="norm"
meth[c("PA8")]="norm"
meth[c("PA9")]="norm"
meth[c("PA10")]="norm"
meth[c("NA1")]="norm"
meth[c("NA2")]="norm"
meth[c("NA3")]="norm"
meth[c("NA4")]="norm"
meth[c("NA5")]="norm"
meth[c("NA6")]="norm"
meth[c("NA7")]="norm"
meth[c("NA8")]="norm"
meth[c("NA9")]="norm"
meth[c("NA10")]="norm"
imputed <- mice(data3, method=meth, predictorMatrix=predM, m=5)
data3 <- complete(imputed)
#Round imputed data to nearest whole number for estimation purposes. 
data3$PP1 <- ceiling(data3$PP1)
data3$PP3 <- ceiling(data3$PP3)
data3$PP8 <- ceiling(data3$PP8)
data3$PP9 <- ceiling(data3$PP9)
data3$PP10 <- ceiling(data3$PP10)
data3$OCBI3 <- ceiling(data3$OCBI3)
data3$OCBI5 <- ceiling(data3$OCBI5)
data3$OCBO1 <- ceiling(data3$OCBO1)
data3$OCBO3 <- ceiling(data3$OCBO3)
data3$OCBO4 <- ceiling(data3$OCBO4)
data3$OCBO5 <- ceiling(data3$OCBO5)
data3$OCBO6 <- ceiling(data3$OCBO6)
data3$OCBO7 <- ceiling(data3$OCBO7)
data3$IRB2 <- ceiling(data3$IRB2)
data3$IRB4 <- ceiling(data3$IRB4)
data3$IRB5 <- ceiling(data3$IRB5)
data3$IRB6 <- ceiling(data3$IRB6)
data3$IRB7 <- ceiling(data3$IRB7)
data3$PA1 <- ceiling(data3$PA1)
data3$PA2 <- ceiling(data3$PA2)
data3$PA3 <- ceiling(data3$PA3)
data3$PA4 <- ceiling(data3$PA4)
data3$PA5 <- ceiling(data3$PA5)
data3$PA6 <- ceiling(data3$PA6)
data3$PA7 <- ceiling(data3$PA7)
data3$PA8 <- ceiling(data3$PA8)
data3$PA9 <- ceiling(data3$PA9)
data3$PA10 <- ceiling(data3$PA10)
data3$NA1 <- ceiling(data3$NA1)
data3$NA2 <- ceiling(data3$NA2)
data3$NA3 <- ceiling(data3$NA3)
data3$NA4 <- ceiling(data3$NA4)
data3$NA5 <- ceiling(data3$NA5)
data3$NA6 <- ceiling(data3$NA6)
data3$NA7 <- ceiling(data3$NA7)
data3$NA8 <- ceiling(data3$NA8)
data3$NA9 <- ceiling(data3$NA9)
data3$NA10 <- ceiling(data3$NA10)

#Setup demographics.
#Rename variables.
colnames(data3)[colnames(data3)=="SEX"] <- "GENDER"

#Calculate descriptives
M <- mean(data3$AGE, na.rm = TRUE)
SD <- sd(data3$AGE, na.rm = TRUE)

#Calculate frequencies
##Recode single "f" to female. 
data3$GENDER[data3$GENDER=="f"] <- 1
female.n <- as.numeric(freq_vect(data3$GENDER)[2,"Count"])
female.p <- as.numeric(freq_vect(data3$GENDER)[2,"Percentage"])
white.n <- as.numeric(freq_vect(data3$RACE)[2,"Count"])
white.p <- as.numeric(freq_vect(data3$RACE)[2,"Percentage"])
fulltime.n <- as.numeric(freq_vect(data3$PartFullTime)[2,"Count"])
fulltime.p <- as.numeric(freq_vect(data3$PartFullTime)[2,"Percentage"])

#Cronbach Alphas
#Create scale scores
my.keys.list <- list(PP=c("PP1","PP2","PP3","PP4","PP5","PP6","PP7","PP8","PP9","PP10"),
                     IRB=c("IRB1","IRB2","IRB3","IRB4","IRB5","-IRB6","-IRB7"),
                     OCBI=c("OCBI1","OCBI2","OCBI3","OCBI4","OCBI5","OCBI6","OCBI7"),
                     OCBO=c("OCBO1","OCBO2","-OCBO3","-OCBO4","-OCBO5","OCBO6","OCBO7"),
                     PA=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10"),
                     Na=c("NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     AP=c("PA1","PA2","PA3","PA4","PA5","PA6","PA7","PA8","PA9","PA10","NA1","NA2","NA3","NA4","NA5","NA6","NA7","NA8","NA9","NA10"),
                     NIW=c("IRB6","IRB7","OCBO3","OCBO4","OCBO5"))
my.scales <- scoreItems(my.keys.list,data3)
PP.alpha <- my.scales[["alpha"]][1]
IRB.alpha <- my.scales[["alpha"]][2]
OCBI.alpha <- my.scales[["alpha"]][3]
OCBO.alpha <- my.scales[["alpha"]][4]
PA.alpha <- my.scales[["alpha"]][5]
Na.alpha <- my.scales[["alpha"]][6]
AP.alpha <- my.scales[["alpha"]][7]
NIW.alpha <- my.scales[["alpha"]][9]
```
  Participants were recruited using a SurveyMonkey panel and randomly assigned to a condition where they received all measures at the same time (i.e., control) or a condition whereby a temporal separation of one week was used to divide the adminstration of predictor and criterion measures. All respondents received $5 to complete this survey. Fifteen respondents did not answer demographic questions and were  For the temporal remedy condition (n = `r apa(N2,0,T)`), after one week, the in-role behavior and OCB measures were administered along with a measure of positive and negative affectivity and the demographics questionnaire.OCB. Additionally, anticipating a significant amount of attrition in temporal separation condition, we requested that individuals twice as many in the longitudinal condition to end up with roughly equal sample sizes. For the cross-sectional data (n = `r apa(N1,0,T)`), respondents completed all measures at the same point in time. Notwithstanding missing demographic data, the sample was female biased (n = `r apa(female.n,0,T)`, `r apa(female,2,T)`), predominantly Caucasian, and  the average age was *M* = `r apa(M,2,T)` (*SD* = `r apa(SD,2,T)`). The majority (n = `r apa(fulltime.n,0,T)`, *f* = `r apa(fulltime.p,2,T)`) of respondents worked full-time. The same measures used in study 1 and 2 were used in study 3. Cronbach alphas ranged from `r apa(OCBO.alpha)` for OCBO to `r apa(NA.alpha)` for negative affectivity. Again, cases of missing item level data were handled using the normal model approach [see @WuComparisonImputationStrategies2015]. 

##Analytical Approach
  We used established measured method effect techniques to assess the presence and biasing role of momentary affect [@WilliamsMethodVarianceMarker2010]. Similar to study 1, our expectations were that method effects attributable to momentary affect would be stronger in our control condition because, as all measures were administered simultaneously, mood would act as a constant contaminating factor. In other words, we expect to observe significant measurement contamination attributable to momentary mood in the form of significant and positive path coefficients linking momentary affect to the indicators of our measurement model, which are expectations consistent with prior research [@Williamsalternativeapproachmethod1994]. Furthermore, we expected that momentary positive affect would result in biased estimates of correlation.

  Conversely, we expected momentary affect to have virtually no effect in our remedied condition involving a 1-week temporal separation. This pattern would suggest that CMV attributable to affect would be present in a same-source same-time-point survey (hypothesis 1a). Evidence of bias attributable to momentary affect would emerge if the interconstruct correlations varied as a function of momentary affect effects. Thus, supporting hypothesis 1b would provide evidence supporting the viability of a one-week temporal separation for reducing affect effects. Again, we employed @WilliamsMethodVarianceMarker2010 measured method effects technique, which involve a series of nested model comparisons under different assumptions of method variance presence (i.e., CMV is not present, non equal/noncongeneric CMV is present, unequal/congeneric CMV is present) and bias (i.e., no bias or significant bias) while also examiing the non-invariance of our measurement model.

  Following study 1, we carried out our analyses using 'lavaan' in R and used robust maximum likelihood estimation (maximum likelihood estimation with robust standard errors) [see @LiConfirmatoryfactoranalysis2016] and the same modeling assumptions were applied (i.e., negative method factor, correlated residuals, factor loadings, and latent construct correlations). Satorra-Bentler X2 difference testing was, again, used to compare our models.

#Results - Study 3
```{r Temporal Separation Substantive Analyses, include=FALSE}
method.cfa <- '
#Method factors
  PA =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 
  Na =~ NA*NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10
  AP =~ NA*PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 + NA1 + NA2 + NA3 + NA4 + NA5 + NA6 + NA7 + NA8 + NA9 + NA10

#set covariances for bifactor to zero
  PA ~~ 0*Na
  PA ~~ 0*AP
  Na ~~ 0*AP

#set variances to be 1.
  PA ~~ 1*PA
  Na ~~ 1*Na
  AP ~~ 1*AP

#Factor means of the first group are fixed as 0. The factor means of the other groups are freely estimated. 
##Method factors
  PA ~ 0
  Na ~ 0
  AP ~ 0
'
#To see the results of an anlysis of the discriminant validity of the measurement model, see the following object. 
method <- cfa(model = method.cfa, data = data3, parameterization = "theta", estimator = "dwls", information = "expected")
#Get method factor scores
df <- predict(method)

#bind to dataframe
data3 <- cbind(data3,df)

#Note: certain response categories are too few for the estimator to work.  Specifically, the "strongly disagree" and "disagree" response options were simply combined to reflect a "disagree" option. So I combined them:

##Model 1 <- Initial Model
initial.cfa <- '
##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). 
PP ~~ c(ppirba,ppirbb)*IRB
PP ~~ c(ppocbia,ppocbib)*OCBI
PP ~~ c(ppocboa,ppocbob)*OCBO
PP ~~ c(pppaa,pppab)*PosAff
IRB ~~ c(irbocbia,irbocbib)*OCBI
IRB ~~ c(irbocboa,irbocbob)*OCBO
IRB ~~ c(irbpaa,irbpab)*PosAff
OCBI ~~ c(ocbioa,ocbiob)*OCBO
OCBI ~~ c(ocbipaa,ocbipab)*PosAff
OCBO ~~ c(ocbopaa,ocbopab)*PosAff

#Compute factor covariance differences 
ppirbc := ppirba-ppirbb
ppocbic := ppocbia-ppocbib
ppocboc := ppocboa-ppocbob
pppac := pppaa-pppab
irbocbic := irbocbia-irbocbib
irbocboc := irbocboa-irbocbob
irbpac := irbpaa-irbpab
ocbioc := ocbioa-ocbiob
ocbipac := ocbipaa-ocbipab
ocbopac := ocbopaa-ocbopab

#Factor means of latent factors for both groups are fixed at zero to allow identification, with the exception of the composite indicators.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
initial <- cfa(initial.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)

#Model 2: Baseline. Method and substantive covariances are constrained to zero. Method effects are constrained to zero.
baseline.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factor covariances are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
baseline <- cfa(baseline.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(initial, baseline) #As expected, baseline is much worse. 

#Model 3: Method U model. Freely estimate method effects across groups. Tests for the pressence of method effects attributable to a common sources of variance (proximal causes and positive affectivity). Method effects are allowed to vary across conditions. Factor differences in factor loadings and covariances have been computed to facilitate interpretation of method effects. 
methodu.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1b)*PP1 + c(papp2a, papp2b)*PP2 + c(papp3a,papp3b)*PP3 + c(papp4a,papp4b)*PP4 + c(papp5a,papp5b)*PP5 + c(papp6a,papp6b)*PP6 + c(papp7a,papp7b)*PP7 + c(papp8a,papp8b)*PP8 + c(papp9a,papp9b)*PP9 + c(papp10a,papp10b)*PP10 + c(pairb1a,pairb1b)*IRB1 + c(pairb2a,pairb2b)*IRB2 + c(pairb3a,pairb3b)*IRB3 + c(pairb4a,pairb4b)*IRB4 + c(paocbi1a,paocbi1b)*OCBI1 + c(paocbi2a,paocbi2b)*OCBI2 + c(paocbi3a,paocbi3b)*OCBI3 + c(paocbi4a,paocbi4b)*OCBI4 + c(paocbi5a,paocbi5b)*OCBI5 + c(paocbi6a,paocbi6b)*OCBI6 + c(paocbi7a,paocbi7b)*OCBI7 + c(paocbo1a,paocbo1b)*OCBO1 + c(paocbo2a,paocbo2b)*OCBO2 + c(paocbo6a,paocbo6b)*OCBO6 + c(paocbo7a,paocbo7b)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences 
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a
papp1c	:=	papp1b	-	papp1a
papp2c	:=	papp2b	-	papp2a
papp3c	:=	papp3b	-	papp3a
papp4c	:=	papp4b	-	papp4a
papp5c	:=	papp5b	-	papp5a
papp6c	:=	papp6b	-	papp6a
papp7c	:=	papp7b	-	papp7a
papp8c	:=	papp8b	-	papp8a
papp9c	:=	papp9b	-	papp9a
papp10c	:=	papp10b	-	papp10a
pairb1c	:=	pairb1b	-	pairb1a
pairb2c	:=	pairb2b	-	pairb2a
pairb3c	:=	pairb3b	-	pairb3a
pairb4c	:=	pairb4b	-	pairb4a
paocbi1c	:=	paocbi1b	-	paocbi1a
paocbi2c	:=	paocbi2b	-	paocbi2a
paocbi3c	:=	paocbi3a	-	paocbi3b
paocbi4c	:=	paocbi4b	-	paocbi4a
paocbi5c	:=	paocbi5b	-	paocbi5a
paocbi6c	:=	paocbi6b	-	paocbi6a
paocbi7c	:=	paocbi7b	-	paocbi7a
paocbo1c	:=	paocbo1b	-	paocbo1a
paocbo2c	:=	paocbo2b	-	paocbo2a
paocbo6c	:=	paocbo6b	-	paocbo6a
paocbo7c	:=	paocbo7b	-	paocbo7a

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Compute factor covariances differences.
PPIRB3 := PPIRB1-PPIRB2
PPOCBI3 := PPOCBI1-PPOCBI2
PPOCBO13 := PPOCBO1-PPOCBO2
IRBOCBI3 := IRBOCBI1-IRBOCBI2
IRBOCBO3 := IRBOCBO1-IRBOCBO2
OCBIO3 := OCBIO1-OCBIO2

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodu <- cfa(methodu.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(baseline,methodu) #Method variance attributable to positive affectivity has been identified. 

#Model 4: Method I model. Constrain estimates of method effects to be equal within substantive variables but different across substantive variables. This tests whether method effects attributable to positive affectivity are present to an equal degree within a given factor but vary across different factors.
methodi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp1a, papp1a)*PP2 + c(papp1a,papp1a)*PP3 + c(papp1a,papp1a)*PP4 + c(papp1a,papp1a)*PP5 + c(papp1a,papp1a)*PP6 + c(papp1a,papp1a)*PP7 + c(papp1a,papp1a)*PP8 + c(papp1a,papp1a)*PP9 + c(papp1a,papp1a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb1a,pairb1a)*IRB2 + c(pairb1a,pairb1a)*IRB3 + c(pairb1a,pairb1a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi1a,paocbi1a)*OCBI2 + c(paocbi1a,paocbi1a)*OCBI3 + c(paocbi1a,paocbi1a)*OCBI4 + c(paocbi1a,paocbi1a)*OCBI5 + c(paocbi1a,paocbi1a)*OCBI6 + c(paocbi1a,paocbi1a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo1a,paocbo1a)*OCBO2 + c(paocbo1a,paocbo1a)*OCBO6 + c(paocbo1a,paocbo1a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. 
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodi <- cfa(methodi.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodi,methodu) #Method variance is congeneric across substantive items. 

#Model 5: Method UC model. Constrain estimates of method effects, which are freely estimated across all factors (i.e., method u), to be equal across conditions. This is done by making the method factor loadings equal across conditions and tests whether method variance attributable to positive affectivity is equally present across conditions. 
methoduc.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp2a, papp2a)*PP2 + c(papp3a,papp3a)*PP3 + c(papp4a,papp4a)*PP4 + c(papp5a,papp5a)*PP5 + c(papp6a,papp6a)*PP6 + c(papp7a,papp7a)*PP7 + c(papp8a,papp8a)*PP8 + c(papp9a,papp9a)*PP9 + c(papp10a,papp10a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences. Done for interpretation purposes. 
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methoduc <- cfa(methoduc.cfa,group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methoduc,methodu) #Method variance attributable to positive affectivity does not vary across the two conditions. Method uc constraints retained. 

#Model 6: Method UP model. Constrain substantive factor loadings to be equal across conditions but free across factors and within factors. This tests the hypothesis that proximal remedies do or do not cause a difference in the factor loadings of our measurement model. If this model is equivalent to methodu, then proximal remedies do not cause a meaningful difference in factor loadings. 

methodup.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4 
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp2a, papp2a)*PP2 + c(papp3a,papp3a)*PP3 + c(papp4a,papp4a)*PP4 + c(papp5a,papp5a)*PP5 + c(papp6a,papp6a)*PP6 + c(papp7a,papp7a)*PP7 + c(papp8a,papp8a)*PP8 + c(papp9a,papp9a)*PP9 + c(papp10a,papp10a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Constrain substantive factor loadings to equality. 
pp1a==pp1b
pp2a==pp2b
pp3a==pp3b
pp4a==pp4b
pp5a==pp5b
pp6a==pp6b
pp7a==pp7b
pp8a==pp8b
pp9a==pp9b
pp10a==pp10b
irb1a==irb1b
irb2a==irb2b
irb3a==irb3b
irb4a==irb4b
ocbi1a==ocbi1b
ocbi2a==ocbi2b
ocbi3a==ocbi3b
ocbi4a==ocbi4b
ocbi5a==ocbi5b
ocbi6a==ocbi6b
ocbi7a==ocbi7b
ocbo1a==ocbo1b
ocbo2a==ocbo2b
ocbo6a==ocbo6b
ocbo7a==ocbo7b

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodup <- cfa(methodup.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodup,methoduc) #Method variance attributable to other proximal causes of method variance has been detected. Need to follow up with tests to identify the nature of the proximal causes of method variance (congeneric vs. non-congeneric).

#Model 7: Method UPI model. Allow substantive factor loadings to vary across conditions but (1) force the differences in factor loadings to be equal within factors yet to (2) vary across factors. Tests the hypothesis that proximal causes of method effects addressed by proximal remedies are congeneric (vs. non-congeneric) and is done by (i) computing factor loading differences across conditions and then (ii) forcing the differences to be equal across conditions. If this model is statistically different from method uc, then proximal method effects have complex effects and so a simple correction for failing to use proximal remedies will not be viable. However, if the model is not statistically different from method u, then this suggests that proximal method effects in the factor loadings vary across measurement models.
methodupi.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp2a, papp2a)*PP2 + c(papp3a,papp3a)*PP3 + c(papp4a,papp4a)*PP4 + c(papp5a,papp5a)*PP5 + c(papp6a,papp6a)*PP6 + c(papp7a,papp7a)*PP7 + c(papp8a,papp8a)*PP8 + c(papp9a,papp9a)*PP9 + c(papp10a,papp10a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Method factors are also constrained to zero.
PP ~~ c(PPIRB1,PPIRB2)*IRB
PP ~~ c(PPOCBI1,PPOCBI2)*OCBI
PP ~~ c(PPOCBO1,PPOCBO2)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(IRBOCBI1,IRBOCBI2)*OCBI
IRB ~~ c(IRBOCBO1,IRBOCBO2)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(OCBIO1,OCBIO2)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodupi <- cfa(methodupi.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodupi,methoduc) #Methodupi is statistically different from method u, so a simple correction is not tenable.

#Model 8: Method RAff model. Constrain estimates of covariances to be equal to baseline levels in respective conditions. Test method bias due to positive affectivity and proximal causes of method variance. 
methodruc.cfa <- '

##Substantive factors
PP =~ c(pp1a, pp1b)*PP1 + c(pp2a, pp2b)*PP2 + c(pp3a,pp3b)*PP3 + c(pp4a,pp4b)*PP4 + c(pp5a,pp5b)*PP5 + c(pp6a,pp6b)*PP6 + c(pp7a,pp7b)*PP7 + c(pp8a,pp8b)*PP8 + c(pp9a,pp9b)*PP9 + c(pp10a,pp10b)*PP10
IRB =~ c(irb1a,irb1b)*IRB1 + c(irb2a,irb2b)*IRB2 + c(irb3a,irb3b)*IRB3 + c(irb4a,irb4b)*IRB4
OCBI =~ c(ocbi1a,ocbi1b)*OCBI1 + c(ocbi2a,ocbi2b)*OCBI2 + c(ocbi3a,ocbi3b)*OCBI3 + c(ocbi4a,ocbi4b)*OCBI4 + c(ocbi5a,ocbi5b)*OCBI5 + c(ocbi6a,ocbi6b)*OCBI6 + c(ocbi7a,ocbi7b)*OCBI7
OCBO =~ c(ocbo1a,ocbo1b)*OCBO1 + c(ocbo2a,ocbo2b)*OCBO2 + c(ocbo6a,ocbo6b)*OCBO6 + c(ocbo7a,ocbo7b)*OCBO7

##Method factors
PosAff =~ c(1,1)*PA + c(papp1a, papp1a)*PP1 + c(papp2a, papp2a)*PP2 + c(papp3a,papp3a)*PP3 + c(papp4a,papp4a)*PP4 + c(papp5a,papp5a)*PP5 + c(papp6a,papp6a)*PP6 + c(papp7a,papp7a)*PP7 + c(papp8a,papp8a)*PP8 + c(papp9a,papp9a)*PP9 + c(papp10a,papp10a)*PP10 + c(pairb1a,pairb1a)*IRB1 + c(pairb2a,pairb2a)*IRB2 + c(pairb3a,pairb3a)*IRB3 + c(pairb4a,pairb4a)*IRB4 + c(paocbi1a,paocbi1a)*OCBI1 + c(paocbi2a,paocbi2a)*OCBI2 + c(paocbi3a,paocbi3a)*OCBI3 + c(paocbi4a,paocbi4a)*OCBI4 + c(paocbi5a,paocbi5a)*OCBI5 + c(paocbi6a,paocbi6a)*OCBI6 + c(paocbi7a,paocbi7a)*OCBI7 + c(paocbo1a,paocbo1a)*OCBO1 + c(paocbo2a,paocbo2a)*OCBO2 + c(paocbo6a,paocbo6a)*OCBO6 + c(paocbo7a,paocbo7a)*OCBO7
PA ~~ ((1-.921)*0.824)*PA

#Compute factor loading differences.  
pp1c	:=	pp1b	-	pp1a
pp2c	:=	pp2b	-	pp2a
pp3c	:=	pp3b	-	pp3a
pp4c	:=	pp4b	-	pp4a
pp5c	:=	pp5b	-	pp5a
pp6c	:=	pp6b	-	pp6a
pp7c	:=	pp7b	-	pp7a
pp8c	:=	pp8b	-	pp8a
pp9c	:=	pp9b	-	pp9a
pp10c	:=	pp10b	-	pp10a
irb1c	:=	irb1b	-	irb1a
irb2c	:=	irb2b	-	irb2a
irb3c	:=	irb3b	-	irb3a
irb4c	:=	irb4b	-	irb4a
ocbi1c	:=	ocbi1b	-	ocbi1a
ocbi2c	:=	ocbi2b	-	ocbi2a
ocbi3c	:=	ocbi3b	-	ocbi3a
ocbi4c	:=	ocbi4b	-	ocbi4a
ocbi5c	:=	ocbi5b	-	ocbi5a
ocbi6c	:=	ocbi6b	-	ocbi6a
ocbi7c	:=	ocbi7b	-	ocbi7a
ocbo1c	:=	ocbo1b	-	ocbo1a
ocbo2c	:=	ocbo2b	-	ocbo2a
ocbo6c	:=	ocbo6b	-	ocbo6a
ocbo7c	:=	ocbo7b	-	ocbo7a

#Constrain the differences to be equal within factors but vary across factors.
pp1c==pp2c
pp2c==pp3c
pp3c==pp4c
pp4c==pp5c
pp5c==pp6c
pp6c==pp7c
pp7c==pp8c
pp8c==pp9c
pp9c==pp10c
irb1c==irb2c
irb2c==irb3c
irb3c==irb4c
ocbi1c==ocbi2c
ocbi2c==ocbi3c
ocbi3c==ocbi4c
ocbi4c==ocbi5c
ocbi5c==ocbi6c
ocbi6c==ocbi7c
ocbo1c==ocbo2c
ocbo2c==ocbo6c
ocbo6c==ocbo7c

#Factor variances are fixed to 1 to allow estimation.
###Substantive factors
PP ~~ c(1,1)*PP
IRB ~~ c(1,1)*IRB
OCBI ~~ c(1,1)*OCBI
OCBO ~~ c(1,1)*OCBO

##Factor covariances freely estimated (with the exception being the bifactors). However, correlations with the method factors are fixed to zero. Latent covariances come from the 
PP ~~ c(.372,.342)*IRB
PP ~~ c(.559,.338)*OCBI
PP ~~ c(.453,.317)*OCBO
PP ~~ c(0,0)*PosAff
IRB ~~ c(.688,.497)*OCBI
IRB ~~ c(.837,.645)*OCBO
IRB ~~ c(0,0)*PosAff
OCBI ~~ c(.794,.859)*OCBO
OCBI ~~ c(0,0)*PosAff
OCBO ~~ c(0,0)*PosAff

#Factor means of the both groups are fixed at zero to allow identification.
##Substantive factors
PP ~ c(0, 0)*1
IRB ~ c(0, 0)*1
OCBI ~ c(0, 0)*1
OCBO ~ c(0, 0)*1
'
methodruc <- cfa(methodruc.cfa, group = "COND", data = data3, estimator = "DWLS", parameterization = "theta", information = "expected", std.lv=TRUE)
anova(methodruc,methoduc) #Evidence of bias attributable to the accounted for method effects (i.e., positive affectivity and proximal method variance). 

## extract fit indices tables
fitm.initial <- fitmeasures(initial)      #Model 1: Initial model.
fitm.baseline <- fitmeasures(baseline)    #Model 2: Baseline model.
fitm.methodu <- fitmeasures(methodu)      #Model 3: Unconstrained method effects model. (Presence of method effects).
fitm.methodi <- fitmeasures(methodi)      #Model 4: Method effects vary across substantive constructs. (Congeneric vs. Noncongeneric CMV).
fitm.methoduc <- fitmeasures(methoduc)    #Model 5: Constrain method effects to equality across conditions. (Proximal method variance equal across remedied vs. non-remedied).
fitm.methodup <- fitmeasures(methodup)    #Model 6: Constrain substantive factor loadings to be equal across conditions (proximal remedies decontaminate measurement models).
fitm.methodupi <- fitmeasures(methodupi)  #Model 7: Force factor loadings to be equal within factors but vary across factors (congeneric vs. noncongeneric proximal method effects).
fitm.methodupc <-  fitmeasures(methodupc) #Model 8: Tests for constant proximal method effect.
fitm.methodru <- fitmeasures(methodrupi)  #Model 9: Constrain latent covariances to baseline levels in respective conditions (test for method bias).

#Build table
greeks=c(alpha='\u03b1', tau='\u03c4', sigma='\u03c3', beta='\u03b2', gamma='\u03b3', chi='\u03c7', delta='\u0394')
Model <- c("Initial CFA", "Baseline", "Method U", "Method I", "Method Uc", "Method Up", "Method Upi", "Method Ru", "Method U")
chi.square <- c(paste0(greeks['chi'],'^2^'))
df <- c("df")
chi.square.p.value <- c("*p* value")
RMSEA <- c("RMSEA")
RMSEA.lower <- c("90% LCL")
RMSEA.upper <- c("90% UCL")
RMSEA.pvalue <- c("RMSEA p value")
SRMR <- c("SRMR")
table <- as.data.frame(cbind(Model,chi.square,df,"p value","CF","RMSEA","90% LCL","90% UCL","RMSEA p value","SRMR"))
colnames(table)[2] <- paste0(greeks['chi'],'^2')
colnames(table)[3] <- df
colnames(table)[4] <- c("p value")
colnames(table)[5] <- c("CFI")
colnames(table)[6] <- RMSEA
colnames(table)[7] <- RMSEA.lower
colnames(table)[8] <- RMSEA.upper
colnames(table)[9] <- RMSEA.pvalue
colnames(table)[10] <- SRMR
#Convert collumns 2 through 9 to numeric.
table$`χ^2` <- as.numeric(table$χ)
table$df <- as.numeric(table$df)
table$`p value` <- as.numeric(table$`p value`)
table$CFI <- as.numeric(table$CFI)
table$RMSEA <- as.numeric(table$RMSEA)
table$`90% LCL` <- as.numeric(table$`90% LCL`)
table$`90% UCL` <- as.numeric(table$`90% UCL`)
table$`RMSEA p value` <- as.numeric(table$`RMSEA p value`)
table$SRMR <- as.numeric(table$SRMR)

#Insert stats
##Chi-Square
table[1,2]<- round(as.numeric(fitMeasures(initial)[3]), digits = 2)
table[2,2]<- round(as.numeric(fitmeasures(baseline)[3]), digits = 2)
table[3,2]<- round(as.numeric(fitmeasures(methodu)[3]), digits = 2)
table[4,2]<- round(as.numeric(fitmeasures(methodi)[3]), digits = 2)
table[5,2]<- round(as.numeric(fitmeasures(methoduc)[3]), digits = 2)
table[6,2]<- round(as.numeric(fitmeasures(methodup)[3]), digits = 2)
table[7,2]<- round(as.numeric(fitmeasures(methodupi)[3]), digits = 2)
table[8,2]<- round(as.numeric(fitmeasures(methodru)[3]), digits = 2)
table[9,2]<- round(as.numeric(fitmeasures(methoduu)[3]), digits = 2)

##df
table[1,3]<- round(as.numeric(fitMeasures(initial)[4]), digits = 2)
table[2,3]<- round(as.numeric(fitmeasures(baseline)[4]), digits = 2)
table[3,3]<- round(as.numeric(fitmeasures(methodu)[4]), digits = 2)
table[4,3]<- round(as.numeric(fitmeasures(methodi)[4]), digits = 2)
table[5,3]<- round(as.numeric(fitmeasures(methoduc)[4]), digits = 2)
table[6,3]<- round(as.numeric(fitmeasures(methodup)[4]), digits = 2)
table[7,3]<- round(as.numeric(fitmeasures(methodupi)[4]), digits = 2)
table[8,3]<- round(as.numeric(fitmeasures(methodru)[4]), digits = 2)
table[9,3]<- round(as.numeric(fitmeasures(methoduu)[4]), digits = 2)

##Chi-Square p value
#Adapt p-values to table.
pvalr <- function(pvals, sig.limit = .001, digits = 3, html = FALSE) {

  roundr <- function(x, digits = 1) {
    res <- sprintf(paste0('%.', digits, 'f'), x)
    zzz <- paste0('0.', paste(rep('0', digits), collapse = ''))
    res[res == paste0('-', zzz)] <- zzz
    res
  }

  sapply(pvals, function(x, sig.limit) {
    if (x < sig.limit)
      if (html)
        return(sprintf('&lt; %s', format(sig.limit))) else
          return(sprintf('< %s', format(sig.limit)))
    if (x > .1)
      return(roundr(x, digits = 2)) else
        return(roundr(x, digits = digits))
  }, sig.limit = sig.limit)
}
table[1,4]<- pvalr(as.numeric(fitMeasures(initial)[5]), digits = 2)
table[2,4]<- pvalr(as.numeric(fitmeasures(baseline)[5]), digits = 2)
table[3,4]<- pvalr(as.numeric(fitmeasures(methodu)[5]), digits = 2)
table[4,4]<- pvalr(as.numeric(fitmeasures(methodi)[5]), digits = 2)
table[5,4]<- pvalr(as.numeric(fitmeasures(methoduc)[5]), digits = 2)
table[6,4]<- pvalr(as.numeric(fitmeasures(methodup)[5]), digits = 2)
table[7,4]<- pvalr(as.numeric(fitmeasures(methodupi)[5]), digits = 2)
table[8,4]<- pvalr(as.numeric(fitmeasures(methodru)[5]), digits = 2)
table[9,4]<- pvalr(as.numeric(fitmeasures(methoduu)[5]), digits = 2)

#CFI
table[1,5]<- round(as.numeric(fitMeasures(initial)[9]), digits = 3)
table[2,5]<- round(as.numeric(fitmeasures(baseline)[9]), digits = 3)
table[3,5]<- round(as.numeric(fitmeasures(methodu)[9]), digits = 3)
table[4,5]<- round(as.numeric(fitmeasures(methodi)[9]), digits = 3)
table[5,5]<- round(as.numeric(fitmeasures(methoduc)[9]), digits = 3)
table[6,5]<- round(as.numeric(fitmeasures(methodup)[9]), digits = 3)
table[7,5]<- round(as.numeric(fitmeasures(methodupi)[9]), digits = 3)
table[8,5]<- round(as.numeric(fitmeasures(methodru)[9]), digits = 3)
table[9,5]<- round(as.numeric(fitmeasures(methoduu)[9]), digits = 3)

##RMSEA
table[1,6]<- round(as.numeric(fitMeasures(initial)[17]), digits = 3)
table[2,6]<- round(as.numeric(fitmeasures(baseline)[17]), digits = 3)
table[3,6]<- round(as.numeric(fitmeasures(methodu)[17]), digits = 3)
table[4,6]<- round(as.numeric(fitmeasures(methodi)[17]), digits = 3)
table[5,6]<- round(as.numeric(fitmeasures(methoduc)[17]), digits = 3)
table[6,6]<- round(as.numeric(fitmeasures(methodup)[17]), digits = 3)
table[7,6]<- round(as.numeric(fitmeasures(methodupi)[17]), digits = 3)
table[8,6]<- round(as.numeric(fitmeasures(methodru)[17]), digits = 3)
table[9,6]<- round(as.numeric(fitmeasures(methoduu)[17]), digits = 3)

#RMSEA lower
table[1,7]<- round(as.numeric(fitMeasures(initial)[18]), digits = 3)
table[2,7]<- round(as.numeric(fitmeasures(baseline)[18]), digits = 3)
table[3,7]<- round(as.numeric(fitmeasures(methodu)[18]), digits = 3)
table[4,7]<- round(as.numeric(fitmeasures(methodi)[18]), digits = 3)
table[5,7]<- round(as.numeric(fitmeasures(methoduc)[18]), digits = 3)
table[6,7]<- round(as.numeric(fitmeasures(methodup)[18]), digits = 3)
table[7,7]<- round(as.numeric(fitmeasures(methodupi)[18]), digits = 3)
table[8,7]<- round(as.numeric(fitmeasures(methodru)[18]), digits = 3)
table[9,7]<- round(as.numeric(fitmeasures(methoduu)[18]), digits = 3)

#RMSEA upper
table[1,8]<- round(as.numeric(fitMeasures(initial)[19]), digits = 3)
table[2,8]<- round(as.numeric(fitmeasures(baseline)[19]), digits = 3)
table[3,8]<- round(as.numeric(fitmeasures(methodu)[19]), digits = 3)
table[4,8]<- round(as.numeric(fitmeasures(methodi)[19]), digits = 3)
table[5,8]<- round(as.numeric(fitmeasures(methoduc)[19]), digits = 3)
table[6,8]<- round(as.numeric(fitmeasures(methodup)[19]), digits = 3)
table[7,8]<- round(as.numeric(fitmeasures(methodupi)[19]), digits = 3)
table[8,8]<- round(as.numeric(fitmeasures(methodru)[19]), digits = 3)
table[9,8]<- round(as.numeric(fitmeasures(methoduu)[19]), digits = 3)

#RMSEA p-value
table[1,9]<- pvalr(as.numeric(fitMeasures(initial)[20]), digits = 3)
table[2,9]<- pvalr(as.numeric(fitmeasures(baseline)[20]), digits = 3)
table[3,9]<- pvalr(as.numeric(fitmeasures(methodu)[20]), digits = 3)
table[4,9]<- pvalr(as.numeric(fitmeasures(methodi)[20]), digits = 3)
table[5,9]<- pvalr(as.numeric(fitmeasures(methoduc)[20]), digits = 3)
table[6,9]<- pvalr(as.numeric(fitmeasures(methodup)[20]), digits = 3)
table[7,9]<- pvalr(as.numeric(fitmeasures(methodupi)[20]), digits = 3)
table[8,9]<- pvalr(as.numeric(fitmeasures(methodru)[20]), digits = 3)
table[9,9]<- pvalr(as.numeric(fitmeasures(methoduu)[20]), digits = 3)

#SRMR
table[1,10]<- round(as.numeric(fitMeasures(initial)[23]), digits = 3)
table[2,10]<- round(as.numeric(fitmeasures(baseline)[23]), digits = 3)
table[3,10]<- round(as.numeric(fitmeasures(methodu)[23]), digits = 3)
table[4,10]<- round(as.numeric(fitmeasures(methodi)[23]), digits = 3)
table[5,10]<- round(as.numeric(fitmeasures(methoduc)[23]), digits = 3)
table[6,10]<- round(as.numeric(fitmeasures(methodup)[23]), digits = 3)
table[7,10]<- round(as.numeric(fitmeasures(methodupi)[23]), digits = 3)
table[8,10]<- round(as.numeric(fitmeasures(methodru)[23]), digits = 3)
table[9,10]<- round(as.numeric(fitmeasures(methoduu)[23]), digits = 3)

#Relable table to table 2.
table2 <- table

#Build table. These codes need to be fixed. 
Model <- c("Baseline vs. Method U", "Method U vs. Method I", "Method U vs. Method Uc", "Method U vs. Method Up", "Method U vs. Method Upi", "Method U vs. Method Ru", "Method U vs. Method Uu")
chi.square <- c(paste0(greeks['delta']),paste0(greeks['chi']), "^2^")
df <- c(paste0(greeks['delta']),"df")
chi.square.critical.value <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
table <- as.data.frame(cbind(Model,chi.square,df,chi.square.critical.value,"pvalue"))
colnames(table)[2] <- c(paste0(greeks['chi']))
colnames(table)[3] <- c("df")
colnames(table)[4] <- c(paste0(greeks['chi'],'^2^', " critical value; 0.05"))
colnames(table)[5] <- c("p value")

#Convert collumns 2 through 4 to numeric.
table$χ <- as.numeric(table$χ)    #chi-square
table$df <- as.numeric(table$df)  #df
table$`χ^2^ critical value; 0.05` <- as.numeric(table$`χ^2^ critical value; 0.05`)  #critical-value
table$`p value` <- as.numeric(table$`p value`)

#Insert stats
#Chi-square difference
table[1,2]<- abs(table2$`χ^2`[2] - table2$`χ^2`[3])
table[2,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[4])
table[3,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[5])
table[4,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[6])
table[5,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[7])
table[6,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[8])
table[7,2]<- abs(table2$`χ^2`[3] - table2$`χ^2`[9])

#df difference
table[1,3]<- abs(table2$df[2] - table2$df[3])
table[2,3]<- abs(table2$df[3] - table2$df[4])
table[3,3]<- abs(table2$df[3] - table2$df[5])
table[4,3]<- abs(table2$df[3] - table2$df[6])
table[5,3]<- abs(table2$df[3] - table2$df[7])
table[6,3]<- abs(table2$df[3] - table2$df[8])
table[7,3]<- abs(table2$df[3] - table2$df[9])

#chi-square critical value
table[1,4]<- round(qchisq(.05, table$df[1], lower.tail=FALSE), digits = 2)
table[2,4]<- round(qchisq(.05, table$df[2], lower.tail=FALSE), digits = 2)
table[3,4]<- round(qchisq(.05, table$df[3], lower.tail=FALSE), digits = 2)
table[4,4]<- round(qchisq(.05, table$df[4], lower.tail=FALSE), digits = 2)
table[5,4]<- round(qchisq(.05, table$df[5], lower.tail=FALSE), digits = 2)
table[6,4]<- round(qchisq(.05, table$df[6], lower.tail=FALSE), digits = 2)
table[7,4]<- round(qchisq(.05, table$df[7], lower.tail=FALSE), digits = 2)

#p value
table[1,5]<- pvalr(pchisq(table$χ[1], table$df[1], lower.tail=FALSE), digits = 2)
table[2,5]<- pvalr(pchisq(table$χ[2], table$df[2], lower.tail=FALSE), digits = 2)
table[3,5]<- pvalr(pchisq(table$χ[3], table$df[3], lower.tail=FALSE), digits = 2)
table[4,5]<- pvalr(pchisq(table$χ[4], table$df[4], lower.tail=FALSE), digits = 2)
table[5,5]<- pvalr(pchisq(table$χ[5], table$df[5], lower.tail=FALSE), digits = 2)
table[6,5]<- pvalr(pchisq(table$χ[6], table$df[6], lower.tail=FALSE), digits = 2)
table[7,5]<- pvalr(pchisq(table$χ[7], table$df[7], lower.tail=FALSE), digits = 2)

#Relable table to table 3.
table3 <- table

#Factor loadings table for Method U.
PT <- inspect(methodu, what = "std")
PT.Remedied <- PT[["0"]][["lambda"]]
PT.NonRemedied <- PT[["1"]][["lambda"]]
##Organize cells
###Remedied
PTR.p <- round(as.data.frame(PT.Remedied[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.i <- round(as.data.frame(PT.Remedied[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.oi <- round(as.data.frame(PT.Remedied[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Remedied)"
PTR.oo <- round(as.data.frame(PT.Remedied[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Remedied)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Remedied)"
PT.Remedied <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.Remedied$residualsr <- round(1-(PT.Remedied$`Substantive Factor Loading (Remedied)`^2+PT.Remedied$`Method Factor Loading (Remedied)`^2), digits = 2)

#Non-Remedied
PTR.p <- round(as.data.frame(PT.NonRemedied[1:10,]), digits = 2)
PTR.p <- PTR.p[c(1,5)]
colnames(PTR.p)[colnames(PTR.p)=="PP"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.p)[colnames(PTR.p)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.i <- round(as.data.frame(PT.NonRemedied[11:17,]), digits = 2)
PTR.i <- PTR.i[c(2,5)]
colnames(PTR.i)[colnames(PTR.i)=="IRB"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.i)[colnames(PTR.i)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.oi <- round(as.data.frame(PT.NonRemedied[18:24,]), digits = 2)
PTR.oi <- PTR.oi[c(3,5)]
colnames(PTR.oi)[colnames(PTR.oi)=="OCBI"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.oi)[colnames(PTR.oi)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PTR.oo <- round(as.data.frame(PT.NonRemedied[25:31,]), digits = 2)
PTR.oo <- PTR.oo[c(4,5)]
colnames(PTR.oo)[colnames(PTR.oo)=="OCBO"] <- "Substantive Factor Loading (Non-Remedied)"
colnames(PTR.oo)[colnames(PTR.oo)=="PosAff"] <- "Method Factor Loading (Non-Remedied)"
PT.NonRemedied <- as.data.frame(rbind(PTR.p,PTR.i,PTR.oi,PTR.oo))
PT.NonRemedied$residualsnr <- round(1-(PT.NonRemedied$`Substantive Factor Loading (Non-Remedied)`^2 + PT.NonRemedied$`Method Factor Loading (Non-Remedied)`^2), digits = 2)
#Combine
PT.full <- cbind(PT.Remedied,PT.NonRemedied)
#Make PT.full all positive to avoid calculation issues
PT.full <- abs(PT.full)

#Method and substantive reliability table.
Model <- c("Proactive Personality", "In-Role Behavior", "Org. Citizenship Behavior (Org.)", "Org. Citizenship Behavior (Ind.)", "Positive Affectivity")
table <- as.data.frame(cbind(Model,"V1","V2","V3","V4","V5","V6","V7","V8"))
colnames(table)[1] <- c("Latent Variable")
colnames(table)[2] <- c("Total Reliability (Remedied)")
colnames(table)[3] <- c("Substantive Reliability (Remedied)")
colnames(table)[4] <- c("Method Reliability (Remedied)")
colnames(table)[5] <- c("% Reliable Method Variance (Remedied)")
colnames(table)[6] <- c("Total Reliability (Non-Remedied)")
colnames(table)[7] <- c("Substantive Reliability (Non-Remedied)")
colnames(table)[8] <- c("Method Reliability (Non-Remedied)")
colnames(table)[9] <- c("% Reliable Method Variance (Non-Remedied)")

#Convert collumns 2 through 5 to numeric.
table$`Total Reliability (Remedied)` <- as.numeric(table$`Total Reliability (Remedied)`)
table$`Substantive Reliability (Remedied)` <- as.numeric(table$`Substantive Reliability (Remedied)`)
table$`Method Reliability (Remedied)` <- as.numeric(table$`Method Reliability (Remedied)`)
table$`% Reliable Method Variance (Remedied)` <- as.numeric(table$`% Reliable Method Variance (Remedied)`)
table$`Total Reliability (Non-Remedied)` <- as.numeric(table$`Total Reliability (Non-Remedied)`)
table$`Substantive Reliability (Non-Remedied)` <- as.numeric(table$`Substantive Reliability (Non-Remedied)`)
table$`Method Reliability (Non-Remedied)` <- as.numeric(table$`Method Reliability (Non-Remedied)`)
table$`% Reliable Method Variance (Non-Remedied)` <- as.numeric(table$`% Reliable Method Variance (Non-Remedied)`)

#Insert stats

##Substantive Reliability: Remedied
table[1,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[2,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[3,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[4,3]<- round(sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Method Reliability: Remedied
table[1,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Remedied)`[1:10])^2) + sum(PT.full$residualsr[1:10])), digits = 2)
table[2,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Remedied)`[11:17])^2) + sum(PT.full$residualsr[11:17])), digits = 2)
table[3,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Remedied)`[18:24])^2) + sum(PT.full$residualsr[18:24])), digits = 2)
table[4,4]<- round(sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Remedied)`[25:31])^2) + sum(PT.full$residualsr[25:31])), digits = 2)

##Total Reliability: Remedied
table[1,2] <- sum(table[1,3],table[1,4])
table[2,2] <- sum(table[2,3],table[2,4])
table[3,2] <- sum(table[3,3],table[3,4])
table[4,2] <- sum(table[4,3],table[4,4])

##% Reliable Method Variance: Remedied
table[1,5] <- round(table[1,4]/table[1,2], digits = 2)
table[2,5] <- round(table[2,4]/table[2,2], digits = 2)
table[3,5] <- round(table[3,4]/table[3,2], digits = 2)
table[4,5] <- round(table[4,4]/table[4,2], digits = 2)

##Substantive Reliability: Non-Remedied
table[1,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2) + sum(PT.full$residualsnr[1:10])), digits = 2)
table[2,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2) + sum(PT.full$residualsnr[11:17])), digits = 2)
table[3,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2) + sum(PT.full$residualsnr[18:24])), digits = 2)
table[4,7]<- round(sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2) + sum(PT.full$residualsnr[25:31])), digits = 2)

##Method Reliability: Non-Remedied
table[1,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[1:10])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[1:10])^2) + sum(PT.full$residualsnr[1:10])), digits = 2)
table[2,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[11:17])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[11:17])^2) + sum(PT.full$residualsnr[11:17])), digits = 2)
table[3,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[18:24])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[18:24])^2) + sum(PT.full$residualsnr[18:24])), digits = 2)
table[4,8]<- round(sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2/((sum(PT.full$`Substantive Factor Loading (Non-Remedied)`[25:31])^2+sum(PT.full$`Method Factor Loading (Non-Remedied)`[25:31])^2) + sum(PT.full$residualsnr[25:31])), digits = 2)

##Total Reliability: Non-Remedied
table[1,6] <- sum(table[1,7],table[1,8])
table[2,6] <- sum(table[2,7],table[2,8])
table[3,6] <- sum(table[3,7],table[3,8])
table[4,6] <- sum(table[4,7],table[4,8])

##% Reliable Method Variance: Non-Remedied
table[1,9] <- round(table[1,8]/table[1,6], digits = 2)
table[2,9] <- round(table[2,8]/table[2,6], digits = 2)
table[3,9] <- round(table[3,8]/table[3,6], digits = 2)
table[4,9] <- round(table[4,8]/table[4,6], digits = 2)

#Insert PA data.
table[5,2] <- round(PA.alpha, digits = 2)
table[5,3] <- round(PA.alpha, digits = 2)
table[5,4] <- 0
table[5,5] <- NA
table[5,6] <- round(PA.alpha, digits = 2)
table[5,7] <- round(PA.alpha, digits = 2)
table[5,8] <- 0
table[5,9] <- NA

#Relable table to table 4.
table4 <- table

```
```{r Table 9 Descriptives Study 3, include = TRUE}
table1 <- apa.cor.table(scales)
```
```{r Table 10 Model-Data Fit Study 3, include = TRUE}
table2
```
```{r Table 11 Model-Comparison Table Study 3, include = TRUE}
table3
```
```{r Table 12 Variance Decomposition Study 3, include = TRUE}
table4
```
#Discussion - Study 3
  Our results speak to a more nuanced view of method variance that has been offered by @SpectorNewPerspectiveMethod2017, who urge researchers to focus less on broad solutions to CMV (e.g., broad set of remedies for proximal method effects and statistical controls that assume unidimensional method effects) and more more on the extraneuous effects that are introduced by the measurement strategy employed in an investigation, which they refer to as either common or unique method variance. To explain by way of example, studies seeking to estimate the effect of attitudinal factors on behaviors should consider sources of variance that are common to all measures in the study (e.g., mood and social desirability) as well as factors unique to specific measures in the study (e.g., response sets might affect self-reports of attitudes while impression management might affect reports of sensitive behaviors, like deviance). Either common or unique sources of variance could dominate a particular study, or they could also cancel each other out. Either way, they introduce variation into the measures utilized in an investigation, which can result in either inflated or attentuated effect size estimates. They also encourage research into the developmentof a knowledge base upon which to rely in deciding how method variance could be addressed in investigations, which will require accumulating knowledge about soruces of methods to consider and control in a study. To this point, while our investigation focused on certain common method variance sources (e.g., consistency motifs, affectivity, mood), we did not exhaustively study the role played by all possible sources (e.g., social desirability). We also neglected to address the role played by uncommon method variance sources (e.g., impression management, which seems relevant for self-reports of IRB, limited information, which seems relevant for self-reports of behavior; and response sets, which seems relevant for proactive personalitiy). Therefore, we encourage future reserach to investigate the role played by these sources of nuissance variance. 

#Genernal Discussion
  Overall, our results suggest that method variance may far more nuanced than suggested by the early literature. Firstly, our data align with the view the view that method variance is best viewed multidimensionally and approached in an multipronged manner. For instance, we found several method effects linked to positive affect, mood, negative item wording, and (presumably) being in a common block. These forces were also strong enough to cause biased estimates of latent construct correlation in our remedied condition, some of which became non-significant once method effects were controlled. However, certain causes of method variance seem insufficient for causing bias.

The results of our investigation revealed that proximal remedies do, indeed, reduce the presence of method variance targeted by such remedies. Study 1 showed that context effects can be reduced by randomizing items and scales around filler scales. More specifically, randomizing items and scales reduced the inflating effects that occur when items and scales were presented in a consistent order. We also found that consistency motifs can be weakened by a cover story, as consistency motif effects were only observed in the non-remedied condition. In Study 2, mood effects were nullified by separating measurements of predictors and criterion variables by one week. Specifically, momentary mood effects were observed only in our non-remedied condition.

While these findings support the viability of proximal remedies for causes of method variance, they also revealed that, with the possible exception of context effects, these remedies address relatively minor sources of method bias that were unique and inconsistent in their effects. For instance, small biasing effects were observed for consistency motifs and mood. Yet, our findings suggest that other biases which are unaffected by these remedies are more important (i.e., PA, which consistently inflated effect size estimates across both studies). As PA is an important and stable trait in organizational behavior research, researchers should statistically account for this likely source of method variance. Additionally, negative item wording emerged as another consistently biasing method factor that exerted an attenuating effect on relationships when negative items were present in a measure. Thus, researchers may want to avoid using negatively worded items. Indeed, echoing Podsakoff et al. (2003) our results suggest that using both procedural and statistical remedies is important to reducing less-biased effect size estimates.

Despite addressing relatively minor and inconsistent causes of bias, these proximal remedies may be useful when researchers believe that other sources of method variance might play a complementary role. This might occur when independent method effects (e.g., positive affectivity and negative item wording) are common contaminants for a measurement model. This is because minor sources of method variance may have relatively independent and incremental effects that could be insignificant in isolation but potent in combination. Researchers may also wish to use these remedies to address uncommon method variance.

Comparing our findings to effects reported by @FullerJr.Changedrivennature2009 suggests that more research is needed into the role that method variance plays into these substantive relationships. Fuller and Marler estimated for the proactive personality–voice relationship is much smaller (ρ = .31) than the estimate provided by our two studies (ρ = .65-.76). Yet, it is not clear why this disparity exists. The original meta-analysis may not have accounted for unique sources of method variance, which would systematically attenuate estimates. Or, this disparity in findings could be social desirability, which is likely correlated with proactive personality and PA, but was not measured in this research. Finally, we conducted several post hoc tests to determine if other sources of CMV could have created these effects; yet, our subsequent tests of common scale format and anchor effects provided no evidence of this. A test of evaluation consistency bias (i.e., halo factor) on these positively valenced items was conducted using the unmeasured latent method factor modeling technique, yet it failed to run. Interestingly, after accounting for method factors, we found more conservative estimates of the relations between proactive personality to task performance (ρ = .39) and to contextual performance (ρ = .56) than did @FullerJr.Changedrivennature2009. In our data, the proactive personality– IRB relationship (ρ = .15-.33) and the proactive personality–OCBI/O relationships (ρ = .14-.49) after accounting for method factors, resulted in statistically non-significant relationships. Additionally, prior estimates were likely inflated by PA, as we provide evidence that method variance dominated the OCBO measurement model (74% of reliable variance in Study 1 and 63% in Study 2). We call for future research into the role of method variance in the assessment of OCB. Based on our findings, we recommend that researchers relying on same-source research designs may be wise to use separation remedies to reduce the presence and impact of method effects, even though these procedural remedies may not address important sources of method variance. Additionally, as suggested by others (i.e., Spector et al., in press), there may be specific sources of method variance for which to account in order to produce less biased estimates.

From a practical standapoint, the contaminating role of proactive personality may not be viewed as a serious problem. Indeed, practitioners may be unsurprised to see that proactive personality is contaminated by positive affectivity. This may even be desired from the standpoint that the alternative, which would be assessing an affective disposition, may be viewed as lacking in job relevance by key stakeholders. 

##Limitations and Future Research
  We only measured one cause of method variance: positive affectivity. There were many other method effects that we could have included in our analyses (e.g., negative affectivity, affective polarity, negative item wording, consistency motifs or response styles, common item blocking effects, momentary mood), but due to convergence issues we elected to only report the findings for a scale that was both well established and used consistently across our three studies. To a related point and suggested by many other scholars [@Coleinsidiouseffectsfailing2007; @LandisPracticeAllowingCorrelated2009; @PodsakoffCommonmethodbiases2003; @WeijtersDiscriminantValidityWhere2014], common scale content appeared to cause residual covariation across our studies and contributed to poor model data fit across our studies. We have made our data publically available for reanalysis for researchers interested in exploring both the implications of controlling for other sources of method variance and accounting for residual covariances. We do ask that researchers interested in using our data contact include us on any future manuscript developments.
  To a related point, we only measured positive affectivity using the positive affectivity scale of the PANAS. While some might view our decision to use the PANAS as desireable, there are noteworthy problems associated with using teh PANAS in study such as ours. Most importantly, as a measure of a contaminating source of method variance, it has been suggested that such measures satisfy scalar invariance across methodological conditions  [@WilliamsFourResearchDesigns2016; @WilliamsMethodVarianceMarker2010], which is difficult to achieve in practice. Indeed, we examined this possibility for all of our method variables and scarcely found instances where scalar invariance was upheld. Therefore, we call for more research into stronger measures of method effects themselves.
  As noted previously, by modeling item level responses, we more faithfully test method variance theory. However, this could be taken one step further by incorporating both larger datasets and item reponse theory, which more faithfully models the item reponse process, which only a few studies examine to date [@LiuGeneralUnfoldingIRT2018; @SteinbergContextserialordereffects1994]. Indeed, this would overcome a significant limitation to our study (i.e., small samples). Linking causes of method variance to the item response process would meaningfully contribute to measurement development and research design in the organizational sciences. 
  
#References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
